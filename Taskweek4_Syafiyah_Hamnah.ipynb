{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syafiyahh/TaskWeek4/blob/main/Taskweek4_Syafiyah_Hamnah.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1OnxR8OWH_xK",
      "metadata": {
        "id": "1OnxR8OWH_xK"
      },
      "source": [
        "TUGAS WEEK 4\n",
        "\n",
        "Nama: Syafiyah Hamnah Hasan\n",
        "\n",
        "NPM: 2106726144"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IGBKupOvHOcV",
      "metadata": {
        "id": "IGBKupOvHOcV"
      },
      "source": [
        "#8.1 Deep Convolutional Neural Networks (AlexNet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "270c2008",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "270c2008",
        "outputId": "b3a49ae9-564a-40bb-c9a3-80592a9944b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: d2l==1.0.3 in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (1.0.0)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (1.23.5)\n",
            "Requirement already satisfied: matplotlib==3.7.2 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (3.7.2)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (0.1.6)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (2.31.0)\n",
            "Requirement already satisfied: pandas==2.0.3 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (2.0.3)\n",
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (1.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.5.5)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (5.6.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (10.4.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline==0.1.6->d2l==1.0.3) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->d2l==1.0.3) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->d2l==1.0.3) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.3) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.3) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l==1.0.3) (1.16.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.6.9)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.0.13)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (2.18.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.4)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.1.4)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.10.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.3.0)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.1.0)\n",
            "Requirement already satisfied: qtpy>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from qtconsole->jupyter==1.0.0->d2l==1.0.3) (2.4.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (71.0.4)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.23.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l==1.0.3) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l==1.0.3) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.20.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install d2l==1.0.3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3ed4012",
      "metadata": {
        "id": "c3ed4012"
      },
      "source": [
        "## Deep Convolutional Neural Networks (AlexNet)\n",
        ":label:`sec_alexnet`\n",
        "\n",
        "\n",
        "Although CNNs were well known\n",
        "in the computer vision and machine learning communities\n",
        "following the introduction of LeNet :cite:`LeCun.Jackel.Bottou.ea.1995`,\n",
        "they did not immediately dominate the field.\n",
        "Although LeNet achieved good results on early small datasets,\n",
        "the performance and feasibility of training CNNs\n",
        "on larger, more realistic datasets had yet to be established.\n",
        "In fact, for much of the intervening time between the early 1990s\n",
        "and the watershed results of 2012 :cite:`Krizhevsky.Sutskever.Hinton.2012`,\n",
        "neural networks were often surpassed by other machine learning methods,\n",
        "such as kernel methods :cite:`Scholkopf.Smola.2002`, ensemble methods :cite:`Freund.Schapire.ea.1996`,\n",
        "and structured estimation :cite:`Taskar.Guestrin.Koller.2004`.\n",
        "\n",
        "For computer vision, this comparison is perhaps not entirely accurate.\n",
        "That is, although the inputs to convolutional networks\n",
        "consist of raw or lightly-processed (e.g., by centering) pixel values, practitioners would never feed raw pixels into traditional models.\n",
        "Instead, typical computer vision pipelines\n",
        "consisted of manually engineering feature extraction pipelines, such as SIFT :cite:`Lowe.2004`, SURF :cite:`Bay.Tuytelaars.Van-Gool.2006`, and bags of visual words :cite:`Sivic.Zisserman.2003`.\n",
        "Rather than *learning* the features, the features were *crafted*.\n",
        "Most of the progress came from having more clever ideas for feature extraction on the one hand and deep insight into geometry :cite:`Hartley.Zisserman.2000` on the other. The learning algorithm was often considered an afterthought.\n",
        "\n",
        "Although some neural network accelerators were available in the 1990s,\n",
        "they were not yet sufficiently powerful to make\n",
        "deep multichannel, multilayer CNNs\n",
        "with a large number of parameters. For instance, NVIDIA's GeForce 256 from 1999\n",
        "was able to process at most 480 million floating-point operations, such as additions and multiplications, per second (MFLOPS), without any meaningful\n",
        "programming framework for operations beyond games. Today's accelerators are able to perform in excess of 1000 TFLOPs per device.\n",
        "Moreover, datasets were still relatively small: OCR on 60,000 low-resolution $28 \\times 28$ pixel images was considered a highly challenging task.\n",
        "Added to these obstacles, key tricks for training neural networks\n",
        "including parameter initialization heuristics :cite:`Glorot.Bengio.2010`,\n",
        "clever variants of stochastic gradient descent :cite:`Kingma.Ba.2014`,\n",
        "non-squashing activation functions :cite:`Nair.Hinton.2010`,\n",
        "and effective regularization techniques :cite:`Srivastava.Hinton.Krizhevsky.ea.2014` were still missing.\n",
        "\n",
        "Thus, rather than training *end-to-end* (pixel to classification) systems,\n",
        "classical pipelines looked more like this:\n",
        "\n",
        "1. Obtain an interesting dataset. In the early days, these datasets required expensive sensors. For instance, the [Apple QuickTake 100](https://en.wikipedia.org/wiki/Apple_QuickTake) of 1994 sported a whopping 0.3 megapixel (VGA) resolution, capable of storing up to 8 images, all for the price of \\$1000.\n",
        "1. Preprocess the dataset with hand-crafted features based on some knowledge of optics, geometry, other analytic tools, and occasionally on the serendipitous discoveries by lucky graduate students.\n",
        "1. Feed the data through a standard set of feature extractors such as the SIFT (scale-invariant feature transform) :cite:`Lowe.2004`, the SURF (speeded up robust features) :cite:`Bay.Tuytelaars.Van-Gool.2006`, or any number of other hand-tuned pipelines. OpenCV still provides SIFT extractors to this day!\n",
        "1. Dump the resulting representations into your favorite classifier, likely a linear model or kernel method, to train a classifier.\n",
        "\n",
        "If you spoke to machine learning researchers,\n",
        "they would reply that machine learning was both important and beautiful.\n",
        "Elegant theories proved the properties of various classifiers :cite:`boucheron2005theory` and convex\n",
        "optimization :cite:`Boyd.Vandenberghe.2004` had become the mainstay for obtaining them.\n",
        "The field of machine learning was thriving, rigorous, and eminently useful. However,\n",
        "if you spoke to a computer vision researcher,\n",
        "you would hear a very different story.\n",
        "The dirty truth of image recognition, they would tell you,\n",
        "is that features, geometry :cite:`Hartley.Zisserman.2000,hartley2009global`, and engineering,\n",
        "rather than novel learning algorithms, drove progress.\n",
        "Computer vision researchers justifiably believed\n",
        "that a slightly bigger or cleaner dataset\n",
        "or a slightly improved feature-extraction pipeline\n",
        "mattered far more to the final accuracy than any learning algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07938be6",
      "metadata": {
        "id": "07938be6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3425d857",
      "metadata": {
        "id": "3425d857"
      },
      "source": [
        "## Representation Learning\n",
        "\n",
        "Another way to cast the state of affairs is that\n",
        "the most important part of the pipeline was the representation.\n",
        "And up until 2012 the representation was calculated mostly mechanically.\n",
        "In fact, engineering a new set of feature functions, improving results, and writing up the method\n",
        "all featured prominently in papers.\n",
        "SIFT :cite:`Lowe.2004`,\n",
        "SURF :cite:`Bay.Tuytelaars.Van-Gool.2006`,\n",
        "HOG (histograms of oriented gradient) :cite:`Dalal.Triggs.2005`,\n",
        "bags of visual words :cite:`Sivic.Zisserman.2003`,\n",
        "and similar feature extractors ruled the roost.\n",
        "\n",
        "Another group of researchers,\n",
        "including Yann LeCun, Geoff Hinton, Yoshua Bengio,\n",
        "Andrew Ng, Shun-ichi Amari, and Juergen Schmidhuber,\n",
        "had different plans.\n",
        "They believed that features themselves ought to be learned.\n",
        "Moreover, they believed that to be reasonably complex,\n",
        "the features ought to be hierarchically composed\n",
        "with multiple jointly learned layers, each with learnable parameters.\n",
        "In the case of an image, the lowest layers might come\n",
        "to detect edges, colors, and textures, by analogy with how the visual system in animals\n",
        "processes its input. In particular, the automatic design of visual features such as those obtained\n",
        "by sparse coding :cite:`olshausen1996emergence` remained an open challenge until the advent of modern CNNs.\n",
        "It was not until :citet:`Dean.Corrado.Monga.ea.2012,le2013building` that the idea of generating features\n",
        "from image data automatically gained significant traction.\n",
        "\n",
        "The first modern CNN :cite:`Krizhevsky.Sutskever.Hinton.2012`, named\n",
        "*AlexNet* after one of its inventors, Alex Krizhevsky, is largely an evolutionary improvement\n",
        "over LeNet. It achieved excellent performance in the 2012 ImageNet challenge.\n",
        "\n",
        "![Image filters learned by the first layer of AlexNet. Reproduction courtesy of :citet:`Krizhevsky.Sutskever.Hinton.2012`.](https://github.com/d2l-ai/d2l-pytorch-colab/blob/master/img/filters.png?raw=1)\n",
        ":width:`400px`\n",
        ":label:`fig_filters`\n",
        "\n",
        "Interestingly, in the lowest layers of the network,\n",
        "the model learned feature extractors that resembled some traditional filters.\n",
        ":numref:`fig_filters`\n",
        "shows lower-level image descriptors.\n",
        "Higher layers in the network might build upon these representations\n",
        "to represent larger structures, like eyes, noses, blades of grass, and so on.\n",
        "Even higher layers might represent whole objects\n",
        "like people, airplanes, dogs, or frisbees.\n",
        "Ultimately, the final hidden state learns a compact representation\n",
        "of the image that summarizes its contents\n",
        "such that data belonging to different categories can be easily separated.\n",
        "\n",
        "AlexNet (2012) and its precursor LeNet (1995) share many architectural elements. This begs the question: why did it take so long?\n",
        "A key difference was that, over the previous two decades, the amount of data and the computing power available had increased significantly. As such AlexNet was much larger: it was trained on much more data, and on much faster GPUs compared to the CPUs available in 1995.\n",
        "\n",
        "### Missing Ingredient: Data\n",
        "\n",
        "Deep models with many layers require large amounts of data\n",
        "in order to enter the regime\n",
        "where they significantly outperform traditional methods\n",
        "based on convex optimizations (e.g., linear and kernel methods).\n",
        "However, given the limited storage capacity of computers,\n",
        "the relative expense of (imaging) sensors,\n",
        "and the comparatively tighter research budgets in the 1990s,\n",
        "most research relied on tiny datasets.\n",
        "Numerous papers relied on the UCI collection of datasets,\n",
        "many of which contained only hundreds or (a few) thousands of images\n",
        "captured in low resolution and often with an artificially clean background.\n",
        "\n",
        "In 2009, the ImageNet dataset was released :cite:`Deng.Dong.Socher.ea.2009`,\n",
        "challenging researchers to learn models from 1 million examples,\n",
        "1000 each from 1000 distinct categories of objects. The categories themselves\n",
        "were based on the most popular noun nodes in WordNet :cite:`Miller.1995`.\n",
        "The ImageNet team used Google Image Search to prefilter large candidate sets\n",
        "for each category and employed\n",
        "the Amazon Mechanical Turk crowdsourcing pipeline\n",
        "to confirm for each image whether it belonged to the associated category.\n",
        "This scale was unprecedented, exceeding others by over an order of magnitude\n",
        "(e.g., CIFAR-100 has 60,000 images). Another aspect was that the images were at\n",
        "relatively high resolution of $224 \\times 224$ pixels, unlike the 80 million-sized\n",
        "TinyImages dataset :cite:`Torralba.Fergus.Freeman.2008`, consisting of $32 \\times 32$ pixel thumbnails.\n",
        "This allowed for the formation of higher-level features.\n",
        "The associated competition, dubbed the ImageNet Large Scale Visual Recognition\n",
        "Challenge :cite:`russakovsky2015imagenet`,\n",
        "pushed computer vision and machine learning research forward,\n",
        "challenging researchers to identify which models performed best\n",
        "at a greater scale than academics had previously considered. The largest vision datasets, such as LAION-5B\n",
        ":cite:`schuhmann2022laion` contain billions of images with additional metadata.\n",
        "\n",
        "### Missing Ingredient: Hardware\n",
        "\n",
        "Deep learning models are voracious consumers of compute cycles.\n",
        "Training can take hundreds of epochs, and each iteration\n",
        "requires passing data through many layers of computationally expensive\n",
        "linear algebra operations.\n",
        "This is one of the main reasons why in the 1990s and early 2000s,\n",
        "simple algorithms based on the more-efficiently optimized\n",
        "convex objectives were preferred.\n",
        "\n",
        "*Graphical processing units* (GPUs) proved to be a game changer\n",
        "in making deep learning feasible.\n",
        "These chips had earlier been developed for accelerating\n",
        "graphics processing to benefit computer games.\n",
        "In particular, they were optimized for high throughput $4 \\times 4$\n",
        "matrix--vector products, which are needed for many computer graphics tasks.\n",
        "Fortunately, the math is strikingly similar\n",
        "to that required for calculating convolutional layers.\n",
        "Around that time, NVIDIA and ATI had begun optimizing GPUs\n",
        "for general computing operations :cite:`Fernando.2004`,\n",
        "going as far as to market them as *general-purpose GPUs* (GPGPUs).\n",
        "\n",
        "To provide some intuition, consider the cores of a modern microprocessor\n",
        "(CPU).\n",
        "Each of the cores is fairly powerful running at a high clock frequency\n",
        "and sporting large caches (up to several megabytes of L3).\n",
        "Each core is well-suited to executing a wide range of instructions,\n",
        "with branch predictors, a deep pipeline, specialized execution units,\n",
        "speculative execution,\n",
        "and many other bells and whistles\n",
        "that enable it to run a large variety of programs with sophisticated control flow.\n",
        "This apparent strength, however, is also its Achilles heel:\n",
        "general-purpose cores are very expensive to build. They excel at general-purpose\n",
        "code with lots of control flow.\n",
        "This requires lots of chip area, not just for the\n",
        "actual ALU (arithmetic logical unit) where computation happens, but also for\n",
        "all the aforementioned bells and whistles, plus\n",
        "memory interfaces, caching logic between cores,\n",
        "high-speed interconnects, and so on. CPUs are\n",
        "comparatively bad at any single task when compared with dedicated hardware.\n",
        "Modern laptops have 4--8 cores,\n",
        "and even high-end servers rarely exceed 64 cores per socket,\n",
        "simply because it is not cost-effective.\n",
        "\n",
        "By comparison, GPUs can consist of thousands of small processing elements (NIVIDA's latest Ampere chips have up to 6912 CUDA cores), often grouped into larger groups (NVIDIA calls them warps).\n",
        "The details differ somewhat between NVIDIA, AMD, ARM and other chip vendors. While each core is relatively weak,\n",
        "running at about 1GHz clock frequency,\n",
        "it is the total number of such cores that makes GPUs orders of magnitude faster than CPUs.\n",
        "For instance, NVIDIA's recent Ampere A100 GPU offers over 300 TFLOPs per chip for specialized 16-bit precision (BFLOAT16) matrix-matrix multiplications, and up to 20 TFLOPs for more general-purpose floating point operations (FP32).\n",
        "At the same time, floating point performance of CPUs rarely exceeds 1 TFLOPs. For instance, Amazon's Graviton 3  reaches 2 TFLOPs peak performance for 16-bit precision operations, a number similar to the GPU performance of Apple's M1 processor.\n",
        "\n",
        "There are many reasons why GPUs are much faster than CPUs in terms of FLOPs.\n",
        "First, power consumption tends to grow *quadratically* with clock frequency.\n",
        "Hence, for the power budget of a CPU core that runs four times faster (a typical number),\n",
        "you can use 16 GPU cores at $\\frac{1}{4}$ the speed,\n",
        "which yields $16 \\times \\frac{1}{4} = 4$ times the performance.\n",
        "Second, GPU cores are much simpler\n",
        "(in fact, for a long time they were not even *able*\n",
        "to execute general-purpose code),\n",
        "which makes them more energy efficient. For instance, (i) they tend not to support speculative evaluation, (ii) it typically is not possible to program each processing element individually, and (iii) the caches per core tend to be much smaller.\n",
        "Last, many operations in deep learning require high memory bandwidth.\n",
        "Again, GPUs shine here with buses that are at least 10 times as wide as many CPUs.\n",
        "\n",
        "Back to 2012. A major breakthrough came\n",
        "when Alex Krizhevsky and Ilya Sutskever\n",
        "implemented a deep CNN\n",
        "that could run on GPUs.\n",
        "They realized that the computational bottlenecks in CNNs,\n",
        "convolutions and matrix multiplications,\n",
        "are all operations that could be parallelized in hardware.\n",
        "Using two NVIDIA GTX 580s with 3GB of memory, either of which was capable of 1.5 TFLOPs (still a challenge for most CPUs a decade later),\n",
        "they implemented fast convolutions.\n",
        "The [cuda-convnet](https://code.google.com/archive/p/cuda-convnet/) code\n",
        "was good enough that for several years\n",
        "it was the industry standard and powered\n",
        "the first couple of years of the deep learning boom.\n",
        "\n",
        "## AlexNet\n",
        "\n",
        "AlexNet, which employed an 8-layer CNN,\n",
        "won the ImageNet Large Scale Visual Recognition Challenge 2012\n",
        "by a large margin :cite:`Russakovsky.Deng.Huang.ea.2013`.\n",
        "This network showed, for the first time,\n",
        "that the features obtained by learning can transcend manually-designed features, breaking the previous paradigm in computer vision.\n",
        "\n",
        "The architectures of AlexNet and LeNet are strikingly similar,\n",
        "as :numref:`fig_alexnet` illustrates.\n",
        "Note that we provide a slightly streamlined version of AlexNet\n",
        "removing some of the design quirks that were needed in 2012\n",
        "to make the model fit on two small GPUs.\n",
        "\n",
        "![From LeNet (left) to AlexNet (right).](http://d2l.ai/_images/alexnet.svg)\n",
        ":label:`fig_alexnet`\n",
        "\n",
        "There are also significant differences between AlexNet and LeNet.\n",
        "First, AlexNet is much deeper than the comparatively small LeNet-5.\n",
        "AlexNet consists of eight layers: five convolutional layers,\n",
        "two fully connected hidden layers, and one fully connected output layer.\n",
        "Second, AlexNet used the ReLU instead of the sigmoid\n",
        "as its activation function. Let's delve into the details below.\n",
        "\n",
        "### Architecture\n",
        "\n",
        "In AlexNet's first layer, the convolution window shape is $11\\times11$.\n",
        "Since the images in ImageNet are eight times taller and wider\n",
        "than the MNIST images,\n",
        "objects in ImageNet data tend to occupy more pixels with more visual detail.\n",
        "Consequently, a larger convolution window is needed to capture the object.\n",
        "The convolution window shape in the second layer\n",
        "is reduced to $5\\times5$, followed by $3\\times3$.\n",
        "In addition, after the first, second, and fifth convolutional layers,\n",
        "the network adds max-pooling layers\n",
        "with a window shape of $3\\times3$ and a stride of 2.\n",
        "Moreover, AlexNet has ten times more convolution channels than LeNet.\n",
        "\n",
        "After the final convolutional layer, there are two huge fully connected layers\n",
        "with 4096 outputs.\n",
        "These layers require nearly 1GB model parameters.\n",
        "Because of the limited memory in early GPUs,\n",
        "the original AlexNet used a dual data stream design,\n",
        "so that each of their two GPUs could be responsible\n",
        "for storing and computing only its half of the model.\n",
        "Fortunately, GPU memory is comparatively abundant now,\n",
        "so we rarely need to break up models across GPUs these days\n",
        "(our version of the AlexNet model deviates\n",
        "from the original paper in this aspect).\n",
        "\n",
        "### Activation Functions\n",
        "\n",
        "Furthermore, AlexNet changed the sigmoid activation function to a simpler ReLU activation function. On the one hand, the computation of the ReLU activation function is simpler. For example, it does not have the exponentiation operation found in the sigmoid activation function.\n",
        " On the other hand, the ReLU activation function makes model training easier when using different parameter initialization methods. This is because, when the output of the sigmoid activation function is very close to 0 or 1, the gradient of these regions is almost 0, so that backpropagation cannot continue to update some of the model parameters. By contrast, the gradient of the ReLU activation function in the positive interval is always 1 (:numref:`subsec_activation-functions`). Therefore, if the model parameters are not properly initialized, the sigmoid function may obtain a gradient of almost 0 in the positive interval, meaning that the model cannot be effectively trained.\n",
        "\n",
        "### Capacity Control and Preprocessing\n",
        "\n",
        "AlexNet controls the model complexity of the fully connected layer\n",
        "by dropout (:numref:`sec_dropout`),\n",
        "while LeNet only uses weight decay.\n",
        "To augment the data even further, the training loop of AlexNet\n",
        "added a great deal of image augmentation,\n",
        "such as flipping, clipping, and color changes.\n",
        "This makes the model more robust and the larger sample size effectively reduces overfitting.\n",
        "See :citet:`Buslaev.Iglovikov.Khvedchenya.ea.2020` for an in-depth review of such preprocessing steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29feac8e",
      "metadata": {
        "id": "29feac8e"
      },
      "outputs": [],
      "source": [
        "class AlexNet(d2l.Classifier):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(96, kernel_size=11, stride=4, padding=1),\n",
        "            nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.LazyConv2d(256, kernel_size=5, padding=2), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.LazyConv2d(384, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.LazyConv2d(384, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.LazyConv2d(256, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), nn.Flatten(),\n",
        "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
        "            nn.LazyLinear(4096), nn.ReLU(),nn.Dropout(p=0.5),\n",
        "            nn.LazyLinear(num_classes))\n",
        "        self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59e725f1",
      "metadata": {
        "id": "59e725f1"
      },
      "source": [
        "We [**construct a single-channel data example**] with both height and width of 224 (**to observe the output shape of each layer**). It matches the AlexNet architecture in :numref:`fig_alexnet`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d5c2c0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d5c2c0a",
        "outputId": "2aaa870a-0839-4e09-d65e-4078d32b06b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d output shape:\t torch.Size([1, 96, 54, 54])\n",
            "ReLU output shape:\t torch.Size([1, 96, 54, 54])\n",
            "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
            "Conv2d output shape:\t torch.Size([1, 256, 26, 26])\n",
            "ReLU output shape:\t torch.Size([1, 256, 26, 26])\n",
            "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
            "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
            "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
            "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
            "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
            "Conv2d output shape:\t torch.Size([1, 256, 12, 12])\n",
            "ReLU output shape:\t torch.Size([1, 256, 12, 12])\n",
            "MaxPool2d output shape:\t torch.Size([1, 256, 5, 5])\n",
            "Flatten output shape:\t torch.Size([1, 6400])\n",
            "Linear output shape:\t torch.Size([1, 4096])\n",
            "ReLU output shape:\t torch.Size([1, 4096])\n",
            "Dropout output shape:\t torch.Size([1, 4096])\n",
            "Linear output shape:\t torch.Size([1, 4096])\n",
            "ReLU output shape:\t torch.Size([1, 4096])\n",
            "Dropout output shape:\t torch.Size([1, 4096])\n",
            "Linear output shape:\t torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "AlexNet().layer_summary((1, 1, 224, 224))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "193ba4c7",
      "metadata": {
        "id": "193ba4c7"
      },
      "source": [
        "## Training\n",
        "\n",
        "Although AlexNet was trained on ImageNet in :citet:`Krizhevsky.Sutskever.Hinton.2012`,\n",
        "we use Fashion-MNIST here\n",
        "since training an ImageNet model to convergence could take hours or days\n",
        "even on a modern GPU.\n",
        "One of the problems with applying AlexNet directly on [**Fashion-MNIST**]\n",
        "is that its (**images have lower resolution**) ($28 \\times 28$ pixels)\n",
        "(**than ImageNet images.**)\n",
        "To make things work, (**we upsample them to $224 \\times 224$**).\n",
        "This is generally not a smart practice, as it simply increases the computational\n",
        "complexity without adding information. Nonetheless, we do it here to be faithful to the AlexNet architecture.\n",
        "We perform this resizing with the `resize` argument in the `d2l.FashionMNIST` constructor.\n",
        "\n",
        "Now, we can [**start training AlexNet.**]\n",
        "Compared to LeNet in :numref:`sec_lenet`,\n",
        "the main change here is the use of a smaller learning rate\n",
        "and much slower training due to the deeper and wider network,\n",
        "the higher image resolution, and the more costly convolutions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acd6a3e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "acd6a3e0",
        "outputId": "e0b9a21c-a9ee-4ac1-cc91-ad63088d6fe8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-10-05T16:09:30.998878</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 238.965625 183.35625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m46c5ad3d90\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m46c5ad3d90\" x=\"30.103125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.921875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m46c5ad3d90\" x=\"69.163125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(65.981875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m46c5ad3d90\" x=\"108.223125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(105.041875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m46c5ad3d90\" x=\"147.283125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(144.101875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m46c5ad3d90\" x=\"186.343125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(183.161875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m46c5ad3d90\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m87600db9f4\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m87600db9f4\" x=\"30.103125\" y=\"132.50604\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.5 -->\n      <g transform=\"translate(7.2 136.305259) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m87600db9f4\" x=\"30.103125\" y=\"99.488803\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 103.288022) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m87600db9f4\" x=\"30.103125\" y=\"66.471566\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.5 -->\n      <g transform=\"translate(7.2 70.270785) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m87600db9f4\" x=\"30.103125\" y=\"33.454329\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 37.253547) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_11\">\n    <path d=\"M 34.954394 13.5 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 49.633125 13.649402 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_15\"/>\n   <g id=\"line2d_16\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 49.633125 13.649402 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 49.633125 13.649402 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 49.633125 13.649402 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_34\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_35\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_40\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_44\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_45\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_46\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_47\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_48\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_50\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_53\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_54\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_56\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_57\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_58\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_59\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_60\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_61\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_62\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_63\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_64\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_65\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_66\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_67\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_68\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_69\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_70\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_71\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_72\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_73\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_74\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_75\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_76\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_77\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_78\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \nL 147.283125 114.26689 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_79\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \nL 151.884543 126.879707 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_80\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_81\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \nL 147.283125 114.26689 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_82\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \nL 151.884543 126.879707 \nL 161.628722 128.145459 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_83\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_84\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \nL 147.283125 114.26689 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_85\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \nL 151.884543 126.879707 \nL 161.628722 128.145459 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_86\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \nL 166.813125 127.543156 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_87\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \nL 147.283125 114.26689 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_88\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \nL 151.884543 126.879707 \nL 161.628722 128.145459 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_89\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \nL 166.813125 127.543156 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_90\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \nL 147.283125 114.26689 \nL 166.813125 113.620389 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_91\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \nL 151.884543 126.879707 \nL 161.628722 128.145459 \nL 171.372901 130.240556 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_92\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \nL 166.813125 127.543156 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_93\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \nL 147.283125 114.26689 \nL 166.813125 113.620389 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_94\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \nL 151.884543 126.879707 \nL 161.628722 128.145459 \nL 171.372901 130.240556 \nL 181.11708 131.171918 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_95\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \nL 166.813125 127.543156 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_96\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \nL 147.283125 114.26689 \nL 166.813125 113.620389 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_97\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \nL 151.884543 126.879707 \nL 161.628722 128.145459 \nL 171.372901 130.240556 \nL 181.11708 131.171918 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_98\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \nL 166.813125 127.543156 \nL 186.343125 131.451646 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_99\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \nL 147.283125 114.26689 \nL 166.813125 113.620389 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_100\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \nL 151.884543 126.879707 \nL 161.628722 128.145459 \nL 171.372901 130.240556 \nL 181.11708 131.171918 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_101\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \nL 166.813125 127.543156 \nL 186.343125 131.451646 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_102\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \nL 147.283125 114.26689 \nL 166.813125 113.620389 \nL 186.343125 112.124949 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_103\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \nL 151.884543 126.879707 \nL 161.628722 128.145459 \nL 171.372901 130.240556 \nL 181.11708 131.171918 \nL 190.861259 131.88167 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_104\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \nL 166.813125 127.543156 \nL 186.343125 131.451646 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_105\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \nL 147.283125 114.26689 \nL 166.813125 113.620389 \nL 186.343125 112.124949 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_106\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \nL 151.884543 126.879707 \nL 161.628722 128.145459 \nL 171.372901 130.240556 \nL 181.11708 131.171918 \nL 190.861259 131.88167 \nL 200.605438 133.642364 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_107\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \nL 166.813125 127.543156 \nL 186.343125 131.451646 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_108\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \nL 147.283125 114.26689 \nL 166.813125 113.620389 \nL 186.343125 112.124949 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_109\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \nL 151.884543 126.879707 \nL 161.628722 128.145459 \nL 171.372901 130.240556 \nL 181.11708 131.171918 \nL 190.861259 131.88167 \nL 200.605438 133.642364 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_110\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \nL 166.813125 127.543156 \nL 186.343125 131.451646 \nL 205.873125 132.078737 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_111\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \nL 147.283125 114.26689 \nL 166.813125 113.620389 \nL 186.343125 112.124949 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_112\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \nL 151.884543 126.879707 \nL 161.628722 128.145459 \nL 171.372901 130.240556 \nL 181.11708 131.171918 \nL 190.861259 131.88167 \nL 200.605438 133.642364 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_113\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \nL 166.813125 127.543156 \nL 186.343125 131.451646 \nL 205.873125 132.078737 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_114\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \nL 147.283125 114.26689 \nL 166.813125 113.620389 \nL 186.343125 112.124949 \nL 205.873125 112.216373 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_115\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \nL 151.884543 126.879707 \nL 161.628722 128.145459 \nL 171.372901 130.240556 \nL 181.11708 131.171918 \nL 190.861259 131.88167 \nL 200.605438 133.642364 \nL 210.349618 134.794608 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_116\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \nL 166.813125 127.543156 \nL 186.343125 131.451646 \nL 205.873125 132.078737 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_117\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \nL 147.283125 114.26689 \nL 166.813125 113.620389 \nL 186.343125 112.124949 \nL 205.873125 112.216373 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_118\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \nL 151.884543 126.879707 \nL 161.628722 128.145459 \nL 171.372901 130.240556 \nL 181.11708 131.171918 \nL 190.861259 131.88167 \nL 200.605438 133.642364 \nL 210.349618 134.794608 \nL 220.093797 134.890502 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_119\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \nL 166.813125 127.543156 \nL 186.343125 131.451646 \nL 205.873125 132.078737 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_120\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \nL 147.283125 114.26689 \nL 166.813125 113.620389 \nL 186.343125 112.124949 \nL 205.873125 112.216373 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_121\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \nL 151.884543 126.879707 \nL 161.628722 128.145459 \nL 171.372901 130.240556 \nL 181.11708 131.171918 \nL 190.861259 131.88167 \nL 200.605438 133.642364 \nL 210.349618 134.794608 \nL 220.093797 134.890502 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_122\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \nL 166.813125 127.543156 \nL 186.343125 131.451646 \nL 205.873125 132.078737 \nL 225.403125 135.91132 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_123\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \nL 147.283125 114.26689 \nL 166.813125 113.620389 \nL 186.343125 112.124949 \nL 205.873125 112.216373 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_124\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.57343 \nL 54.442752 13.75034 \nL 64.186931 15.843905 \nL 73.93111 81.776225 \nL 83.675289 101.293718 \nL 93.419468 107.521004 \nL 103.163647 111.491949 \nL 112.907826 115.45439 \nL 122.652006 119.102736 \nL 132.396185 121.673227 \nL 142.140364 124.938942 \nL 151.884543 126.879707 \nL 161.628722 128.145459 \nL 171.372901 130.240556 \nL 181.11708 131.171918 \nL 190.861259 131.88167 \nL 200.605438 133.642364 \nL 210.349618 134.794608 \nL 220.093797 134.890502 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_125\">\n    <path d=\"M 49.633125 13.649402 \nL 69.163125 39.765933 \nL 88.693125 100.255113 \nL 108.223125 110.961992 \nL 127.753125 120.854964 \nL 147.283125 125.675376 \nL 166.813125 127.543156 \nL 186.343125 131.451646 \nL 205.873125 132.078737 \nL 225.403125 135.91132 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_126\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 137.651923 \nL 88.693125 124.813337 \nL 108.223125 120.993107 \nL 127.753125 115.945179 \nL 147.283125 114.26689 \nL 166.813125 113.620389 \nL 186.343125 112.124949 \nL 205.873125 112.216373 \nL 225.403125 110.538084 \n\" clip-path=\"url(#pc4193ffd69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 145.8 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 138.8125 60.06875 \nL 218.403125 60.06875 \nQ 220.403125 60.06875 220.403125 58.06875 \nL 220.403125 14.2 \nQ 220.403125 12.2 218.403125 12.2 \nL 138.8125 12.2 \nQ 136.8125 12.2 136.8125 14.2 \nL 136.8125 58.06875 \nQ 136.8125 60.06875 138.8125 60.06875 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_127\">\n     <path d=\"M 140.8125 20.298438 \nL 150.8125 20.298438 \nL 160.8125 20.298438 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- train_loss -->\n     <g transform=\"translate(168.8125 23.798438) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_128\">\n     <path d=\"M 140.8125 35.254688 \nL 150.8125 35.254688 \nL 160.8125 35.254688 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- val_loss -->\n     <g transform=\"translate(168.8125 38.754688) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n    <g id=\"line2d_129\">\n     <path d=\"M 140.8125 50.210938 \nL 150.8125 50.210938 \nL 160.8125 50.210938 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_14\">\n     <!-- val_acc -->\n     <g transform=\"translate(168.8125 53.710938) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc4193ffd69\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = AlexNet(lr=0.01)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(224, 224))\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "trainer.fit(model, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9c33357",
      "metadata": {
        "id": "f9c33357"
      },
      "source": [
        "## Discussion\n",
        "\n",
        "AlexNet's structure bears a striking resemblance to LeNet, with a number of critical improvements, both for accuracy (dropout) and for ease of training (ReLU). What is equally striking is the amount of progress that has been made in terms of deep learning tooling. What was several months of work in 2012 can now be accomplished in a dozen lines of code using any modern framework.\n",
        "\n",
        "Reviewing the architecture, we see that AlexNet has an Achilles heel when it comes to efficiency: the last two hidden layers require matrices of size $6400 \\times 4096$ and $4096 \\times 4096$, respectively. This corresponds to 164 MB of memory and 81 MFLOPs of computation, both of which are a nontrivial outlay, especially on smaller devices, such as mobile phones. This is one of the reasons why AlexNet has been surpassed by much more effective architectures that we will cover in the following sections. Nonetheless, it is a key step from shallow to deep networks that are used nowadays. Note that even though the number of parameters exceeds by far the amount of training data in our experiments (the last two layers have more than 40 million parameters, trained on a datasets of 60 thousand images), there is hardly any overfitting: training and validation loss are virtually identical throughout training. This is due to the improved regularization, such as dropout, inherent in modern deep network designs.\n",
        "\n",
        "Although it seems that there are only a few more lines in AlexNet's implementation than in LeNet's, it took the academic community many years to embrace this conceptual change and take advantage of its excellent experimental results. This was also due to the lack of efficient computational tools. At the time neither DistBelief :cite:`Dean.Corrado.Monga.ea.2012` nor Caffe :cite:`Jia.Shelhamer.Donahue.ea.2014` existed, and Theano :cite:`Bergstra.Breuleux.Bastien.ea.2010` still lacked many distinguishing features. It was the availability of TensorFlow :cite:`Abadi.Barham.Chen.ea.2016` that dramatically changed the situation.\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Following up on the discussion above, analyze the computational properties of AlexNet.\n",
        "    1. Compute the memory footprint for convolutions and fully connected layers, respectively. Which one dominates?\n",
        "    1. Calculate the computational cost for the convolutions and the fully connected layers.\n",
        "    1. How does the memory (read and write bandwidth, latency, size) affect computation? Is there any difference in its effects for training and inference?\n",
        "1. You are a chip designer and need to trade off computation and memory bandwidth. For example, a faster chip requires more power and possibly a larger chip area. More memory bandwidth requires more pins and control logic, thus also more area. How do you optimize?\n",
        "1. Why do engineers no longer report performance benchmarks on AlexNet?\n",
        "1. Try increasing the number of epochs when training AlexNet. Compared with LeNet, how do the results differ? Why?\n",
        "1. AlexNet may be too complex for the Fashion-MNIST dataset, in particular due to the low resolution of the initial images.\n",
        "    1. Try simplifying the model to make the training faster, while ensuring that the accuracy does not drop significantly.\n",
        "    1. Design a better model that works directly on $28 \\times 28$ images.\n",
        "1. Modify the batch size, and observe the changes in throughput (images/s), accuracy, and GPU memory.\n",
        "1. Apply dropout and ReLU to LeNet-5. Does it improve? Can you improve things further by preprocessing to take advantage of the invariances inherent in the images?\n",
        "1. Can you make AlexNet overfit? Which feature do you need to remove or change to break training?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e825ff7",
      "metadata": {
        "id": "3e825ff7"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/76)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DvGVgjaSNzZh",
      "metadata": {
        "id": "DvGVgjaSNzZh"
      },
      "source": [
        "###Answer No. 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o4-dBJYfOTGR",
      "metadata": {
        "id": "o4-dBJYfOTGR"
      },
      "source": [
        "1.1 Compute the memory footprint for convolutions and fully connected layers, respectively. Which one dominates?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mKn3dwq_N2Tk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKn3dwq_N2Tk",
        "outputId": "595d8449-a0e9-424e-dd93-7ae2f3819177"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3747200"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#Rumus dari jumlah parameter konvolusi: ∑layers(c_i∗c_o∗k_h∗k_w+c_o)\n",
        "\n",
        "3*96*11*11+96+96*256*5*5+256+256*384*3*3+384+384*384*3*3+384+384*256*3*3+256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Qrcq1nIuOZA0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qrcq1nIuOZA0",
        "outputId": "1bfa8b85-50c7-48b2-9576-980553fc21d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43040778"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#Rumus dari jumlah parameter fully connected: ∑layers(x_i∗x_o+x_o)\n",
        "80*80*4096+4096+4096*4096+4096+4096*10+10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h45GhDAvPUaj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h45GhDAvPUaj",
        "outputId": "dcbb7553-90f8-44c5-88d9-a5423c1bb110"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conv': 3747200, 'lr': 43040778}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model = AlexNet()\n",
        "X = torch.randn(1,3, 224, 224)\n",
        "_ = model(X)\n",
        "params = {'conv':0, 'lr':0}\n",
        "for idx, module in enumerate(model.net):\n",
        "    if type(module) not in (nn.Linear,nn.Conv2d):\n",
        "        continue\n",
        "    num = sum(p.numel() for p in module.parameters())\n",
        "    # print(f\"Module {idx + 1}: {num} parameters type:{type(module)}\")\n",
        "    if type(module) == nn.Conv2d:\n",
        "        params['conv'] += num\n",
        "\n",
        "    else:\n",
        "        params['lr'] += num\n",
        "\n",
        "params"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aqTnaAIHO8zK",
      "metadata": {
        "id": "aqTnaAIHO8zK"
      },
      "source": [
        "Sehingga, lapisan fully connected memiliki julah parameter yang lebih banyak"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FzNZQS6NPMHO",
      "metadata": {
        "id": "FzNZQS6NPMHO"
      },
      "source": [
        "1.2 Calculate the computational cost for the convolutions and the fully connected layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bxMNpROcO7yL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxMNpROcO7yL",
        "outputId": "6fcbe9b1-6a65-4d84-81c3-be480390859d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "962858112"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Rumus dari computational cost untuk konvolusi: ∑layers(c_i∗c_o∗k_h∗k_w∗h_o∗w_o)\n",
        "\n",
        "3*96*11*11*54*54+96*256*5*5*26*26+256*384*3*3*12*12+384*384*3*3*12*12+384*256*3*3*12*12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xoD6D1mbP_IB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoD6D1mbP_IB",
        "outputId": "f1178744-f0b5-45b3-9112-f2cd91f9bc95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43040778"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Rumus dari omputational cost untuk lapisan fully connected: ∑layers(xi∗xo+xo)\n",
        "\n",
        "80*80*4096+4096+4096*4096+4096+4096*10+10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ipAoDauQI7_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ipAoDauQI7_",
        "outputId": "aa3ddeac-705f-4e09-c2f1-e06c09ec7b4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conv': 962858112, 'lr': 43040778}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "x = torch.randn(1,3, 224, 224)\n",
        "params = {'conv':0, 'lr':0}\n",
        "for idx, module in enumerate(model.net):\n",
        "    c_i = x.shape[1]\n",
        "    x = module(x)\n",
        "    if type(module) == nn.Conv2d:\n",
        "        k = [p.shape for p in module.parameters()]\n",
        "        c_o,h_o,w_o = x.shape[1], x.shape[2], x.shape[3]\n",
        "        params['conv'] += c_i*c_o*h_o*w_o*k[0][-1]*k[0][-2]\n",
        "    if type(module) == nn.Linear:\n",
        "        params['lr'] += sum(p.numel() for p in module.parameters())\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-zdIIhyEQKqV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zdIIhyEQKqV",
        "outputId": "d3b3539a-d29b-4ef2-ff25-83a4e8d490f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 46787978\n"
          ]
        }
      ],
      "source": [
        "X = torch.randn(1,3, 224, 224)\n",
        "_ = model(X)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(\"Total parameters:\", total_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KwFEL34YQOlJ",
      "metadata": {
        "id": "KwFEL34YQOlJ"
      },
      "source": [
        "1.3 How does the memory (read and write bandwidth, latency, size) affect computation? Is there any difference in its effects for training and inference?\n",
        "\n",
        "\n",
        "Faktor-faktor seperti memori, bandwidth, latensi, dan ukuran memori berpengaruh pada kinerja, efisiensi, dan kecepatan komputasi. Berikut adalah pengaruh aspek-aspek memori tersebut terhadap komputasi:\n",
        "\n",
        "\n",
        "*   Bandwidth yang tinggi mempercepat perpindahan data antara memori dan unit pemrosesan\n",
        "*   Latensi yang rendah memungkinkan akses data yang lebih cepat, mempercepat perhitungan.\n",
        "*   Memori yang besar mengurangi perpindahan data yang sering dilakukan, memungkinkan kinerja yang lebih baik.\n",
        "\n",
        "Perbedaan pelatihan dan inferensi:\n",
        "\n",
        "\n",
        "*   Dalam pelatihan, bandwidth memori sangat penting karena pembaruan bobot dan gradien yang sering.\n",
        "*   Dalam inferensi, latensi rendah dan bandwidth tinggi lebih difokuskan, terutama untuk aplikasi real-time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qT0v14N0RaZ3",
      "metadata": {
        "id": "qT0v14N0RaZ3"
      },
      "source": [
        "###Answer No. 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iDmec6qQRfvr",
      "metadata": {
        "id": "iDmec6qQRfvr"
      },
      "source": [
        "2. You are a chip designer and need to trade off computation and memory bandwidth. For example, a faster chip requires more power and possibly a larger chip area. More memory bandwidth requires more pins and control logic, thus also more area. How do you optimize?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0nukNnfR1Cr",
      "metadata": {
        "id": "e0nukNnfR1Cr"
      },
      "source": [
        "Mengoptimalkan trade-off antara komputasi dan bandwidth memori dalam desain chip dimulai dengan menetapkan tujuan kinerja sesuai kebutuhan aplikasi. Beban kerja dianalisis untuk memahami pola akses memori, lalu arsitektur yang seimbang antara komputasi dan memori dieksplorasi, termasuk desain hierarki memori yang efisien. Efisiensi daya ditingkatkan melalui teknik hemat energi, sementara ruang chip dioptimalkan dengan integrasi memori dekat unit komputasi untuk mengurangi latensi. Bandwidth memori ditingkatkan dengan bus lebar dan antarmuka cepat, serta paralelisme dan pipelining digunakan untuk mengurangi dampak latensi. Desain kemudian divalidasi melalui simulasi dan pengujian."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GzWjIIoaSKh3",
      "metadata": {
        "id": "GzWjIIoaSKh3"
      },
      "source": [
        "###Answer No. 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jBbRb6csSQ6d",
      "metadata": {
        "id": "jBbRb6csSQ6d"
      },
      "source": [
        "3. Why do engineers no longer report performance benchmarks on AlexNet?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daos_7d_SgVQ",
      "metadata": {
        "id": "daos_7d_SgVQ"
      },
      "source": [
        "Engineer tidak lagi menggunakan AlexNet sebagai benchmark karena beberapa alasan.\n",
        "\n",
        "AlexNet diperkenalkan pada 2012 dan kini dianggap ketinggalan zaman dibandingkan dengan arsitektur yang lebih baru, seperti VGG, ResNet, dan Transformer-based models (BERT, GPT), dimana model-model ini lebih efisien dan akurat.\n",
        "\n",
        "Penelitian juga telah berkembang, dan kini para peneliti sering menguji model di berbagai tugas dan dataset untuk memastikan kinerja di berbagai skenario, bukan hanya satu benchmark.\n",
        "\n",
        "Selain itu, fokus telah beralih ke aplikasi dunia nyata, seperti analisis gambar medis atau pemahaman bahasa alami, sehingga penggunaan AlexNet untuk benchmarking berkurang.\n",
        "\n",
        "Perubahan perangkat keras dan perangkat lunak juga mempengaruhi tolok ukur, dengan model baru lebih dioptimalkan untuk teknologi terbaru. Akhirnya, arah penelitian kini lebih fokus pada interpretabilitas, ketahanan, dan keadilan model daripada tolok ukur model lama seperti AlexNet."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EYmhhpM1S8zm",
      "metadata": {
        "id": "EYmhhpM1S8zm"
      },
      "source": [
        "###Answer No. 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dP6AVAPvS-Y_",
      "metadata": {
        "id": "dP6AVAPvS-Y_"
      },
      "source": [
        "4. Try increasing the number of epochs when training AlexNet. Compared with LeNet, how do the results differ? Why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6MQLRhAiQMQz",
      "metadata": {
        "id": "6MQLRhAiQMQz"
      },
      "outputs": [],
      "source": [
        "model = AlexNet(lr=0.01)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(224, 224))\n",
        "trainer = d2l.Trainer(max_epochs=20)\n",
        "trainer.fit(model, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vigkB_sgobtI",
      "metadata": {
        "id": "vigkB_sgobtI"
      },
      "source": [
        "Hasil pelatihan AlexNet dengan menambah jumlah epoch umumnya lebih baik dibandingkan LeNet karena AlexNet memiliki arsitektur yang lebih dalam dan kompleks, memungkinkan model menangkap fitur yang lebih mendetail. Namun, AlexNet membutuhkan lebih banyak data dan waktu pelatihan karena jumlah parameter yang lebih besar, sementara LeNet lebih sederhana dan lebih cepat dilatih, tetapi kinerjanya lebih terbatas pada tugas yang lebih kompleks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E8uiFTFFofJb",
      "metadata": {
        "id": "E8uiFTFFofJb"
      },
      "source": [
        "###Answer No. 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xSua_ewcohWL",
      "metadata": {
        "id": "xSua_ewcohWL"
      },
      "source": [
        "5. AlexNet may be too complex for the Fashion-MNIST dataset, in particular due to the low resolution of the initial images.\n",
        "\n",
        "5.1 Try simplifying the model to make the training faster, while ensuring that the accuracy does not drop significantly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fJBdfSFfpAY6",
      "metadata": {
        "id": "fJBdfSFfpAY6"
      },
      "source": [
        "Untuk menyederhanakan AlexNet agar lebih cocok dengan dataset Fashion-MNIST, kita bisa mengurangi jumlah lapisan konvolusi atau neuron pada fully connected layer, serta mengurangi ukuran filter. Selain itu, kita dapat mengurangi jumlah parameter dengan menurunkan ukuran batch atau menggunakan regularisasi seperti dropout. Hal ini dapat mempercepat pelatihan tanpa mengorbankan akurasi secara signifikan."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TElDhQhtpDEg",
      "metadata": {
        "id": "TElDhQhtpDEg"
      },
      "source": [
        "5.2 Design a better model that works directly on 28×28 images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4mwaInauyrJt",
      "metadata": {
        "id": "4mwaInauyrJt"
      },
      "outputs": [],
      "source": [
        "class SmallAlexnet(d2l.Classifier):\n",
        "    def __init__(self,lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(256, kernel_size=3, padding=1),nn.ReLU(),\n",
        "            nn.LazyConv2d(256, kernel_size=3, padding=1),nn.ReLU(),\n",
        "            nn.LazyConv2d(256, kernel_size=3, padding=1),nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.LazyConv2d(512, kernel_size=3, padding=1),nn.ReLU(),\n",
        "            nn.LazyConv2d(512, kernel_size=3, padding=1),nn.ReLU(),\n",
        "            nn.LazyConv2d(256, kernel_size=3, padding=1),nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), nn.Flatten(),\n",
        "            nn.LazyLinear(1024), nn.ReLU(),\n",
        "            nn.LazyLinear(num_classes)\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "igm1sdOByzHR",
      "metadata": {
        "id": "igm1sdOByzHR"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RF5mCBW5qT-G",
      "metadata": {
        "id": "RF5mCBW5qT-G"
      },
      "source": [
        "###Answer No. 6"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FCNi4yCuqVvg",
      "metadata": {
        "id": "FCNi4yCuqVvg"
      },
      "source": [
        "6. Modify the batch size, and observe the changes in throughput (images/s), accuracy, and GPU memory."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aA0CmIezrFm2",
      "metadata": {
        "id": "aA0CmIezrFm2"
      },
      "source": [
        "###Answer No. 7"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SDZKgsgBrKMt",
      "metadata": {
        "id": "SDZKgsgBrKMt"
      },
      "source": [
        "Apply dropout and ReLU to LeNet-5. Does it improve? Can you improve things further by preprocessing to take advantage of the invariances inherent in the images?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uemLqtYay6Rs",
      "metadata": {
        "id": "uemLqtYay6Rs"
      },
      "outputs": [],
      "source": [
        "class LeNet(d2l.Classifier):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(nn.LazyConv2d(6, kernel_size=5, padding=2),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                                 nn.LazyConv2d(16, kernel_size=5),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                                 nn.Flatten(),\n",
        "                                 nn.LazyLinear(120),\n",
        "                                 nn.ReLU(), nn.Dropout(0.5),\n",
        "                                 nn.LazyLinear(84),\n",
        "                                 nn.ReLU(), nn.Dropout(0.5),\n",
        "                                 nn.LazyLinear(num_classes))\n",
        "model = LeNet(lr=0.01)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(28, 28))\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "trainer.fit(model, data)\n",
        "X,y = next(iter(data.get_dataloader(False)))\n",
        "X = X.to('cuda')\n",
        "y = y.to('cuda')\n",
        "y_hat = model(X)\n",
        "print(f'acc: {model.accuracy(y_hat,y).item():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4vqGElSHrLYe",
      "metadata": {
        "id": "4vqGElSHrLYe"
      },
      "source": [
        "###Answer No. 8"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9LYgdoUCrPSk",
      "metadata": {
        "id": "9LYgdoUCrPSk"
      },
      "source": [
        "Can you make AlexNet overfit? Which feature do you need to remove or change to break training?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "esIPsSicsHH8",
      "metadata": {
        "id": "esIPsSicsHH8"
      },
      "source": [
        "AlexNet dapat overfit apabila beberapa fitur dimodifikasi saat proses pelatihan. Beberapa hal yang dapat dilakukan untuk membuat AlexNet overfit antara lain mengurangi ukuran dataset pelatihan secara signifikan, membuat model yang lebih kompleks (menambahkan layer, unit, atau filter), menggunakan learning rate yang sangat kecil, dan mengurangi augmentasi data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T_QeWTQAsytu",
      "metadata": {
        "id": "T_QeWTQAsytu"
      },
      "source": [
        "#8.2 Networks Using Blocks (VGG)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c884009",
      "metadata": {
        "id": "7c884009"
      },
      "source": [
        "## (**VGG Blocks**)\n",
        ":label:`subsec_vgg-blocks`\n",
        "\n",
        "The basic building block of CNNs\n",
        "is a sequence of the following:\n",
        "(i) a convolutional layer\n",
        "with padding to maintain the resolution,\n",
        "(ii) a nonlinearity such as a ReLU,\n",
        "(iii) a pooling layer such\n",
        "as max-pooling to reduce the resolution. One of the problems with\n",
        "this approach is that the spatial resolution decreases quite rapidly. In particular,\n",
        "this imposes a hard limit of $\\log_2 d$ convolutional layers on the network before all\n",
        "dimensions ($d$) are used up. For instance, in the case of ImageNet, it would be impossible to have\n",
        "more than 8 convolutional layers in this way.\n",
        "\n",
        "The key idea of :citet:`Simonyan.Zisserman.2014` was to use *multiple* convolutions in between downsampling\n",
        "via max-pooling in the form of a block. They were primarily interested in whether deep or\n",
        "wide networks perform better. For instance, the successive application of two $3 \\times 3$ convolutions\n",
        "touches the same pixels as a single $5 \\times 5$ convolution does. At the same time, the latter uses approximately\n",
        "as many parameters ($25 \\cdot c^2$) as three $3 \\times 3$ convolutions do ($3 \\cdot 9 \\cdot c^2$).\n",
        "In a rather detailed analysis they showed that deep and narrow networks significantly outperform their shallow counterparts. This set deep learning on a quest for ever deeper networks with over 100 layers for typical applications.\n",
        "Stacking $3 \\times 3$ convolutions\n",
        "has become a gold standard in later deep networks (a design decision only to be revisited recently by\n",
        ":citet:`liu2022convnet`). Consequently, fast implementations for small convolutions have become a staple on GPUs :cite:`lavin2016fast`.\n",
        "\n",
        "Back to VGG: a VGG block consists of a *sequence* of convolutions with $3\\times3$ kernels with padding of 1\n",
        "(keeping height and width) followed by a $2 \\times 2$ max-pooling layer with stride of 2\n",
        "(halving height and width after each block).\n",
        "In the code below, we define a function called `vgg_block`\n",
        "to implement one VGG block.\n",
        "\n",
        "The function below takes two arguments,\n",
        "corresponding to the number of convolutional layers `num_convs`\n",
        "and the number of output channels `num_channels`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a35971a",
      "metadata": {
        "id": "7a35971a"
      },
      "outputs": [],
      "source": [
        "def vgg_block(num_convs, out_channels):\n",
        "    layers = []\n",
        "    for _ in range(num_convs):\n",
        "        layers.append(nn.LazyConv2d(out_channels, kernel_size=3, padding=1))\n",
        "        layers.append(nn.ReLU())\n",
        "    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c267659",
      "metadata": {
        "id": "6c267659"
      },
      "source": [
        "## [**VGG Network**]\n",
        ":label:`subsec_vgg-network`\n",
        "\n",
        "Like AlexNet and LeNet,\n",
        "the VGG Network can be partitioned into two parts:\n",
        "the first consisting mostly of convolutional and pooling layers\n",
        "and the second consisting of fully connected layers that are identical to those in AlexNet.\n",
        "The key difference is\n",
        "that the convolutional layers are grouped in nonlinear transformations that\n",
        "leave the dimensonality unchanged, followed by a resolution-reduction step, as\n",
        "depicted in :numref:`fig_vgg`.\n",
        "\n",
        "![From AlexNet to VGG. The key difference is that VGG consists of blocks of layers, whereas AlexNet's layers are all designed individually.](http://d2l.ai/_images/vgg.svg)\n",
        ":width:`400px`\n",
        ":label:`fig_vgg`\n",
        "\n",
        "The convolutional part of the network connects several VGG blocks from :numref:`fig_vgg` (also defined in the `vgg_block` function)\n",
        "in succession. This grouping of convolutions is a pattern that has\n",
        "remained almost unchanged over the past decade, although the specific choice of\n",
        "operations has undergone considerable modifications.\n",
        "The variable `arch` consists of a list of tuples (one per block),\n",
        "where each contains two values: the number of convolutional layers\n",
        "and the number of output channels,\n",
        "which are precisely the arguments required to call\n",
        "the `vgg_block` function. As such, VGG defines a *family* of networks rather than just\n",
        "a specific manifestation. To build a specific network we simply iterate over `arch` to compose the blocks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35ed8ba4",
      "metadata": {
        "id": "35ed8ba4"
      },
      "outputs": [],
      "source": [
        "class VGG(d2l.Classifier):\n",
        "    def __init__(self, arch, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        conv_blks = []\n",
        "        for (num_convs, out_channels) in arch:\n",
        "            conv_blks.append(vgg_block(num_convs, out_channels))\n",
        "        self.net = nn.Sequential(\n",
        "            *conv_blks, nn.Flatten(),\n",
        "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
        "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
        "            nn.LazyLinear(num_classes))\n",
        "        self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4413c3f",
      "metadata": {
        "id": "f4413c3f"
      },
      "source": [
        "The original VGG network had five convolutional blocks,\n",
        "among which the first two have one convolutional layer each\n",
        "and the latter three contain two convolutional layers each.\n",
        "The first block has 64 output channels\n",
        "and each subsequent block doubles the number of output channels,\n",
        "until that number reaches 512.\n",
        "Since this network uses eight convolutional layers\n",
        "and three fully connected layers, it is often called VGG-11.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc110465",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc110465",
        "outputId": "14cf4ebd-d7ad-4824-c46c-350ba2e09457"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential output shape:\t torch.Size([1, 64, 112, 112])\n",
            "Sequential output shape:\t torch.Size([1, 128, 56, 56])\n",
            "Sequential output shape:\t torch.Size([1, 256, 28, 28])\n",
            "Sequential output shape:\t torch.Size([1, 512, 14, 14])\n",
            "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
            "Flatten output shape:\t torch.Size([1, 25088])\n",
            "Linear output shape:\t torch.Size([1, 4096])\n",
            "ReLU output shape:\t torch.Size([1, 4096])\n",
            "Dropout output shape:\t torch.Size([1, 4096])\n",
            "Linear output shape:\t torch.Size([1, 4096])\n",
            "ReLU output shape:\t torch.Size([1, 4096])\n",
            "Dropout output shape:\t torch.Size([1, 4096])\n",
            "Linear output shape:\t torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "VGG(arch=((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))).layer_summary(\n",
        "    (1, 1, 224, 224))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb49027b",
      "metadata": {
        "id": "cb49027b"
      },
      "source": [
        "As you can see, we halve height and width at each block,\n",
        "finally reaching a height and width of 7\n",
        "before flattening the representations\n",
        "for processing by the fully connected part of the network.\n",
        ":citet:`Simonyan.Zisserman.2014` described several other variants of VGG.\n",
        "In fact, it has become the norm to propose *families* of networks with\n",
        "different speed--accuracy trade-off when introducing a new architecture.\n",
        "\n",
        "## Training\n",
        "\n",
        "[**Since VGG-11 is computationally more demanding than AlexNet\n",
        "we construct a network with a smaller number of channels.**]\n",
        "This is more than sufficient for training on Fashion-MNIST.\n",
        "The [**model training**] process is similar to that of AlexNet in :numref:`sec_alexnet`.\n",
        "Again observe the close match between validation and training loss,\n",
        "suggesting only a small amount of overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xucXcRoz0pNi",
      "metadata": {
        "id": "xucXcRoz0pNi"
      },
      "outputs": [],
      "source": [
        "model = VGG(arch=((1, 16), (1, 32), (2, 64), (2, 128), (2, 128)), lr=0.01)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(224, 224))\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oPPoAQIK0qve",
      "metadata": {
        "id": "oPPoAQIK0qve"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "157480ef",
      "metadata": {
        "id": "157480ef"
      },
      "source": [
        "## Summary\n",
        "\n",
        "One might argue that VGG is the first truly modern convolutional neural network. While AlexNet introduced many of the components of what make deep learning effective at scale, it is VGG that arguably introduced key properties such as blocks of multiple convolutions and a preference for deep and narrow networks. It is also the first network that is actually an entire family of similarly parametrized models, giving the practitioner ample trade-off between complexity and speed. This is also the place where modern deep learning frameworks shine. It is no longer necessary to generate XML configuration files to specify a network but rather, to assemble said networks through simple Python code.\n",
        "\n",
        "More recently ParNet :cite:`Goyal.Bochkovskiy.Deng.ea.2021` demonstrated that it is possible to achieve competitive performance using a much more shallow architecture through a large number of parallel computations. This is an exciting development and there is hope that it will influence architecture designs in the future. For the remainder of the chapter, though, we will follow the path of scientific progress over the past decade.\n",
        "\n",
        "## Exercises\n",
        "\n",
        "\n",
        "1. Compared with AlexNet, VGG is much slower in terms of computation, and it also needs more GPU memory.\n",
        "    1. Compare the number of parameters needed for AlexNet and VGG.\n",
        "    1. Compare the number of floating point operations used in the convolutional layers and in the fully connected layers.\n",
        "    1. How could you reduce the computational cost created by the fully connected layers?\n",
        "1. When displaying the dimensions associated with the various layers of the network, we only see the information associated with eight blocks (plus some auxiliary transforms), even though the network has 11 layers. Where did the remaining three layers go?\n",
        "1. Use Table 1 in the VGG paper :cite:`Simonyan.Zisserman.2014` to construct other common models, such as VGG-16 or VGG-19.\n",
        "1. Upsampling the resolution in Fashion-MNIST eight-fold from $28 \\times 28$ to $224 \\times 224$ dimensions is very wasteful. Try modifying the network architecture and resolution conversion, e.g., to 56 or to 84 dimensions for its input instead. Can you do so without reducing the accuracy of the network? Consult the VGG paper :cite:`Simonyan.Zisserman.2014` for ideas on adding more nonlinearities prior to downsampling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ogkxs92zzdyJ",
      "metadata": {
        "id": "ogkxs92zzdyJ"
      },
      "source": [
        "No 1."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fyHos61czsHE",
      "metadata": {
        "id": "fyHos61czsHE"
      },
      "source": [
        "1.1 Compare the number of parameters needed for AlexNet and VGG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1DHRUCkf0BYe",
      "metadata": {
        "id": "1DHRUCkf0BYe"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YmlTVyCG0aJr",
      "metadata": {
        "id": "YmlTVyCG0aJr"
      },
      "outputs": [],
      "source": [
        "def stat_params(net, params):\n",
        "    for idx, module in enumerate(net):\n",
        "        if type(module) not in (nn.Linear,nn.Conv2d):\n",
        "            continue\n",
        "        num = sum(p.numel() for p in module.parameters())\n",
        "        if type(module) == nn.Conv2d:\n",
        "            params['conv'] += num\n",
        "        else:\n",
        "            params['lr'] += num\n",
        "\n",
        "def stat_comp(net, params, x):\n",
        "    for idx, module in enumerate(net):\n",
        "        c_i = x.shape[1]\n",
        "        x = module(x)\n",
        "        if type(module) == nn.Conv2d:\n",
        "            k = [p.shape for p in module.parameters()]\n",
        "            c_o,h_o,w_o = x.shape[1], x.shape[2], x.shape[3]\n",
        "            params['conv'] += c_i*c_o*h_o*w_o*k[0][-1]*k[0][-2]\n",
        "        if type(module) == nn.Linear:\n",
        "            params['lr'] += sum(p.numel() for p in module.parameters())\n",
        "    return x\n",
        "\n",
        "\n",
        "def vgg_block(num_convs, out_channels):\n",
        "    layers = []\n",
        "    for _ in range(num_convs):\n",
        "        layers.append(nn.LazyConv2d(out_channels, kernel_size=3, padding=1))\n",
        "        layers.append(nn.ReLU())\n",
        "    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class VGG(d2l.Classifier):\n",
        "    def __init__(self, arch, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        conv_blks = []\n",
        "        for (num_convs, out_channels) in arch:\n",
        "            conv_blks.append(vgg_block(num_convs, out_channels))\n",
        "        self.net = nn.Sequential(*conv_blks, nn.Flatten(),\n",
        "                                 nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
        "                                 nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
        "                                 nn.LazyLinear(num_classes))\n",
        "        self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bx8ZXmKfTSdQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx8ZXmKfTSdQ",
        "outputId": "1cb2d5b0-52fa-4cbc-8350-d277cf2ae94e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "              ReLU-2         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-3         [-1, 64, 112, 112]               0\n",
            "            Conv2d-4        [-1, 128, 112, 112]          73,856\n",
            "              ReLU-5        [-1, 128, 112, 112]               0\n",
            "         MaxPool2d-6          [-1, 128, 56, 56]               0\n",
            "            Conv2d-7          [-1, 256, 56, 56]         295,168\n",
            "              ReLU-8          [-1, 256, 56, 56]               0\n",
            "            Conv2d-9          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-10          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-11          [-1, 256, 28, 28]               0\n",
            "           Conv2d-12          [-1, 512, 28, 28]       1,180,160\n",
            "             ReLU-13          [-1, 512, 28, 28]               0\n",
            "           Conv2d-14          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-15          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-16          [-1, 512, 14, 14]               0\n",
            "           Conv2d-17          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-18          [-1, 512, 14, 14]               0\n",
            "           Conv2d-19          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-20          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-21            [-1, 512, 7, 7]               0\n",
            "          Flatten-22                [-1, 25088]               0\n",
            "           Linear-23                 [-1, 4096]     102,764,544\n",
            "             ReLU-24                 [-1, 4096]               0\n",
            "          Dropout-25                 [-1, 4096]               0\n",
            "           Linear-26                 [-1, 4096]      16,781,312\n",
            "             ReLU-27                 [-1, 4096]               0\n",
            "          Dropout-28                 [-1, 4096]               0\n",
            "           Linear-29                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 128,807,306\n",
            "Trainable params: 128,807,306\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 125.37\n",
            "Params size (MB): 491.36\n",
            "Estimated Total Size (MB): 617.30\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'conv': 9220480, 'lr': 119586826}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arch=((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))\n",
        "vgg = VGG(arch=arch)\n",
        "X = torch.randn(1,3, 224, 224)\n",
        "_ = vgg(X)\n",
        "params = {'conv':0, 'lr':0}\n",
        "for idx, module in enumerate(vgg.net):\n",
        "    if type(module) == nn.Sequential:\n",
        "        stat_params(module,params)\n",
        "    if type(module) == nn.Linear:\n",
        "        num = sum(p.numel() for p in module.parameters())\n",
        "        params['lr'] += num\n",
        "summary(vgg, (3, 224, 224))\n",
        "params"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q0zYOwFe1BFq",
      "metadata": {
        "id": "Q0zYOwFe1BFq"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9HSOkfUl04r0",
      "metadata": {
        "id": "9HSOkfUl04r0"
      },
      "source": [
        "1.2 Compare the number of floating point operations used in the convolutional layers and in the fully connected layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YCEKPfU006IV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCEKPfU006IV",
        "outputId": "afe07b42-ab20-48a6-d709-120e2a278bac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'conv': 7485456384, 'lr': 119586826}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.randn(1,3, 224, 224)\n",
        "params = {'conv':0, 'lr':0}\n",
        "for idx, module in enumerate(vgg.net):\n",
        "    if type(module) == nn.Sequential:\n",
        "        x = stat_comp(module, params, x)\n",
        "    if type(module) == nn.Linear:\n",
        "        params['lr'] += sum(p.numel() for p in module.parameters())\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NFHAvfYF1EwZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFHAvfYF1EwZ",
        "outputId": "25d07559-7c56-4296-86e0-d489bf72042f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameters: 128807306\n"
          ]
        }
      ],
      "source": [
        "X = torch.randn(1,3, 224, 224)\n",
        "_ = vgg(X)\n",
        "total_params = sum(p.numel() for p in vgg.parameters())\n",
        "print(\"Total parameters:\", total_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0mfNMNCq1IPX",
      "metadata": {
        "id": "0mfNMNCq1IPX"
      },
      "source": [
        "1.3 How could you reduce the computational cost created by the fully connected layers?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2KK0IPPy1la3",
      "metadata": {
        "id": "2KK0IPPy1la3"
      },
      "source": [
        "Untuk mengurangi biaya komputasi yang dihasilkan oleh fully connected layers, beberapa strategi dapat diterapkan. Salah satunya adalah menggunakan Global Average Pooling (GAP), yang menghitung rata-rata setiap fitur dan menggantikan fully connected layers di akhir jaringan, mengurangi jumlah parameter secara signifikan. Selain itu, mengganti fully connected layers dengan convolutional layers berukuran kernel 1x1 juga bisa menurunkan jumlah parameter tanpa mengorbankan performa. Network pruning juga bisa dilakukan untuk memangkas koneksi atau neuron yang tidak penting, mengurangi parameter sambil mempertahankan akurasi. Pendekatan lain termasuk low-rank approximations, yang menggunakan matriks dengan peringkat lebih rendah untuk mempercepat komputasi, serta kuantisasi untuk mengurangi presisi komputasi dan memori. Model compression dan knowledge distillation juga membantu memperkecil ukuran model dan mengurangi kompleksitas komputasi tanpa kehilangan performa yang signifikan."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ly5Ez2w82Cfv",
      "metadata": {
        "id": "ly5Ez2w82Cfv"
      },
      "source": [
        " No. 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dssuzFeK2HTh",
      "metadata": {
        "id": "dssuzFeK2HTh"
      },
      "source": [
        "When displaying the dimensions associated with the various layers of the network, we only see the information associated with eight blocks (plus some auxiliary transforms), even though the network has 11 layers. Where did the remaining three layers go?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a258vHy02iON",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a258vHy02iON",
        "outputId": "fb2955a9-6000-489c-f245-7552ee8af893"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (net): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (5): Flatten(start_dim=1, end_dim=-1)\n",
              "    (6): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Dropout(p=0.5, inplace=False)\n",
              "    (9): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (10): ReLU()\n",
              "    (11): Dropout(p=0.5, inplace=False)\n",
              "    (12): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vgg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1Qn3h6O2TFG",
      "metadata": {
        "id": "e1Qn3h6O2TFG"
      },
      "source": [
        "Blok konvolusi dianggap sebagai satu lapisan dalam jaringan, dan tiga blok konvolusi terakhir di VGG masing-masing terdiri dari dua lapisan konvolusi, yang merupakan tiga lapisan yang tersisa."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mFBCwlq22WAZ",
      "metadata": {
        "id": "mFBCwlq22WAZ"
      },
      "source": [
        " No. 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tEQk_8y22dnL",
      "metadata": {
        "id": "tEQk_8y22dnL"
      },
      "source": [
        "Use Table 1 in the VGG paper (Simonyan and Zisserman, 2014) to construct other common models, such as VGG-16 or VGG-19."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oMZdUwS51GfT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMZdUwS51GfT",
        "outputId": "9f612cab-cb5c-4185-c9c0-39d58da710f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (net): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): LazyConv2d(0, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): LazyConv2d(0, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (5): ReLU()\n",
              "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (5): ReLU()\n",
              "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (5): ReLU()\n",
              "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (5): Flatten(start_dim=1, end_dim=-1)\n",
              "    (6): LazyLinear(in_features=0, out_features=4096, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Dropout(p=0.5, inplace=False)\n",
              "    (9): LazyLinear(in_features=0, out_features=4096, bias=True)\n",
              "    (10): ReLU()\n",
              "    (11): Dropout(p=0.5, inplace=False)\n",
              "    (12): LazyLinear(in_features=0, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arch16=((2, 64), (2, 128), (3, 256), (3, 512), (3, 512))\n",
        "vgg16 = VGG(arch=arch16)\n",
        "vgg16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jNIgPNup2gAW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNIgPNup2gAW",
        "outputId": "d926aa1b-3980-458d-da1d-0b9eb5b595b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (net): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): LazyConv2d(0, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): LazyConv2d(0, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (5): ReLU()\n",
              "      (6): LazyConv2d(0, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (7): ReLU()\n",
              "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (5): ReLU()\n",
              "      (6): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (7): ReLU()\n",
              "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (5): ReLU()\n",
              "      (6): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (7): ReLU()\n",
              "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (5): Flatten(start_dim=1, end_dim=-1)\n",
              "    (6): LazyLinear(in_features=0, out_features=4096, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Dropout(p=0.5, inplace=False)\n",
              "    (9): LazyLinear(in_features=0, out_features=4096, bias=True)\n",
              "    (10): ReLU()\n",
              "    (11): Dropout(p=0.5, inplace=False)\n",
              "    (12): LazyLinear(in_features=0, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arch19=((2, 64), (2, 128), (4, 256), (4, 512), (4, 512))\n",
        "vgg19 = VGG(arch=arch19)\n",
        "vgg19"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xx0zx4s32rko",
      "metadata": {
        "id": "xx0zx4s32rko"
      },
      "source": [
        "No. 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "knZkg2C52uFF",
      "metadata": {
        "id": "knZkg2C52uFF"
      },
      "source": [
        "Upsampling the resolution in Fashion-MNIST eight-fold from 28×28\n",
        " to 224×224 dimensions is very wasteful. Try modifying the network architecture and resolution conversion, e.g., to 56 or to 84 dimensions for its input instead. Can you do so without reducing the accuracy of the network? Consult the VGG paper (Simonyan and Zisserman, 2014) for ideas on adding more nonlinearities prior to downsampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FDE4Tkqj2pJC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "FDE4Tkqj2pJC",
        "outputId": "0500a94f-5da8-48a0-8f9c-0b5dd05aac39"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-7b024ad80bb8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFashionMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d2l/torch.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_batch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d2l/torch.py\u001b[0m in \u001b[0;36mfit_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_clip_val\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# To be discussed later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_clip_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = VGG(arch=((3, 128), (3, 256)), lr=0.01)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(28, 28))\n",
        "trainer.fit(model, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wyNeQhVx242j",
      "metadata": {
        "id": "wyNeQhVx242j"
      },
      "source": [
        "#8.3 Network in Network (NiN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4098e4aa",
      "metadata": {
        "id": "4098e4aa"
      },
      "source": [
        "# Network in Network (NiN)\n",
        ":label:`sec_nin`\n",
        "\n",
        "LeNet, AlexNet, and VGG all share a common design pattern:\n",
        "extract features exploiting *spatial* structure\n",
        "via a sequence of convolutions and pooling layers\n",
        "and post-process the representations via fully connected layers.\n",
        "The improvements upon LeNet by AlexNet and VGG mainly lie\n",
        "in how these later networks widen and deepen these two modules.\n",
        "\n",
        "This design poses two major challenges.\n",
        "First, the fully connected layers at the end\n",
        "of the architecture consume tremendous numbers of parameters. For instance, even a simple\n",
        "model such as VGG-11 requires a monstrous matrix, occupying almost\n",
        "400MB of RAM in single precision (FP32). This is a significant impediment to computation, in particular on\n",
        "mobile and embedded devices. After all, even high-end mobile phones sport no more than 8GB of RAM. At the time VGG was invented, this was an order of magnitude less (the iPhone 4S had 512MB). As such, it would have been difficult to justify spending the majority of memory on an image classifier.\n",
        "\n",
        "Second, it is equally impossible to add fully connected layers\n",
        "earlier in the network to increase the degree of nonlinearity: doing so would destroy the\n",
        "spatial structure and require potentially even more memory.\n",
        "\n",
        "The *network in network* (*NiN*) blocks :cite:`Lin.Chen.Yan.2013` offer an alternative,\n",
        "capable of solving both problems in one simple strategy.\n",
        "They were proposed based on a very simple insight: (i) use $1 \\times 1$ convolutions to add\n",
        "local nonlinearities across the channel activations and (ii) use global average pooling to integrate\n",
        "across all locations in the last representation layer. Note that global average pooling would not\n",
        "be effective, were it not for the added nonlinearities. Let's dive into this in detail.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95132206",
      "metadata": {
        "id": "95132206"
      },
      "source": [
        "## (**NiN Blocks**)\n",
        "\n",
        "Recall :numref:`subsec_1x1`. In it we said that the inputs and outputs of convolutional layers\n",
        "consist of four-dimensional tensors with axes\n",
        "corresponding to the example, channel, height, and width.\n",
        "Also recall that the inputs and outputs of fully connected layers\n",
        "are typically two-dimensional tensors corresponding to the example and feature.\n",
        "The idea behind NiN is to apply a fully connected layer\n",
        "at each pixel location (for each height and width).\n",
        "The resulting $1 \\times 1$ convolution can be thought of as\n",
        "a fully connected layer acting independently on each pixel location.\n",
        "\n",
        ":numref:`fig_nin` illustrates the main structural\n",
        "differences between VGG and NiN, and their blocks.\n",
        "Note both the difference in the NiN blocks (the initial convolution is followed by $1 \\times 1$ convolutions, whereas VGG retains $3 \\times 3$ convolutions) and at the end where we no longer require a giant fully connected layer.\n",
        "\n",
        "![Comparing the architectures of VGG and NiN, and of their blocks.](http://d2l.ai/_images/nin.svg)\n",
        ":width:`600px`\n",
        ":label:`fig_nin`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "538cefc3",
      "metadata": {
        "id": "538cefc3"
      },
      "outputs": [],
      "source": [
        "def nin_block(out_channels, kernel_size, strides, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.LazyConv2d(out_channels, kernel_size, strides, padding), nn.ReLU(),\n",
        "        nn.LazyConv2d(out_channels, kernel_size=1), nn.ReLU(),\n",
        "        nn.LazyConv2d(out_channels, kernel_size=1), nn.ReLU())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c944308",
      "metadata": {
        "id": "5c944308"
      },
      "source": [
        "## [**NiN Model**]\n",
        "\n",
        "NiN uses the same initial convolution sizes as AlexNet (it was proposed shortly thereafter).\n",
        "The kernel sizes are $11\\times 11$, $5\\times 5$, and $3\\times 3$, respectively,\n",
        "and the numbers of output channels match those of AlexNet. Each NiN block is followed by a max-pooling layer\n",
        "with a stride of 2 and a window shape of $3\\times 3$.\n",
        "\n",
        "The second significant difference between NiN and both AlexNet and VGG\n",
        "is that NiN avoids fully connected layers altogether.\n",
        "Instead, NiN uses a NiN block with a number of output channels equal to the number of label classes, followed by a *global* average pooling layer,\n",
        "yielding a vector of logits.\n",
        "This design significantly reduces the number of required model parameters, albeit at the expense of a potential increase in training time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "200542dc",
      "metadata": {
        "id": "200542dc"
      },
      "outputs": [],
      "source": [
        "class NiN(d2l.Classifier):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nin_block(96, kernel_size=11, strides=4, padding=0),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nin_block(256, kernel_size=5, strides=1, padding=2),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nin_block(384, kernel_size=3, strides=1, padding=1),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout(0.5),\n",
        "            nin_block(num_classes, kernel_size=3, strides=1, padding=1),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten())\n",
        "        self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7562f54",
      "metadata": {
        "id": "f7562f54"
      },
      "source": [
        "We create a data example to see [**the output shape of each block**].\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0a1fe2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0a1fe2c",
        "outputId": "98ade426-c25e-4cc0-e24a-9c89eb9101db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential output shape:\t torch.Size([1, 96, 54, 54])\n",
            "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
            "Sequential output shape:\t torch.Size([1, 256, 26, 26])\n",
            "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
            "Sequential output shape:\t torch.Size([1, 384, 12, 12])\n",
            "MaxPool2d output shape:\t torch.Size([1, 384, 5, 5])\n",
            "Dropout output shape:\t torch.Size([1, 384, 5, 5])\n",
            "Sequential output shape:\t torch.Size([1, 10, 5, 5])\n",
            "AdaptiveAvgPool2d output shape:\t torch.Size([1, 10, 1, 1])\n",
            "Flatten output shape:\t torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "NiN().layer_summary((1, 1, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "id1Y0aQ66aov",
      "metadata": {
        "id": "id1Y0aQ66aov"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b4ac0209",
      "metadata": {
        "id": "b4ac0209"
      },
      "source": [
        "## [**Training**]\n",
        "\n",
        "As before we use Fashion-MNIST to train the model using the same\n",
        "optimizer that we used for AlexNet and VGG.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "111948ca",
      "metadata": {
        "id": "111948ca",
        "outputId": "60ceef86-4ba4-4ed5-a015-d44325ab85f8"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
              "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
              "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
              "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
              " <metadata>\n",
              "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
              "   <cc:Work>\n",
              "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
              "    <dc:date>2023-08-18T20:05:45.077717</dc:date>\n",
              "    <dc:format>image/svg+xml</dc:format>\n",
              "    <dc:creator>\n",
              "     <cc:Agent>\n",
              "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
              "     </cc:Agent>\n",
              "    </dc:creator>\n",
              "   </cc:Work>\n",
              "  </rdf:RDF>\n",
              " </metadata>\n",
              " <defs>\n",
              "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
              " </defs>\n",
              " <g id=\"figure_1\">\n",
              "  <g id=\"patch_1\">\n",
              "   <path d=\"M 0 183.35625 \n",
              "L 238.965625 183.35625 \n",
              "L 238.965625 0 \n",
              "L 0 0 \n",
              "z\n",
              "\" style=\"fill: #ffffff\"/>\n",
              "  </g>\n",
              "  <g id=\"axes_1\">\n",
              "   <g id=\"patch_2\">\n",
              "    <path d=\"M 30.103125 145.8 \n",
              "L 225.403125 145.8 \n",
              "L 225.403125 7.2 \n",
              "L 30.103125 7.2 \n",
              "z\n",
              "\" style=\"fill: #ffffff\"/>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_1\">\n",
              "    <g id=\"xtick_1\">\n",
              "     <g id=\"line2d_1\">\n",
              "      <defs>\n",
              "       <path id=\"m5841fb9f64\" d=\"M 0 0 \n",
              "L 0 3.5 \n",
              "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </defs>\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5841fb9f64\" x=\"30.103125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_1\">\n",
              "      <!-- 0 -->\n",
              "      <g transform=\"translate(26.921875 160.398438) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
              "Q 1547 4250 1301 3770 \n",
              "Q 1056 3291 1056 2328 \n",
              "Q 1056 1369 1301 889 \n",
              "Q 1547 409 2034 409 \n",
              "Q 2525 409 2770 889 \n",
              "Q 3016 1369 3016 2328 \n",
              "Q 3016 3291 2770 3770 \n",
              "Q 2525 4250 2034 4250 \n",
              "z\n",
              "M 2034 4750 \n",
              "Q 2819 4750 3233 4129 \n",
              "Q 3647 3509 3647 2328 \n",
              "Q 3647 1150 3233 529 \n",
              "Q 2819 -91 2034 -91 \n",
              "Q 1250 -91 836 529 \n",
              "Q 422 1150 422 2328 \n",
              "Q 422 3509 836 4129 \n",
              "Q 1250 4750 2034 4750 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_2\">\n",
              "     <g id=\"line2d_2\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5841fb9f64\" x=\"69.163125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_2\">\n",
              "      <!-- 2 -->\n",
              "      <g transform=\"translate(65.981875 160.398438) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
              "L 3431 531 \n",
              "L 3431 0 \n",
              "L 469 0 \n",
              "L 469 531 \n",
              "Q 828 903 1448 1529 \n",
              "Q 2069 2156 2228 2338 \n",
              "Q 2531 2678 2651 2914 \n",
              "Q 2772 3150 2772 3378 \n",
              "Q 2772 3750 2511 3984 \n",
              "Q 2250 4219 1831 4219 \n",
              "Q 1534 4219 1204 4116 \n",
              "Q 875 4013 500 3803 \n",
              "L 500 4441 \n",
              "Q 881 4594 1212 4672 \n",
              "Q 1544 4750 1819 4750 \n",
              "Q 2544 4750 2975 4387 \n",
              "Q 3406 4025 3406 3419 \n",
              "Q 3406 3131 3298 2873 \n",
              "Q 3191 2616 2906 2266 \n",
              "Q 2828 2175 2409 1742 \n",
              "Q 1991 1309 1228 531 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_3\">\n",
              "     <g id=\"line2d_3\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5841fb9f64\" x=\"108.223125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_3\">\n",
              "      <!-- 4 -->\n",
              "      <g transform=\"translate(105.041875 160.398438) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
              "L 825 1625 \n",
              "L 2419 1625 \n",
              "L 2419 4116 \n",
              "z\n",
              "M 2253 4666 \n",
              "L 3047 4666 \n",
              "L 3047 1625 \n",
              "L 3713 1625 \n",
              "L 3713 1100 \n",
              "L 3047 1100 \n",
              "L 3047 0 \n",
              "L 2419 0 \n",
              "L 2419 1100 \n",
              "L 313 1100 \n",
              "L 313 1709 \n",
              "L 2253 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_4\">\n",
              "     <g id=\"line2d_4\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5841fb9f64\" x=\"147.283125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_4\">\n",
              "      <!-- 6 -->\n",
              "      <g transform=\"translate(144.101875 160.398438) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
              "Q 1688 2584 1439 2293 \n",
              "Q 1191 2003 1191 1497 \n",
              "Q 1191 994 1439 701 \n",
              "Q 1688 409 2113 409 \n",
              "Q 2538 409 2786 701 \n",
              "Q 3034 994 3034 1497 \n",
              "Q 3034 2003 2786 2293 \n",
              "Q 2538 2584 2113 2584 \n",
              "z\n",
              "M 3366 4563 \n",
              "L 3366 3988 \n",
              "Q 3128 4100 2886 4159 \n",
              "Q 2644 4219 2406 4219 \n",
              "Q 1781 4219 1451 3797 \n",
              "Q 1122 3375 1075 2522 \n",
              "Q 1259 2794 1537 2939 \n",
              "Q 1816 3084 2150 3084 \n",
              "Q 2853 3084 3261 2657 \n",
              "Q 3669 2231 3669 1497 \n",
              "Q 3669 778 3244 343 \n",
              "Q 2819 -91 2113 -91 \n",
              "Q 1303 -91 875 529 \n",
              "Q 447 1150 447 2328 \n",
              "Q 447 3434 972 4092 \n",
              "Q 1497 4750 2381 4750 \n",
              "Q 2619 4750 2861 4703 \n",
              "Q 3103 4656 3366 4563 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_5\">\n",
              "     <g id=\"line2d_5\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5841fb9f64\" x=\"186.343125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_5\">\n",
              "      <!-- 8 -->\n",
              "      <g transform=\"translate(183.161875 160.398438) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
              "Q 1584 2216 1326 1975 \n",
              "Q 1069 1734 1069 1313 \n",
              "Q 1069 891 1326 650 \n",
              "Q 1584 409 2034 409 \n",
              "Q 2484 409 2743 651 \n",
              "Q 3003 894 3003 1313 \n",
              "Q 3003 1734 2745 1975 \n",
              "Q 2488 2216 2034 2216 \n",
              "z\n",
              "M 1403 2484 \n",
              "Q 997 2584 770 2862 \n",
              "Q 544 3141 544 3541 \n",
              "Q 544 4100 942 4425 \n",
              "Q 1341 4750 2034 4750 \n",
              "Q 2731 4750 3128 4425 \n",
              "Q 3525 4100 3525 3541 \n",
              "Q 3525 3141 3298 2862 \n",
              "Q 3072 2584 2669 2484 \n",
              "Q 3125 2378 3379 2068 \n",
              "Q 3634 1759 3634 1313 \n",
              "Q 3634 634 3220 271 \n",
              "Q 2806 -91 2034 -91 \n",
              "Q 1263 -91 848 271 \n",
              "Q 434 634 434 1313 \n",
              "Q 434 1759 690 2068 \n",
              "Q 947 2378 1403 2484 \n",
              "z\n",
              "M 1172 3481 \n",
              "Q 1172 3119 1398 2916 \n",
              "Q 1625 2713 2034 2713 \n",
              "Q 2441 2713 2670 2916 \n",
              "Q 2900 3119 2900 3481 \n",
              "Q 2900 3844 2670 4047 \n",
              "Q 2441 4250 2034 4250 \n",
              "Q 1625 4250 1398 4047 \n",
              "Q 1172 3844 1172 3481 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_6\">\n",
              "     <g id=\"line2d_6\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5841fb9f64\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_6\">\n",
              "      <!-- 10 -->\n",
              "      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
              "L 1825 531 \n",
              "L 1825 4091 \n",
              "L 703 3866 \n",
              "L 703 4441 \n",
              "L 1819 4666 \n",
              "L 2450 4666 \n",
              "L 2450 531 \n",
              "L 3481 531 \n",
              "L 3481 0 \n",
              "L 794 0 \n",
              "L 794 531 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"text_7\">\n",
              "     <!-- epoch -->\n",
              "     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n",
              "      <defs>\n",
              "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
              "L 3597 1613 \n",
              "L 953 1613 \n",
              "Q 991 1019 1311 708 \n",
              "Q 1631 397 2203 397 \n",
              "Q 2534 397 2845 478 \n",
              "Q 3156 559 3463 722 \n",
              "L 3463 178 \n",
              "Q 3153 47 2828 -22 \n",
              "Q 2503 -91 2169 -91 \n",
              "Q 1331 -91 842 396 \n",
              "Q 353 884 353 1716 \n",
              "Q 353 2575 817 3079 \n",
              "Q 1281 3584 2069 3584 \n",
              "Q 2775 3584 3186 3129 \n",
              "Q 3597 2675 3597 1894 \n",
              "z\n",
              "M 3022 2063 \n",
              "Q 3016 2534 2758 2815 \n",
              "Q 2500 3097 2075 3097 \n",
              "Q 1594 3097 1305 2825 \n",
              "Q 1016 2553 972 2059 \n",
              "L 3022 2063 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
              "L 1159 -1331 \n",
              "L 581 -1331 \n",
              "L 581 3500 \n",
              "L 1159 3500 \n",
              "L 1159 2969 \n",
              "Q 1341 3281 1617 3432 \n",
              "Q 1894 3584 2278 3584 \n",
              "Q 2916 3584 3314 3078 \n",
              "Q 3713 2572 3713 1747 \n",
              "Q 3713 922 3314 415 \n",
              "Q 2916 -91 2278 -91 \n",
              "Q 1894 -91 1617 61 \n",
              "Q 1341 213 1159 525 \n",
              "z\n",
              "M 3116 1747 \n",
              "Q 3116 2381 2855 2742 \n",
              "Q 2594 3103 2138 3103 \n",
              "Q 1681 3103 1420 2742 \n",
              "Q 1159 2381 1159 1747 \n",
              "Q 1159 1113 1420 752 \n",
              "Q 1681 391 2138 391 \n",
              "Q 2594 391 2855 752 \n",
              "Q 3116 1113 3116 1747 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
              "Q 1497 3097 1228 2736 \n",
              "Q 959 2375 959 1747 \n",
              "Q 959 1119 1226 758 \n",
              "Q 1494 397 1959 397 \n",
              "Q 2419 397 2687 759 \n",
              "Q 2956 1122 2956 1747 \n",
              "Q 2956 2369 2687 2733 \n",
              "Q 2419 3097 1959 3097 \n",
              "z\n",
              "M 1959 3584 \n",
              "Q 2709 3584 3137 3096 \n",
              "Q 3566 2609 3566 1747 \n",
              "Q 3566 888 3137 398 \n",
              "Q 2709 -91 1959 -91 \n",
              "Q 1206 -91 779 398 \n",
              "Q 353 888 353 1747 \n",
              "Q 353 2609 779 3096 \n",
              "Q 1206 3584 1959 3584 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
              "L 3122 2828 \n",
              "Q 2878 2963 2633 3030 \n",
              "Q 2388 3097 2138 3097 \n",
              "Q 1578 3097 1268 2742 \n",
              "Q 959 2388 959 1747 \n",
              "Q 959 1106 1268 751 \n",
              "Q 1578 397 2138 397 \n",
              "Q 2388 397 2633 464 \n",
              "Q 2878 531 3122 666 \n",
              "L 3122 134 \n",
              "Q 2881 22 2623 -34 \n",
              "Q 2366 -91 2075 -91 \n",
              "Q 1284 -91 818 406 \n",
              "Q 353 903 353 1747 \n",
              "Q 353 2603 823 3093 \n",
              "Q 1294 3584 2113 3584 \n",
              "Q 2378 3584 2631 3529 \n",
              "Q 2884 3475 3122 3366 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
              "L 3513 0 \n",
              "L 2938 0 \n",
              "L 2938 2094 \n",
              "Q 2938 2591 2744 2837 \n",
              "Q 2550 3084 2163 3084 \n",
              "Q 1697 3084 1428 2787 \n",
              "Q 1159 2491 1159 1978 \n",
              "L 1159 0 \n",
              "L 581 0 \n",
              "L 581 4863 \n",
              "L 1159 4863 \n",
              "L 1159 2956 \n",
              "Q 1366 3272 1645 3428 \n",
              "Q 1925 3584 2291 3584 \n",
              "Q 2894 3584 3203 3211 \n",
              "Q 3513 2838 3513 2113 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      </defs>\n",
              "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_2\">\n",
              "    <g id=\"ytick_1\">\n",
              "     <g id=\"line2d_7\">\n",
              "      <defs>\n",
              "       <path id=\"m5b729ac6c4\" d=\"M 0 0 \n",
              "L -3.5 0 \n",
              "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </defs>\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5b729ac6c4\" x=\"30.103125\" y=\"121.030627\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_8\">\n",
              "      <!-- 0.5 -->\n",
              "      <g transform=\"translate(7.2 124.829846) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
              "L 1344 794 \n",
              "L 1344 0 \n",
              "L 684 0 \n",
              "L 684 794 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
              "L 3169 4666 \n",
              "L 3169 4134 \n",
              "L 1269 4134 \n",
              "L 1269 2991 \n",
              "Q 1406 3038 1543 3061 \n",
              "Q 1681 3084 1819 3084 \n",
              "Q 2600 3084 3056 2656 \n",
              "Q 3513 2228 3513 1497 \n",
              "Q 3513 744 3044 326 \n",
              "Q 2575 -91 1722 -91 \n",
              "Q 1428 -91 1123 -41 \n",
              "Q 819 9 494 109 \n",
              "L 494 744 \n",
              "Q 775 591 1075 516 \n",
              "Q 1375 441 1709 441 \n",
              "Q 2250 441 2565 725 \n",
              "Q 2881 1009 2881 1497 \n",
              "Q 2881 1984 2565 2268 \n",
              "Q 2250 2553 1709 2553 \n",
              "Q 1456 2553 1204 2497 \n",
              "Q 953 2441 691 2322 \n",
              "L 691 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_2\">\n",
              "     <g id=\"line2d_8\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5b729ac6c4\" x=\"30.103125\" y=\"91.272453\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_9\">\n",
              "      <!-- 1.0 -->\n",
              "      <g transform=\"translate(7.2 95.071672) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_3\">\n",
              "     <g id=\"line2d_9\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5b729ac6c4\" x=\"30.103125\" y=\"61.514279\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_10\">\n",
              "      <!-- 1.5 -->\n",
              "      <g transform=\"translate(7.2 65.313498) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_4\">\n",
              "     <g id=\"line2d_10\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m5b729ac6c4\" x=\"30.103125\" y=\"31.756106\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_11\">\n",
              "      <!-- 2.0 -->\n",
              "      <g transform=\"translate(7.2 35.555324) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"line2d_11\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_12\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_13\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_14\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_15\"/>\n",
              "   <g id=\"line2d_16\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_17\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_18\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_19\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_20\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_21\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_22\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_23\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_24\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_25\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_26\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_27\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_28\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_29\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_30\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_31\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_32\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_33\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_34\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_35\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_36\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_37\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_38\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_39\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_40\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_41\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_42\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_43\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_44\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_45\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_46\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_47\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_48\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_49\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_50\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_51\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_52\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_53\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_54\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_55\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_56\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_57\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_58\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_59\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_60\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_61\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_62\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_63\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_64\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_65\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_66\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_67\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_68\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_69\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_70\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_71\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_72\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_73\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_74\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_75\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_76\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_77\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_78\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "L 147.283125 102.390568 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_79\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "L 151.884543 121.032111 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_80\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_81\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "L 147.283125 102.390568 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_82\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "L 151.884543 121.032111 \n",
              "L 161.628722 122.657064 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_83\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_84\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "L 147.283125 102.390568 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_85\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "L 151.884543 121.032111 \n",
              "L 161.628722 122.657064 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_86\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "L 166.813125 120.95878 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_87\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "L 147.283125 102.390568 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_88\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "L 151.884543 121.032111 \n",
              "L 161.628722 122.657064 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_89\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "L 166.813125 120.95878 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_90\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "L 147.283125 102.390568 \n",
              "L 166.813125 101.766683 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_91\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "L 151.884543 121.032111 \n",
              "L 161.628722 122.657064 \n",
              "L 171.372901 124.173214 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_92\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "L 166.813125 120.95878 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_93\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "L 147.283125 102.390568 \n",
              "L 166.813125 101.766683 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_94\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "L 151.884543 121.032111 \n",
              "L 161.628722 122.657064 \n",
              "L 171.372901 124.173214 \n",
              "L 181.11708 124.927889 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_95\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "L 166.813125 120.95878 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_96\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "L 147.283125 102.390568 \n",
              "L 166.813125 101.766683 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_97\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "L 151.884543 121.032111 \n",
              "L 161.628722 122.657064 \n",
              "L 171.372901 124.173214 \n",
              "L 181.11708 124.927889 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_98\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "L 166.813125 120.95878 \n",
              "L 186.343125 126.993604 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_99\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "L 147.283125 102.390568 \n",
              "L 166.813125 101.766683 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_100\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "L 151.884543 121.032111 \n",
              "L 161.628722 122.657064 \n",
              "L 171.372901 124.173214 \n",
              "L 181.11708 124.927889 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_101\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "L 166.813125 120.95878 \n",
              "L 186.343125 126.993604 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_102\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "L 147.283125 102.390568 \n",
              "L 166.813125 101.766683 \n",
              "L 186.343125 100.000968 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_103\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "L 151.884543 121.032111 \n",
              "L 161.628722 122.657064 \n",
              "L 171.372901 124.173214 \n",
              "L 181.11708 124.927889 \n",
              "L 190.861259 126.078432 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_104\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "L 166.813125 120.95878 \n",
              "L 186.343125 126.993604 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_105\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "L 147.283125 102.390568 \n",
              "L 166.813125 101.766683 \n",
              "L 186.343125 100.000968 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_106\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "L 151.884543 121.032111 \n",
              "L 161.628722 122.657064 \n",
              "L 171.372901 124.173214 \n",
              "L 181.11708 124.927889 \n",
              "L 190.861259 126.078432 \n",
              "L 200.605438 126.543974 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_107\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "L 166.813125 120.95878 \n",
              "L 186.343125 126.993604 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_108\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "L 147.283125 102.390568 \n",
              "L 166.813125 101.766683 \n",
              "L 186.343125 100.000968 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_109\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "L 151.884543 121.032111 \n",
              "L 161.628722 122.657064 \n",
              "L 171.372901 124.173214 \n",
              "L 181.11708 124.927889 \n",
              "L 190.861259 126.078432 \n",
              "L 200.605438 126.543974 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_110\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "L 166.813125 120.95878 \n",
              "L 186.343125 126.993604 \n",
              "L 205.873125 124.961804 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_111\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "L 147.283125 102.390568 \n",
              "L 166.813125 101.766683 \n",
              "L 186.343125 100.000968 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_112\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "L 151.884543 121.032111 \n",
              "L 161.628722 122.657064 \n",
              "L 171.372901 124.173214 \n",
              "L 181.11708 124.927889 \n",
              "L 190.861259 126.078432 \n",
              "L 200.605438 126.543974 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_113\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "L 166.813125 120.95878 \n",
              "L 186.343125 126.993604 \n",
              "L 205.873125 124.961804 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_114\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "L 147.283125 102.390568 \n",
              "L 166.813125 101.766683 \n",
              "L 186.343125 100.000968 \n",
              "L 205.873125 100.618968 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_115\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "L 151.884543 121.032111 \n",
              "L 161.628722 122.657064 \n",
              "L 171.372901 124.173214 \n",
              "L 181.11708 124.927889 \n",
              "L 190.861259 126.078432 \n",
              "L 200.605438 126.543974 \n",
              "L 210.349618 127.928331 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_116\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "L 166.813125 120.95878 \n",
              "L 186.343125 126.993604 \n",
              "L 205.873125 124.961804 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_117\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "L 147.283125 102.390568 \n",
              "L 166.813125 101.766683 \n",
              "L 186.343125 100.000968 \n",
              "L 205.873125 100.618968 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_118\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "L 151.884543 121.032111 \n",
              "L 161.628722 122.657064 \n",
              "L 171.372901 124.173214 \n",
              "L 181.11708 124.927889 \n",
              "L 190.861259 126.078432 \n",
              "L 200.605438 126.543974 \n",
              "L 210.349618 127.928331 \n",
              "L 220.093797 127.550269 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_119\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "L 166.813125 120.95878 \n",
              "L 186.343125 126.993604 \n",
              "L 205.873125 124.961804 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_120\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "L 147.283125 102.390568 \n",
              "L 166.813125 101.766683 \n",
              "L 186.343125 100.000968 \n",
              "L 205.873125 100.618968 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_121\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "L 151.884543 121.032111 \n",
              "L 161.628722 122.657064 \n",
              "L 171.372901 124.173214 \n",
              "L 181.11708 124.927889 \n",
              "L 190.861259 126.078432 \n",
              "L 200.605438 126.543974 \n",
              "L 210.349618 127.928331 \n",
              "L 220.093797 127.550269 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_122\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "L 166.813125 120.95878 \n",
              "L 186.343125 126.993604 \n",
              "L 205.873125 124.961804 \n",
              "L 225.403125 127.787915 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_123\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "L 147.283125 102.390568 \n",
              "L 166.813125 101.766683 \n",
              "L 186.343125 100.000968 \n",
              "L 205.873125 100.618968 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_124\">\n",
              "    <path d=\"M 34.954394 13.5 \n",
              "L 44.698573 13.868319 \n",
              "L 54.442752 19.067692 \n",
              "L 64.186931 47.147834 \n",
              "L 73.93111 69.062972 \n",
              "L 83.675289 80.369094 \n",
              "L 93.419468 99.440551 \n",
              "L 103.163647 105.321997 \n",
              "L 112.907826 110.679047 \n",
              "L 122.652006 113.826477 \n",
              "L 132.396185 115.921938 \n",
              "L 142.140364 118.836319 \n",
              "L 151.884543 121.032111 \n",
              "L 161.628722 122.657064 \n",
              "L 171.372901 124.173214 \n",
              "L 181.11708 124.927889 \n",
              "L 190.861259 126.078432 \n",
              "L 200.605438 126.543974 \n",
              "L 210.349618 127.928331 \n",
              "L 220.093797 127.550269 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_125\">\n",
              "    <path d=\"M 49.633125 14.300545 \n",
              "L 69.163125 62.966599 \n",
              "L 88.693125 96.722288 \n",
              "L 108.223125 109.790341 \n",
              "L 127.753125 74.840754 \n",
              "L 147.283125 119.861155 \n",
              "L 166.813125 120.95878 \n",
              "L 186.343125 126.993604 \n",
              "L 205.873125 124.961804 \n",
              "L 225.403125 127.787915 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_126\">\n",
              "    <path d=\"M 49.633125 139.5 \n",
              "L 69.163125 123.902856 \n",
              "L 88.693125 111.272112 \n",
              "L 108.223125 105.745426 \n",
              "L 127.753125 113.579312 \n",
              "L 147.283125 102.390568 \n",
              "L 166.813125 101.766683 \n",
              "L 186.343125 100.000968 \n",
              "L 205.873125 100.618968 \n",
              "L 225.403125 99.329997 \n",
              "\" clip-path=\"url(#pcbb690d5bc)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_3\">\n",
              "    <path d=\"M 30.103125 145.8 \n",
              "L 30.103125 7.2 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_4\">\n",
              "    <path d=\"M 225.403125 145.8 \n",
              "L 225.403125 7.2 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_5\">\n",
              "    <path d=\"M 30.103125 145.8 \n",
              "L 225.403125 145.8 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_6\">\n",
              "    <path d=\"M 30.103125 7.2 \n",
              "L 225.403125 7.2 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"legend_1\">\n",
              "    <g id=\"patch_7\">\n",
              "     <path d=\"M 138.8125 60.06875 \n",
              "L 218.403125 60.06875 \n",
              "Q 220.403125 60.06875 220.403125 58.06875 \n",
              "L 220.403125 14.2 \n",
              "Q 220.403125 12.2 218.403125 12.2 \n",
              "L 138.8125 12.2 \n",
              "Q 136.8125 12.2 136.8125 14.2 \n",
              "L 136.8125 58.06875 \n",
              "Q 136.8125 60.06875 138.8125 60.06875 \n",
              "z\n",
              "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
              "    </g>\n",
              "    <g id=\"line2d_127\">\n",
              "     <path d=\"M 140.8125 20.298438 \n",
              "L 150.8125 20.298438 \n",
              "L 160.8125 20.298438 \n",
              "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_12\">\n",
              "     <!-- train_loss -->\n",
              "     <g transform=\"translate(168.8125 23.798438) scale(0.1 -0.1)\">\n",
              "      <defs>\n",
              "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
              "L 1172 3500 \n",
              "L 2356 3500 \n",
              "L 2356 3053 \n",
              "L 1172 3053 \n",
              "L 1172 1153 \n",
              "Q 1172 725 1289 603 \n",
              "Q 1406 481 1766 481 \n",
              "L 2356 481 \n",
              "L 2356 0 \n",
              "L 1766 0 \n",
              "Q 1100 0 847 248 \n",
              "Q 594 497 594 1153 \n",
              "L 594 3053 \n",
              "L 172 3053 \n",
              "L 172 3500 \n",
              "L 594 3500 \n",
              "L 594 4494 \n",
              "L 1172 4494 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
              "Q 2534 3019 2420 3045 \n",
              "Q 2306 3072 2169 3072 \n",
              "Q 1681 3072 1420 2755 \n",
              "Q 1159 2438 1159 1844 \n",
              "L 1159 0 \n",
              "L 581 0 \n",
              "L 581 3500 \n",
              "L 1159 3500 \n",
              "L 1159 2956 \n",
              "Q 1341 3275 1631 3429 \n",
              "Q 1922 3584 2338 3584 \n",
              "Q 2397 3584 2469 3576 \n",
              "Q 2541 3569 2628 3553 \n",
              "L 2631 2963 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
              "Q 1497 1759 1228 1600 \n",
              "Q 959 1441 959 1056 \n",
              "Q 959 750 1161 570 \n",
              "Q 1363 391 1709 391 \n",
              "Q 2188 391 2477 730 \n",
              "Q 2766 1069 2766 1631 \n",
              "L 2766 1759 \n",
              "L 2194 1759 \n",
              "z\n",
              "M 3341 1997 \n",
              "L 3341 0 \n",
              "L 2766 0 \n",
              "L 2766 531 \n",
              "Q 2569 213 2275 61 \n",
              "Q 1981 -91 1556 -91 \n",
              "Q 1019 -91 701 211 \n",
              "Q 384 513 384 1019 \n",
              "Q 384 1609 779 1909 \n",
              "Q 1175 2209 1959 2209 \n",
              "L 2766 2209 \n",
              "L 2766 2266 \n",
              "Q 2766 2663 2505 2880 \n",
              "Q 2244 3097 1772 3097 \n",
              "Q 1472 3097 1187 3025 \n",
              "Q 903 2953 641 2809 \n",
              "L 641 3341 \n",
              "Q 956 3463 1253 3523 \n",
              "Q 1550 3584 1831 3584 \n",
              "Q 2591 3584 2966 3190 \n",
              "Q 3341 2797 3341 1997 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
              "L 1178 3500 \n",
              "L 1178 0 \n",
              "L 603 0 \n",
              "L 603 3500 \n",
              "z\n",
              "M 603 4863 \n",
              "L 1178 4863 \n",
              "L 1178 4134 \n",
              "L 603 4134 \n",
              "L 603 4863 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
              "L 3513 0 \n",
              "L 2938 0 \n",
              "L 2938 2094 \n",
              "Q 2938 2591 2744 2837 \n",
              "Q 2550 3084 2163 3084 \n",
              "Q 1697 3084 1428 2787 \n",
              "Q 1159 2491 1159 1978 \n",
              "L 1159 0 \n",
              "L 581 0 \n",
              "L 581 3500 \n",
              "L 1159 3500 \n",
              "L 1159 2956 \n",
              "Q 1366 3272 1645 3428 \n",
              "Q 1925 3584 2291 3584 \n",
              "Q 2894 3584 3203 3211 \n",
              "Q 3513 2838 3513 2113 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \n",
              "L 3263 -1509 \n",
              "L -63 -1509 \n",
              "L -63 -1063 \n",
              "L 3263 -1063 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
              "L 1178 4863 \n",
              "L 1178 0 \n",
              "L 603 0 \n",
              "L 603 4863 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
              "L 2834 2853 \n",
              "Q 2591 2978 2328 3040 \n",
              "Q 2066 3103 1784 3103 \n",
              "Q 1356 3103 1142 2972 \n",
              "Q 928 2841 928 2578 \n",
              "Q 928 2378 1081 2264 \n",
              "Q 1234 2150 1697 2047 \n",
              "L 1894 2003 \n",
              "Q 2506 1872 2764 1633 \n",
              "Q 3022 1394 3022 966 \n",
              "Q 3022 478 2636 193 \n",
              "Q 2250 -91 1575 -91 \n",
              "Q 1294 -91 989 -36 \n",
              "Q 684 19 347 128 \n",
              "L 347 722 \n",
              "Q 666 556 975 473 \n",
              "Q 1284 391 1588 391 \n",
              "Q 1994 391 2212 530 \n",
              "Q 2431 669 2431 922 \n",
              "Q 2431 1156 2273 1281 \n",
              "Q 2116 1406 1581 1522 \n",
              "L 1381 1569 \n",
              "Q 847 1681 609 1914 \n",
              "Q 372 2147 372 2553 \n",
              "Q 372 3047 722 3315 \n",
              "Q 1072 3584 1716 3584 \n",
              "Q 2034 3584 2315 3537 \n",
              "Q 2597 3491 2834 3397 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      </defs>\n",
              "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_128\">\n",
              "     <path d=\"M 140.8125 35.254688 \n",
              "L 150.8125 35.254688 \n",
              "L 160.8125 35.254688 \n",
              "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
              "    </g>\n",
              "    <g id=\"text_13\">\n",
              "     <!-- val_loss -->\n",
              "     <g transform=\"translate(168.8125 38.754688) scale(0.1 -0.1)\">\n",
              "      <defs>\n",
              "       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
              "L 800 3500 \n",
              "L 1894 563 \n",
              "L 2988 3500 \n",
              "L 3597 3500 \n",
              "L 2284 0 \n",
              "L 1503 0 \n",
              "L 191 3500 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      </defs>\n",
              "      <use xlink:href=\"#DejaVuSans-76\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_129\">\n",
              "     <path d=\"M 140.8125 50.210938 \n",
              "L 150.8125 50.210938 \n",
              "L 160.8125 50.210938 \n",
              "\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
              "    </g>\n",
              "    <g id=\"text_14\">\n",
              "     <!-- val_acc -->\n",
              "     <g transform=\"translate(168.8125 53.710938) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-76\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "  </g>\n",
              " </g>\n",
              " <defs>\n",
              "  <clipPath id=\"pcbb690d5bc\">\n",
              "   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
              "  </clipPath>\n",
              " </defs>\n",
              "</svg>\n"
            ],
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = NiN(lr=0.05)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(224, 224))\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "182ce04f",
      "metadata": {
        "id": "182ce04f"
      },
      "source": [
        "## Summary\n",
        "\n",
        "NiN has dramatically fewer parameters than AlexNet and VGG. This stems primarily from the fact that it needs no giant fully connected layers. Instead, it uses global average pooling to aggregate across all image locations after the last stage of the network body. This obviates the need for expensive (learned) reduction operations and replaces them by a simple average. What surprised researchers at the time was the fact that this averaging operation did not harm accuracy. Note that averaging across a low-resolution representation (with many channels) also adds to the amount of translation invariance that the network can handle.\n",
        "\n",
        "Choosing fewer convolutions with wide kernels and replacing them by $1 \\times 1$ convolutions aids the quest for fewer parameters further. It can cater for a significant amount of nonlinearity across channels within any given location. Both $1 \\times 1$ convolutions and global average pooling significantly influenced subsequent CNN designs.\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Why are there two $1\\times 1$ convolutional layers per NiN block? Increase their number to three. Reduce their number to one. What changes?\n",
        "1. What changes if you replace the $1 \\times 1$ convolutions by $3 \\times 3$ convolutions?\n",
        "1. What happens if you replace the global average pooling by a fully connected layer (speed, accuracy, number of parameters)?\n",
        "1. Calculate the resource usage for NiN.\n",
        "    1. What is the number of parameters?\n",
        "    1. What is the amount of computation?\n",
        "    1. What is the amount of memory needed during training?\n",
        "    1. What is the amount of memory needed during prediction?\n",
        "1. What are possible problems with reducing the $384 \\times 5 \\times 5$ representation to a $10 \\times 5 \\times 5$ representation in one step?\n",
        "1. Use the structural design decisions in VGG that led to VGG-11, VGG-16, and VGG-19 to design a family of NiN-like networks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z_RIKYn_BkTE",
      "metadata": {
        "id": "z_RIKYn_BkTE"
      },
      "source": [
        " No. 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0No0HHLXBpAq",
      "metadata": {
        "id": "0No0HHLXBpAq"
      },
      "source": [
        "Why are there two 1×1 convolutional layers per NiN block? Increase their number to three. Reduce their number to one. What changes?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dk-Q25i3CIcr",
      "metadata": {
        "id": "dk-Q25i3CIcr"
      },
      "source": [
        "Dalam arsitektur NiN, lapisan konvolusi 1×1 menambah non-linearitas dan kapasitas jaringan.\n",
        "\n",
        "Dua lapisan 1×1 meningkatkan transformasi fitur dan kapasitas model, yang dapat memperbaiki akurasi.\n",
        "\n",
        "Tiga lapisan 1×1 menambah lebih banyak non-linearitas, tetapi meningkatkan risiko overfitting dan beban komputasi.\n",
        "\n",
        "Satu lapisan 1×1 mengurangi kompleksitas, namun membatasi kemampuan jaringan menangkap fitur kompleks. Ini dapat mempercepat pelatihan tetapi mungkin menyebabkan underfitting.\n",
        "\n",
        "Jumlah lapisan 1×1 harus disesuaikan dengan kebutuhan tugas dan sumber daya komputasi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ec-fOvR4CZdy",
      "metadata": {
        "id": "Ec-fOvR4CZdy"
      },
      "outputs": [],
      "source": [
        "arch = ((96,11,4,0,3),(256,5,1,2,3),(384,3,1,1,3),(10,3,1,1,3))\n",
        "model = NiN(arch)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "trainer.fit(model, data)\n",
        "X,y = next(iter(data.get_dataloader(False)))\n",
        "X = X.to('cuda')\n",
        "y = y.to('cuda')\n",
        "y_hat = model(X)\n",
        "print(f'acc: {model.accuracy(y_hat,y).item():.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NThLQ7rpCaxi",
      "metadata": {
        "id": "NThLQ7rpCaxi"
      },
      "outputs": [],
      "source": [
        "data = d2l.FashionMNIST(batch_size=128, resize=(224, 224))\n",
        "arch = ((96,11,4,0,[[1,0]]),(256,5,1,2,[[1,0]]),(384,3,1,1,[[1,0]]),(10,3,1,1,[[1,0]]))\n",
        "model = NiN(arch, lr=0.05)\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "trainer.fit(model, data)\n",
        "X,y = next(iter(data.get_dataloader(False)))\n",
        "X = X.to('cuda')\n",
        "y = y.to('cuda')\n",
        "y_hat = model(X)\n",
        "print(f'acc: {model.accuracy(y_hat,y).item():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hUt2NaeoCbxm",
      "metadata": {
        "id": "hUt2NaeoCbxm"
      },
      "source": [
        " No. 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "113_r9N6CiZL",
      "metadata": {
        "id": "113_r9N6CiZL"
      },
      "source": [
        "What changes if you replace the 1×1 convolutions by 3×3 convolutions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yl-vZeheClEp",
      "metadata": {
        "id": "yl-vZeheClEp"
      },
      "outputs": [],
      "source": [
        "arch = ((96,11,4,0,[[3,1],[3,1]]),(256,5,1,2,[[3,1],[3,1]]),(384,3,1,1,[[3,1],[3,1]]),(10,3,1,1,[[3,1],[3,1]]))\n",
        "model = NiN(arch)\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "trainer.fit(model, data)\n",
        "X,y = next(iter(data.get_dataloader(False)))\n",
        "X = X.to('cuda')\n",
        "y = y.to('cuda')\n",
        "y_hat = model(X)\n",
        "print(f'acc: {model.accuracy(y_hat,y).item():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p0abinuoC22r",
      "metadata": {
        "id": "p0abinuoC22r"
      },
      "source": [
        "Mengganti konvolusi 1×1 dengan 3×3 akan meningkatkan jumlah parameter dan beban komputasi karena filter 3×3 lebih besar. Namun, ini juga memungkinkan jaringan menangkap lebih banyak informasi spasial dan fitur lokal yang lebih kompleks, sehingga bisa meningkatkan akurasi, tetapi berisiko menyebabkan overfitting jika tidak diimbangi dengan data atau regularisasi yang tepat."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gd5FaeRlC4pa",
      "metadata": {
        "id": "gd5FaeRlC4pa"
      },
      "source": [
        " No 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2p6zpydQC8uQ",
      "metadata": {
        "id": "2p6zpydQC8uQ"
      },
      "source": [
        "What happens if you replace the global average pooling by a fully connected layer (speed, accuracy, number of parameters)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84sqQZJqC-Ql",
      "metadata": {
        "id": "84sqQZJqC-Ql"
      },
      "outputs": [],
      "source": [
        "class MLPNin(d2l.Classifier):\n",
        "    def __init__(self, arch, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        layers = []\n",
        "        for i in range(len(arch)-1):\n",
        "            layers.append(nin_block(*arch[i]))\n",
        "            layers.append(nn.MaxPool2d(3, stride=2))\n",
        "        layers.append(nn.Dropout(0.5))\n",
        "        layers.append(nin_block(*arch[-1]))\n",
        "        layers.append(nn.Flatten())\n",
        "        layers.append(nn.LazyLinear(num_classes))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "        self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6T94C8-YDe8I",
      "metadata": {
        "id": "6T94C8-YDe8I"
      },
      "source": [
        " No. 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GEeX2nE2DjDc",
      "metadata": {
        "id": "GEeX2nE2DjDc"
      },
      "source": [
        "Calculate the resource usage for NiN.\n",
        "\n",
        "4.1 What is the number of parameters?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17j4_z8iDdQH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17j4_z8iDdQH",
        "outputId": "dd5bc2b9-54e4-4f90-e797-df6f28afad37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameters: 2015398\n"
          ]
        }
      ],
      "source": [
        "arch = ((96,11,4,0,2),(256,5,1,2,2),(384,3,1,1,2),(10,3,1,1,2))\n",
        "model = NiN(arch)\n",
        "X = torch.randn(1,3, 224, 224)\n",
        "_ = model(X)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(\"Total parameters:\", total_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XXqUUlODDu6o",
      "metadata": {
        "id": "XXqUUlODDu6o"
      },
      "source": [
        "4.2 What is the amount of computation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OvMkpZpgDmrh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvMkpZpgDmrh",
        "outputId": "6a4a5e0d-8d93-49fe-831e-b807477a65db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop) (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->thop) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->thop) (1.3.0)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "Total FLOPs: 830042124.0\n"
          ]
        }
      ],
      "source": [
        "!pip install thop\n",
        "from thop import profile\n",
        "flops, params = profile(model, inputs=(X,))\n",
        "print(\"Total FLOPs:\", flops)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7E5lwf1AECBi",
      "metadata": {
        "id": "7E5lwf1AECBi"
      },
      "source": [
        "4.3 What is the amount of memory needed during training?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NjTPbTuMDxHf",
      "metadata": {
        "id": "NjTPbTuMDxHf"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Initialize memory counters\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "torch.cuda.empty_cache()\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "trainer.fit(model, data)\n",
        "memory_stats = torch.cuda.memory_stats(device=device)\n",
        "# Print peak memory usage and other memory statistics\n",
        "print(\"Peak memory usage:\", memory_stats[\"allocated_bytes.all.peak\"] / (1024 ** 2), \"MB\")\n",
        "print(\"Current memory usage:\", memory_stats[\"allocated_bytes.all.current\"] / (1024 ** 2), \"MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z1XItopmEHCN",
      "metadata": {
        "id": "Z1XItopmEHCN"
      },
      "source": [
        "4.4 What is the amount of memory needed during prediction?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qo5DepzzEItZ",
      "metadata": {
        "id": "qo5DepzzEItZ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "torch.cuda.empty_cache()\n",
        "_ = model(X)\n",
        "memory_stats = torch.cuda.memory_stats(device=device)\n",
        "print(\"Peak memory usage:\", memory_stats[\"allocated_bytes.all.peak\"] / (1024 ** 2), \"MB\")\n",
        "print(\"Current memory usage:\", memory_stats[\"allocated_bytes.all.current\"] / (1024 ** 2), \"MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-yJR63_4ESVQ",
      "metadata": {
        "id": "-yJR63_4ESVQ"
      },
      "source": [
        " No.5\n",
        "\n",
        "5. What are possible problems with reducing the 384×5×5 representation 10×5×5 representation in one step?\n",
        "\n",
        "Beberapa permasalahan yang dapat muncul antara lain adalah kehilangan informasi secara signifikan, underfitting yang dapat menyebabkan model tidak dapat generalisasi dengan baik, membatasi kemampuan jaringan untuk mentransformasi input secara efektif, dan menghambat model dalam belajar fitur-fitur tingkat tinggi dari data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q06h5CloE8li",
      "metadata": {
        "id": "q06h5CloE8li"
      },
      "source": [
        "No. 6\n",
        "\n",
        "Use the structural design decisions in VGG that led to VGG-11, VGG-16, and VGG-19 to design a family of NiN-like networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DRsHTbPNEVh9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRsHTbPNEVh9",
        "outputId": "e0e4ee89-9e4b-4054-a5cc-b9ef0bb18123"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NiN(\n",
              "  (net): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): LazyConv2d(0, 96, kernel_size=(11, 11), stride=(4, 4))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): LazyConv2d(0, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (2): Sequential(\n",
              "      (0): LazyConv2d(0, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): LazyConv2d(0, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): LazyConv2d(0, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): LazyConv2d(0, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Dropout(p=0.5, inplace=False)\n",
              "    (7): Sequential(\n",
              "      (0): LazyConv2d(0, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): LazyConv2d(0, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (9): Flatten(start_dim=1, end_dim=-1)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arch = ((96,11,4,0,2),(256,5,1,2,2),(384,3,1,1,2),(10,3,1,1,2))\n",
        "nin = NiN(arch)\n",
        "nin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_lrz4EXEFCUo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lrz4EXEFCUo",
        "outputId": "1b0c8e70-97b9-49e8-81ec-86cf41345188"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NiN(\n",
              "  (net): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): LazyConv2d(0, 96, kernel_size=(11, 11), stride=(4, 4))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): LazyConv2d(0, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (2): Sequential(\n",
              "      (0): LazyConv2d(0, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): LazyConv2d(0, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): LazyConv2d(0, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): LazyConv2d(0, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Dropout(p=0.5, inplace=False)\n",
              "    (7): Sequential(\n",
              "      (0): LazyConv2d(0, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): LazyConv2d(0, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (3): ReLU()\n",
              "      (4): LazyConv2d(0, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (5): ReLU()\n",
              "    )\n",
              "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (9): Flatten(start_dim=1, end_dim=-1)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arch15 = ((64,3,2,1),\n",
        "          (256,3,1,1),\n",
        "          (256,3,1,1),\n",
        "          (384,3,1,1),\n",
        "          (10,3,1,1))\n",
        "nin15 = NiN(arch15)\n",
        "nin15"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fnZhoK9hrcCy",
      "metadata": {
        "id": "fnZhoK9hrcCy"
      },
      "source": [
        "#8.4 Multi-Branch Networks (GoogLeNet)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8979a666",
      "metadata": {
        "id": "8979a666"
      },
      "source": [
        "# Multi-Branch Networks  (GoogLeNet)\n",
        ":label:`sec_googlenet`\n",
        "\n",
        "In 2014, *GoogLeNet*\n",
        "won the ImageNet Challenge :cite:`Szegedy.Liu.Jia.ea.2015`, using a structure\n",
        "that combined the strengths of NiN :cite:`Lin.Chen.Yan.2013`, repeated blocks :cite:`Simonyan.Zisserman.2014`,\n",
        "and a cocktail of convolution kernels. It was arguably also the first network that exhibited a clear distinction among the stem (data ingest), body (data processing), and head (prediction) in a CNN. This design pattern has persisted ever since in the design of deep networks: the *stem* is given by the first two or three convolutions that operate on the image. They extract low-level features from the underlying images. This is followed by a *body* of convolutional blocks. Finally, the *head* maps the features obtained so far to the required classification, segmentation, detection, or tracking problem at hand.\n",
        "\n",
        "The key contribution in GoogLeNet was the design of the network body. It solved the problem of selecting\n",
        "convolution kernels in an ingenious way. While other works tried to identify which convolution, ranging from $1 \\times 1$ to $11 \\times 11$ would be best, it simply *concatenated* multi-branch convolutions.\n",
        "In what follows we introduce a slightly simplified version of GoogLeNet: the original design included a number of tricks for stabilizing training through intermediate loss functions, applied to multiple layers of the network.\n",
        "They are no longer necessary due to the availability of improved training algorithms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iWzZuMMVrsWl",
      "metadata": {
        "id": "iWzZuMMVrsWl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd207136",
      "metadata": {
        "id": "fd207136"
      },
      "source": [
        "## (**Inception Blocks**)\n",
        "\n",
        "The basic convolutional block in GoogLeNet is called an *Inception block*,\n",
        "stemming from the meme \"we need to go deeper\" from the movie *Inception*.\n",
        "\n",
        "![Structure of the Inception block.](http://d2l.ai/_images/inception.svg)\n",
        ":label:`fig_inception`\n",
        "\n",
        "As depicted in :numref:`fig_inception`,\n",
        "the inception block consists of four parallel branches.\n",
        "The first three branches use convolutional layers\n",
        "with window sizes of $1\\times 1$, $3\\times 3$, and $5\\times 5$\n",
        "to extract information from different spatial sizes.\n",
        "The middle two branches also add a $1\\times 1$ convolution of the input\n",
        "to reduce the number of channels, reducing the model's complexity.\n",
        "The fourth branch uses a $3\\times 3$ max-pooling layer,\n",
        "followed by a $1\\times 1$ convolutional layer\n",
        "to change the number of channels.\n",
        "The four branches all use appropriate padding to give the input and output the same height and width.\n",
        "Finally, the outputs along each branch are concatenated\n",
        "along the channel dimension and comprise the block's output.\n",
        "The commonly-tuned hyperparameters of the Inception block\n",
        "are the number of output channels per layer, i.e., how to allocate capacity among convolutions of different size.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hjM6w7AMrzWt",
      "metadata": {
        "id": "hjM6w7AMrzWt"
      },
      "outputs": [],
      "source": [
        "class Inception(nn.Module):\n",
        "    # c1--c4 are the number of output channels for each branch\n",
        "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
        "        super(Inception, self).__init__(**kwargs)\n",
        "        # Branch 1\n",
        "        self.b1_1 = nn.LazyConv2d(c1, kernel_size=1)\n",
        "        # Branch 2\n",
        "        self.b2_1 = nn.LazyConv2d(c2[0], kernel_size=1)\n",
        "        self.b2_2 = nn.LazyConv2d(c2[1], kernel_size=3, padding=1)\n",
        "        # Branch 3\n",
        "        self.b3_1 = nn.LazyConv2d(c3[0], kernel_size=1)\n",
        "        self.b3_2 = nn.LazyConv2d(c3[1], kernel_size=5, padding=2)\n",
        "        # Branch 4\n",
        "        self.b4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        self.b4_2 = nn.LazyConv2d(c4, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b1 = F.relu(self.b1_1(x))\n",
        "        b2 = F.relu(self.b2_2(F.relu(self.b2_1(x))))\n",
        "        b3 = F.relu(self.b3_2(F.relu(self.b3_1(x))))\n",
        "        b4 = F.relu(self.b4_2(self.b4_1(x)))\n",
        "        return torch.cat((b1, b2, b3, b4), dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a943308",
      "metadata": {
        "id": "2a943308"
      },
      "source": [
        "To gain some intuition for why this network works so well,\n",
        "consider the combination of the filters.\n",
        "They explore the image in a variety of filter sizes.\n",
        "This means that details at different extents\n",
        "can be recognized efficiently by filters of different sizes.\n",
        "At the same time, we can allocate different amounts of parameters\n",
        "for different filters.\n",
        "\n",
        "\n",
        "## [**GoogLeNet Model**]\n",
        "\n",
        "As shown in :numref:`fig_inception_full`, GoogLeNet uses a stack of a total of 9 inception blocks, arranged into three groups with max-pooling in between,\n",
        "and global average pooling in its head to generate its estimates.\n",
        "Max-pooling between inception blocks reduces the dimensionality.\n",
        "At its stem, the first module is similar to AlexNet and LeNet.\n",
        "\n",
        "![The GoogLeNet architecture.](https://github.com/mdaffaalghiffari23/KomputasiIntelegensia/blob/img/inception-full-90.svg?raw=1)\n",
        ":label:`fig_inception_full`\n",
        "\n",
        "We can now implement GoogLeNet piece by piece. Let's begin with the stem.\n",
        "The first module uses a 64-channel $7\\times 7$ convolutional layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95b8f516",
      "metadata": {
        "id": "95b8f516"
      },
      "outputs": [],
      "source": [
        "class GoogleNet(d2l.Classifier):\n",
        "    def b1(self):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4RDxHHCJr-4e",
      "metadata": {
        "id": "4RDxHHCJr-4e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "762e20f9",
      "metadata": {
        "id": "762e20f9"
      },
      "source": [
        "The second module uses two convolutional layers:\n",
        "first, a 64-channel $1\\times 1$ convolutional layer,\n",
        "followed by a $3\\times 3$ convolutional layer that triples the number of channels. This corresponds to the second branch in the Inception block and concludes the design of the body. At this point we have 192 channels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2f1ae36",
      "metadata": {
        "id": "f2f1ae36"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(GoogleNet)\n",
        "def b2(self):\n",
        "    return nn.Sequential(\n",
        "        nn.LazyConv2d(64, kernel_size=1), nn.ReLU(),\n",
        "        nn.LazyConv2d(192, kernel_size=3, padding=1), nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tCX4bxPfsDSH",
      "metadata": {
        "id": "tCX4bxPfsDSH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "dcc6272e",
      "metadata": {
        "id": "dcc6272e"
      },
      "source": [
        "The third module connects two complete Inception blocks in series.\n",
        "The number of output channels of the first Inception block is\n",
        "$64+128+32+32=256$. This amounts to\n",
        "a ratio of the number of output channels\n",
        "among the four branches of $2:4:1:1$. To achieve this, we first reduce the input\n",
        "dimensions by $\\frac{1}{2}$ and by $\\frac{1}{12}$ in the second and third branch respectively\n",
        "to arrive at $96 = 192/2$ and $16 = 192/12$ channels respectively.\n",
        "\n",
        "The number of output channels of the second Inception block\n",
        "is increased to $128+192+96+64=480$, yielding a ratio of $128:192:96:64 = 4:6:3:2$. As before,\n",
        "we need to reduce the number of intermediate dimensions in the second and third channel. A\n",
        "scale of $\\frac{1}{2}$ and $\\frac{1}{8}$ respectively suffices, yielding $128$ and $32$ channels\n",
        "respectively. This is captured by the arguments of the following `Inception` block constructors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33a37805",
      "metadata": {
        "id": "33a37805"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(GoogleNet)\n",
        "def b3(self):\n",
        "    return nn.Sequential(Inception(64, (96, 128), (16, 32), 32),\n",
        "                         Inception(128, (128, 192), (32, 96), 64),\n",
        "                         nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "112f5cd2",
      "metadata": {
        "id": "112f5cd2"
      },
      "source": [
        "The fourth module is more complicated.\n",
        "It connects five Inception blocks in series,\n",
        "and they have $192+208+48+64=512$, $160+224+64+64=512$,\n",
        "$128+256+64+64=512$, $112+288+64+64=528$,\n",
        "and $256+320+128+128=832$ output channels, respectively.\n",
        "The number of channels assigned to these branches is similar\n",
        "to that in the third module:\n",
        "the second branch with the $3\\times 3$ convolutional layer\n",
        "outputs the largest number of channels,\n",
        "followed by the first branch with only the $1\\times 1$ convolutional layer,\n",
        "the third branch with the $5\\times 5$ convolutional layer,\n",
        "and the fourth branch with the $3\\times 3$ max-pooling layer.\n",
        "The second and third branches will first reduce\n",
        "the number of channels according to the ratio.\n",
        "These ratios are slightly different in different Inception blocks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2beb4b7a",
      "metadata": {
        "id": "2beb4b7a"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(GoogleNet)\n",
        "def b4(self):\n",
        "    return nn.Sequential(Inception(192, (96, 208), (16, 48), 64),\n",
        "                         Inception(160, (112, 224), (24, 64), 64),\n",
        "                         Inception(128, (128, 256), (24, 64), 64),\n",
        "                         Inception(112, (144, 288), (32, 64), 64),\n",
        "                         Inception(256, (160, 320), (32, 128), 128),\n",
        "                         nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "703d40c6",
      "metadata": {
        "id": "703d40c6"
      },
      "source": [
        "The fifth module has two Inception blocks with $256+320+128+128=832$\n",
        "and $384+384+128+128=1024$ output channels.\n",
        "The number of channels assigned to each branch\n",
        "is the same as that in the third and fourth modules,\n",
        "but differs in specific values.\n",
        "It should be noted that the fifth block is followed by the output layer.\n",
        "This block uses the global average pooling layer\n",
        "to change the height and width of each channel to 1, just as in NiN.\n",
        "Finally, we turn the output into a two-dimensional array\n",
        "followed by a fully connected layer\n",
        "whose number of outputs is the number of label classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b836927",
      "metadata": {
        "id": "8b836927"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(GoogleNet)\n",
        "def b5(self):\n",
        "    return nn.Sequential(Inception(256, (160, 320), (32, 128), 128),\n",
        "                         Inception(384, (192, 384), (48, 128), 128),\n",
        "                         nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o9cffCvvsQX2",
      "metadata": {
        "id": "o9cffCvvsQX2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "62f89c54",
      "metadata": {
        "id": "62f89c54"
      },
      "source": [
        "Now that we defined all blocks `b1` through `b5`, it is just a matter of assembling them all into a full network.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe47c47d",
      "metadata": {
        "id": "fe47c47d"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(GoogleNet)\n",
        "def __init__(self, lr=0.1, num_classes=10):\n",
        "    super(GoogleNet, self).__init__()\n",
        "    self.save_hyperparameters()\n",
        "    self.net = nn.Sequential(self.b1(), self.b2(), self.b3(), self.b4(),\n",
        "                             self.b5(), nn.LazyLinear(num_classes))\n",
        "    self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b94378d8",
      "metadata": {
        "id": "b94378d8"
      },
      "source": [
        "The GoogLeNet model is computationally complex. Note the large number of\n",
        "relatively arbitrary hyperparameters in terms of the number of channels chosen, the number of blocks prior to dimensionality reduction, the relative partitioning of capacity across channels, etc. Much of it is due to the\n",
        "fact that at the time when GoogLeNet was introduced, automatic tools for network definition or design exploration\n",
        "were not yet available. For instance, by now we take it for granted that a competent deep learning framework is capable of inferring dimensionalities of input tensors automatically. At the time, many such configurations had to be specified explicitly by the experimenter, thus often slowing down active experimentation. Moreover, the tools needed for automatic exploration were still in flux and initial experiments largely amounted to costly brute-force exploration, genetic algorithms, and similar strategies.\n",
        "\n",
        "For now the only modification we will carry out is to\n",
        "[**reduce the input height and width from 224 to 96\n",
        "to have a reasonable training time on Fashion-MNIST.**]\n",
        "This simplifies the computation. Let's have a look at the\n",
        "changes in the shape of the output between the various modules.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b695b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83b695b7",
        "outputId": "9f7f6b6f-943f-45fd-80dc-061aaa993e0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential output shape:\t torch.Size([1, 64, 24, 24])\n",
            "Sequential output shape:\t torch.Size([1, 192, 12, 12])\n",
            "Sequential output shape:\t torch.Size([1, 480, 6, 6])\n",
            "Sequential output shape:\t torch.Size([1, 832, 3, 3])\n",
            "Sequential output shape:\t torch.Size([1, 1024])\n",
            "Linear output shape:\t torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "model = GoogleNet().layer_summary((1, 1, 96, 96))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f3be870",
      "metadata": {
        "id": "2f3be870"
      },
      "source": [
        "## [**Training**]\n",
        "\n",
        "As before, we train our model using the Fashion-MNIST dataset.\n",
        " We transform it to $96 \\times 96$ pixel resolution\n",
        " before invoking the training procedure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7BVcusP-sZKo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "7BVcusP-sZKo",
        "outputId": "51ba6bd0-635d-420a-866f-ebe7c5584d98"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-10-03T14:21:20.520583</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 238.965625 183.35625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"mbe59019802\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mbe59019802\" x=\"30.103125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.921875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#mbe59019802\" x=\"69.163125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(65.981875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#mbe59019802\" x=\"108.223125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(105.041875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#mbe59019802\" x=\"147.283125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(144.101875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#mbe59019802\" x=\"186.343125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(183.161875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#mbe59019802\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"mc6588b6b10\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mc6588b6b10\" x=\"30.103125\" y=\"117.277547\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.5 -->\n      <g transform=\"translate(7.2 121.076766) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#mc6588b6b10\" x=\"30.103125\" y=\"88.490276\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 92.289495) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#mc6588b6b10\" x=\"30.103125\" y=\"59.703005\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.5 -->\n      <g transform=\"translate(7.2 63.502224) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#mc6588b6b10\" x=\"30.103125\" y=\"30.915734\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 34.714952) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_11\">\n    <path d=\"M 34.954394 13.5 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 49.633125 13.612588 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_15\"/>\n   <g id=\"line2d_16\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 49.633125 13.612588 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 49.633125 13.612588 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 49.633125 13.612588 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path d=\"M 49.633125 139.5 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_34\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_35\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_40\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_44\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_45\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_46\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_47\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_48\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_50\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_53\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_54\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_56\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_57\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_58\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_59\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_60\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_61\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_62\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_63\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_64\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_65\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_66\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_67\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_68\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_69\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_70\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_71\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_72\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_73\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_74\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_75\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_76\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_77\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_78\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \nL 147.283125 105.024737 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_79\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \nL 151.884543 106.765425 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_80\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_81\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \nL 147.283125 105.024737 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_82\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \nL 151.884543 106.765425 \nL 161.628722 102.367817 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_83\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_84\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \nL 147.283125 105.024737 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_85\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \nL 151.884543 106.765425 \nL 161.628722 102.367817 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_86\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \nL 166.813125 110.875071 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_87\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \nL 147.283125 105.024737 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_88\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \nL 151.884543 106.765425 \nL 161.628722 102.367817 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_89\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \nL 166.813125 110.875071 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_90\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \nL 147.283125 105.024737 \nL 166.813125 101.688238 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_91\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \nL 151.884543 106.765425 \nL 161.628722 102.367817 \nL 171.372901 112.048169 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_92\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \nL 166.813125 110.875071 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_93\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \nL 147.283125 105.024737 \nL 166.813125 101.688238 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_94\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \nL 151.884543 106.765425 \nL 161.628722 102.367817 \nL 171.372901 112.048169 \nL 181.11708 113.394891 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_95\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \nL 166.813125 110.875071 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_96\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \nL 147.283125 105.024737 \nL 166.813125 101.688238 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_97\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \nL 151.884543 106.765425 \nL 161.628722 102.367817 \nL 171.372901 112.048169 \nL 181.11708 113.394891 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_98\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \nL 166.813125 110.875071 \nL 186.343125 112.597361 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_99\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \nL 147.283125 105.024737 \nL 166.813125 101.688238 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_100\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \nL 151.884543 106.765425 \nL 161.628722 102.367817 \nL 171.372901 112.048169 \nL 181.11708 113.394891 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_101\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \nL 166.813125 110.875071 \nL 186.343125 112.597361 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_102\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \nL 147.283125 105.024737 \nL 166.813125 101.688238 \nL 186.343125 101.323842 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_103\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \nL 151.884543 106.765425 \nL 161.628722 102.367817 \nL 171.372901 112.048169 \nL 181.11708 113.394891 \nL 190.861259 115.74945 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_104\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \nL 166.813125 110.875071 \nL 186.343125 112.597361 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_105\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \nL 147.283125 105.024737 \nL 166.813125 101.688238 \nL 186.343125 101.323842 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_106\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \nL 151.884543 106.765425 \nL 161.628722 102.367817 \nL 171.372901 112.048169 \nL 181.11708 113.394891 \nL 190.861259 115.74945 \nL 200.605438 116.823476 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_107\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \nL 166.813125 110.875071 \nL 186.343125 112.597361 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_108\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \nL 147.283125 105.024737 \nL 166.813125 101.688238 \nL 186.343125 101.323842 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_109\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \nL 151.884543 106.765425 \nL 161.628722 102.367817 \nL 171.372901 112.048169 \nL 181.11708 113.394891 \nL 190.861259 115.74945 \nL 200.605438 116.823476 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_110\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \nL 166.813125 110.875071 \nL 186.343125 112.597361 \nL 205.873125 117.630711 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_111\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \nL 147.283125 105.024737 \nL 166.813125 101.688238 \nL 186.343125 101.323842 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_112\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \nL 151.884543 106.765425 \nL 161.628722 102.367817 \nL 171.372901 112.048169 \nL 181.11708 113.394891 \nL 190.861259 115.74945 \nL 200.605438 116.823476 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_113\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \nL 166.813125 110.875071 \nL 186.343125 112.597361 \nL 205.873125 117.630711 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_114\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \nL 147.283125 105.024737 \nL 166.813125 101.688238 \nL 186.343125 101.323842 \nL 205.873125 99.057756 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_115\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \nL 151.884543 106.765425 \nL 161.628722 102.367817 \nL 171.372901 112.048169 \nL 181.11708 113.394891 \nL 190.861259 115.74945 \nL 200.605438 116.823476 \nL 210.349618 118.186797 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_116\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \nL 166.813125 110.875071 \nL 186.343125 112.597361 \nL 205.873125 117.630711 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_117\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \nL 147.283125 105.024737 \nL 166.813125 101.688238 \nL 186.343125 101.323842 \nL 205.873125 99.057756 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_118\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \nL 151.884543 106.765425 \nL 161.628722 102.367817 \nL 171.372901 112.048169 \nL 181.11708 113.394891 \nL 190.861259 115.74945 \nL 200.605438 116.823476 \nL 210.349618 118.186797 \nL 220.093797 119.021358 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_119\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \nL 166.813125 110.875071 \nL 186.343125 112.597361 \nL 205.873125 117.630711 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_120\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \nL 147.283125 105.024737 \nL 166.813125 101.688238 \nL 186.343125 101.323842 \nL 205.873125 99.057756 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_121\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \nL 151.884543 106.765425 \nL 161.628722 102.367817 \nL 171.372901 112.048169 \nL 181.11708 113.394891 \nL 190.861259 115.74945 \nL 200.605438 116.823476 \nL 210.349618 118.186797 \nL 220.093797 119.021358 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_122\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \nL 166.813125 110.875071 \nL 186.343125 112.597361 \nL 205.873125 117.630711 \nL 225.403125 119.119372 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_123\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \nL 147.283125 105.024737 \nL 166.813125 101.688238 \nL 186.343125 101.323842 \nL 205.873125 99.057756 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_124\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 13.570927 \nL 54.442752 13.643966 \nL 64.186931 13.755188 \nL 73.93111 13.95881 \nL 83.675289 14.448248 \nL 93.419468 16.218674 \nL 103.163647 30.637921 \nL 112.907826 64.694932 \nL 122.652006 88.287718 \nL 132.396185 97.550164 \nL 142.140364 102.880326 \nL 151.884543 106.765425 \nL 161.628722 102.367817 \nL 171.372901 112.048169 \nL 181.11708 113.394891 \nL 190.861259 115.74945 \nL 200.605438 116.823476 \nL 210.349618 118.186797 \nL 220.093797 119.021358 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_125\">\n    <path d=\"M 49.633125 13.612588 \nL 69.163125 13.841276 \nL 88.693125 14.952976 \nL 108.223125 26.564876 \nL 127.753125 95.443958 \nL 147.283125 102.383598 \nL 166.813125 110.875071 \nL 186.343125 112.597361 \nL 205.873125 117.630711 \nL 225.403125 119.119372 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_126\">\n    <path d=\"M 49.633125 139.5 \nL 69.163125 129.257061 \nL 88.693125 124.462978 \nL 108.223125 138.144903 \nL 127.753125 106.63605 \nL 147.283125 105.024737 \nL 166.813125 101.688238 \nL 186.343125 101.323842 \nL 205.873125 99.057756 \nL 225.403125 98.385901 \n\" clip-path=\"url(#p43bcea3b5e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 145.8 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 138.8125 60.06875 \nL 218.403125 60.06875 \nQ 220.403125 60.06875 220.403125 58.06875 \nL 220.403125 14.2 \nQ 220.403125 12.2 218.403125 12.2 \nL 138.8125 12.2 \nQ 136.8125 12.2 136.8125 14.2 \nL 136.8125 58.06875 \nQ 136.8125 60.06875 138.8125 60.06875 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_127\">\n     <path d=\"M 140.8125 20.298438 \nL 150.8125 20.298438 \nL 160.8125 20.298438 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- train_loss -->\n     <g transform=\"translate(168.8125 23.798438) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_128\">\n     <path d=\"M 140.8125 35.254688 \nL 150.8125 35.254688 \nL 160.8125 35.254688 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- val_loss -->\n     <g transform=\"translate(168.8125 38.754688) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n    <g id=\"line2d_129\">\n     <path d=\"M 140.8125 50.210938 \nL 150.8125 50.210938 \nL 160.8125 50.210938 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_14\">\n     <!-- val_acc -->\n     <g transform=\"translate(168.8125 53.710938) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p43bcea3b5e\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = GoogleNet(lr=0.01)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(96, 96))\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14eaa685",
      "metadata": {
        "id": "14eaa685"
      },
      "source": [
        "## Discussion\n",
        "\n",
        "A key feature of GoogLeNet is that it is actually *cheaper* to compute than its predecessors\n",
        "while simultaneously providing improved accuracy. This marks the beginning of a much more deliberate\n",
        "network design that trades off the cost of evaluating a network with a reduction in errors. It also marks the beginning of experimentation at a block level with network design hyperparameters, even though it was entirely manual at the time. We will revisit this topic in :numref:`sec_cnn-design` when discussing strategies for network structure exploration.\n",
        "\n",
        "Over the following sections we will encounter a number of design choices (e.g., batch normalization, residual connections, and channel grouping) that allow us to improve networks significantly. For now, you can be proud to have implemented what is arguably the first truly modern CNN.\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. GoogLeNet was so successful that it went through a number of iterations, progressively improving speed and accuracy. Try to implement and run some of them. They include the following:\n",
        "    1. Add a batch normalization layer :cite:`Ioffe.Szegedy.2015`, as described later in :numref:`sec_batch_norm`.\n",
        "    1. Make adjustments to the Inception block (width, choice and order of convolutions), as described in :citet:`Szegedy.Vanhoucke.Ioffe.ea.2016`.\n",
        "    1. Use label smoothing for model regularization, as described in :citet:`Szegedy.Vanhoucke.Ioffe.ea.2016`.\n",
        "    1. Make further adjustments to the Inception block by adding residual connection :cite:`Szegedy.Ioffe.Vanhoucke.ea.2017`, as described later in :numref:`sec_resnet`.\n",
        "1. What is the minimum image size needed for GoogLeNet to work?\n",
        "1. Can you design a variant of GoogLeNet that works on Fashion-MNIST's native resolution of $28 \\times 28$ pixels? How would you need to change the stem, the body, and the head of the network, if anything at all?\n",
        "1. Compare the model parameter sizes of AlexNet, VGG, NiN, and GoogLeNet. How do the latter two network\n",
        "   architectures significantly reduce the model parameter size?\n",
        "1. Compare the amount of computation needed in GoogLeNet and AlexNet. How does this affect the design of an accelerator chip, e.g., in terms of memory size, memory bandwidth, cache size, the amount of computation, and the benefit of specialized operations?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "v2YttttLst6n",
      "metadata": {
        "id": "v2YttttLst6n"
      },
      "source": [
        "No. 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0oTvvQtUs59E",
      "metadata": {
        "id": "0oTvvQtUs59E"
      },
      "source": [
        "1. GoogLeNet was so successful that it went through a number of iterations, progressively improving speed and accuracy. Try to implement and run some of them. They include the following"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1YklhM6ysd6H",
      "metadata": {
        "id": "1YklhM6ysd6H"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import warnings\n",
        "import d2l\n",
        "from torchsummary import summary\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K76KCWq1tpSz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "K76KCWq1tpSz",
        "outputId": "2f11d8bb-1150-4b66-a8df-fd6c5a93cda8"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'd2l' has no attribute 'Classifier'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b320ffe4cbc0>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mGoogleNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         return nn.Sequential(nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'd2l' has no attribute 'Classifier'"
          ]
        }
      ],
      "source": [
        "class Inception(nn.Module):\n",
        "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
        "        super().__init__(*kwargs)\n",
        "        self.b1 = nn.Sequential(nn.LazyConv2d(c1, kernel_size=1),\n",
        "                                nn.ReLU())\n",
        "        self.b2 = nn.Sequential(nn.LazyConv2d(c2[0], kernel_size=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.LazyConv2d(c2[1], kernel_size=3, padding=1),\n",
        "                                nn.ReLU())\n",
        "        self.b3 = nn.Sequential(nn.LazyConv2d(c3[0], kernel_size=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.LazyConv2d(c3[1], kernel_size=5, padding=2),\n",
        "                                nn.ReLU())\n",
        "        self.b4 = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "                                nn.LazyConv2d(c4, kernel_size=1),\n",
        "                                nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        o1 = self.b1(x)\n",
        "        o2 = self.b2(x)\n",
        "        o3 = self.b3(x)\n",
        "        o4 = self.b4(x)\n",
        "        return torch.cat((o1,o2,o3,o4),dim=1)\n",
        "\n",
        "class GoogleNet(d2l.Classifier):\n",
        "    def b1(self):\n",
        "        return nn.Sequential(nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "                             nn.ReLU(),\n",
        "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "    def b2(self):\n",
        "        return nn.Sequential(nn.LazyConv2d(64, kernel_size=1), nn.ReLU(),\n",
        "                             nn.LazyConv2d(192, kernel_size=3, padding=1),\n",
        "                             nn.ReLU(),\n",
        "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "    def b3(self):\n",
        "        return nn.Sequential(Inception(64, (96, 128), (16, 32), 32),\n",
        "                             Inception(128, (128, 192), (32, 96), 64),\n",
        "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "    def b4(self):\n",
        "        return nn.Sequential(Inception(192, (96, 208), (16, 48), 64),\n",
        "                             Inception(160, (112, 224), (24, 64), 64),\n",
        "                             Inception(128, (128, 256), (24, 64), 64),\n",
        "                             Inception(112, (144, 288), (32, 64), 64),\n",
        "                             Inception(256, (160, 320), (32, 128), 128),\n",
        "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "    def b5(self):\n",
        "        return nn.Sequential(Inception(256, (160, 320), (32, 128), 128),\n",
        "                             Inception(384, (192, 384), (48, 128), 128),\n",
        "                             nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())\n",
        "\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(self.b1(), self.b2(), self.b3(), self.b4(),\n",
        "                                 self.b5(), nn.LazyLinear(num_classes))\n",
        "        self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sIMTLbtjtvpE",
      "metadata": {
        "id": "sIMTLbtjtvpE"
      },
      "source": [
        "1.1 Add a batch normalization layer :cite:Ioffe.Szegedy.2015, as described later in :numref:sec_batch_norm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rxMCxTJotw13",
      "metadata": {
        "id": "rxMCxTJotw13"
      },
      "outputs": [],
      "source": [
        "class NormInception(nn.Module):\n",
        "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
        "        super().__init__(*kwargs)\n",
        "        self.b1 = nn.Sequential(nn.LazyConv2d(c1, kernel_size=1),\n",
        "                                nn.LazyBatchNorm2d(),\n",
        "                                nn.ReLU())\n",
        "        self.b2 = nn.Sequential(nn.LazyConv2d(c2[0], kernel_size=1),\n",
        "                                nn.LazyBatchNorm2d(),\n",
        "                                nn.ReLU(),\n",
        "                                nn.LazyConv2d(c2[1], kernel_size=3, padding=1),\n",
        "                                nn.LazyBatchNorm2d(),\n",
        "                                nn.ReLU())\n",
        "        self.b3 = nn.Sequential(nn.LazyConv2d(c3[0], kernel_size=1),\n",
        "                                nn.LazyBatchNorm2d(),\n",
        "                                nn.ReLU(),\n",
        "                                nn.LazyConv2d(c3[1], kernel_size=5, padding=2),\n",
        "                                nn.LazyBatchNorm2d(),\n",
        "                                nn.ReLU())\n",
        "        self.b4 = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "                                nn.LazyBatchNorm2d(),\n",
        "                                nn.LazyConv2d(c4, kernel_size=1),\n",
        "                                nn.LazyBatchNorm2d(),\n",
        "                                nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        o1 = self.b1(x)\n",
        "        o2 = self.b2(x)\n",
        "        o3 = self.b3(x)\n",
        "        o4 = self.b4(x)\n",
        "        return torch.cat((o1,o2,o3,o4),dim=1)\n",
        "\n",
        "class NormGoogleNet(d2l.Classifier):\n",
        "    def b1(self):\n",
        "        return nn.Sequential(nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "                             nn.LazyBatchNorm2d(),\n",
        "                             nn.ReLU(),\n",
        "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "    def b2(self):\n",
        "        return nn.Sequential(nn.LazyConv2d(64, kernel_size=1),\n",
        "                             nn.LazyBatchNorm2d(),nn.ReLU(),\n",
        "                             nn.LazyConv2d(192, kernel_size=3, padding=1),\n",
        "                             nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "    def b3(self):\n",
        "        return nn.Sequential(NormInception(64, (96, 128), (16, 32), 32),\n",
        "                             NormInception(128, (128, 192), (32, 96), 64),\n",
        "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "    def b4(self):\n",
        "        return nn.Sequential(NormInception(192, (96, 208), (16, 48), 64),\n",
        "                             NormInception(160, (112, 224), (24, 64), 64),\n",
        "                             NormInception(128, (128, 256), (24, 64), 64),\n",
        "                             NormInception(112, (144, 288), (32, 64), 64),\n",
        "                             NormInception(256, (160, 320), (32, 128), 128),\n",
        "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "    def b5(self):\n",
        "        return nn.Sequential(NormInception(256, (160, 320), (32, 128), 128),\n",
        "                             NormInception(384, (192, 384), (48, 128), 128),\n",
        "                             nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())\n",
        "\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(self.b1(), self.b2(), self.b3(), self.b4(),\n",
        "                                 self.b5(), nn.LazyLinear(num_classes))\n",
        "        self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "On6nySOYt1km",
      "metadata": {
        "id": "On6nySOYt1km"
      },
      "source": [
        "1.2 Make adjustments to the Inception block (width, choice and order of convolutions), as described in Szegedy et al. (2016)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5RdiIm6qt40h",
      "metadata": {
        "id": "5RdiIm6qt40h"
      },
      "outputs": [],
      "source": [
        "class Inception(nn.Module):\n",
        "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
        "        super().__init__(*kwargs)\n",
        "        self.b1 = nn.Sequential(nn.LazyConv2d(c1, kernel_size=1),\n",
        "                                nn.ReLU())\n",
        "        self.b2 = nn.Sequential(nn.LazyConv2d(c2[0], kernel_size=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.LazyConv2d(c2[1], kernel_size=3, padding=1),\n",
        "                                nn.ReLU())\n",
        "        self.b3 = nn.Sequential(nn.LazyConv2d(c3[0], kernel_size=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.LazyConv2d(c3[1], kernel_size=3, padding=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.LazyConv2d(c3[2], kernel_size=3, padding=1),\n",
        "                                nn.ReLU())\n",
        "        self.b4 = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "                                nn.LazyConv2d(c4, kernel_size=1),\n",
        "                                nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        o1 = self.b1(x)\n",
        "        o2 = self.b2(x)\n",
        "        o3 = self.b3(x)\n",
        "        o4 = self.b4(x)\n",
        "        return torch.cat((o1,o2,o3,o4),dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03PBJixdt7d_",
      "metadata": {
        "id": "03PBJixdt7d_"
      },
      "outputs": [],
      "source": [
        "class Inception(nn.Module):\n",
        "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
        "        super().__init__(*kwargs)\n",
        "        self.b1 = nn.Sequential(nn.LazyConv2d(c1, kernel_size=1),\n",
        "                                nn.ReLU())\n",
        "        self.b2 = nn.Sequential(nn.LazyConv2d(c2[0], kernel_size=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.LazyConv2d(c2[1], kernel_size=(1,3), padding=(0,1)),\n",
        "                                nn.ReLU(),\n",
        "                                nn.LazyConv2d(c2[2], kernel_size=(3,1), padding=(1,0)),\n",
        "                                nn.ReLU())\n",
        "        self.b3 = nn.Sequential(nn.LazyConv2d(c3[0], kernel_size=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.LazyConv2d(c3[1], kernel_size=(1,3), padding=(0,1)),\n",
        "                                nn.ReLU(),\n",
        "                                nn.LazyConv2d(c3[2], kernel_size=(3,1), padding=(1,0)),\n",
        "                                nn.ReLU(),\n",
        "                                nn.LazyConv2d(c3[3], kernel_size=(1,3), padding=(0,1)),\n",
        "                                nn.ReLU(),\n",
        "                                nn.LazyConv2d(c3[4], kernel_size=(3,1), padding=(1,0)),\n",
        "                                nn.ReLU())\n",
        "        self.b4 = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "                                nn.LazyConv2d(c4, kernel_size=1),\n",
        "                                nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        o1 = self.b1(x)\n",
        "        o2 = self.b2(x)\n",
        "        o3 = self.b3(x)\n",
        "        o4 = self.b4(x)\n",
        "        return torch.cat((o1,o2,o3,o4),dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gqH2p-2-uA54",
      "metadata": {
        "id": "gqH2p-2-uA54"
      },
      "outputs": [],
      "source": [
        "class Inception(nn.Module):\n",
        "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
        "        super().__init__(*kwargs)\n",
        "        self.b1 = nn.Sequential(nn.LazyConv2d(c1, kernel_size=1),\n",
        "                                nn.ReLU())\n",
        "        self.b2 = nn.Sequential(nn.LazyConv2d(c2[0], kernel_size=1),\n",
        "                                nn.ReLU())\n",
        "        self.b2_1 = nn.Sequential(nn.LazyConv2d(c2[1], kernel_size=(1,3), padding=(0,1)),\n",
        "                                nn.ReLU())\n",
        "        self.b2_2 = nn.Sequential(nn.LazyConv2d(c2[2], kernel_size=(3,1), padding=(1,0)),\n",
        "                                nn.ReLU())\n",
        "        self.b3 = nn.Sequential(nn.LazyConv2d(c3[0], kernel_size=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.LazyConv2d(c3[1], kernel_size=3, padding=1),\n",
        "                                nn.ReLU())\n",
        "        self.b3_1 = nn.Sequential(nn.LazyConv2d(c3[2], kernel_size=(1,3), padding=(0,1)),\n",
        "                                nn.ReLU())\n",
        "        self.b3_2 = nn.Sequential(nn.LazyConv2d(c3[3], kernel_size=(3,1), padding=(1,0)),\n",
        "                                nn.ReLU())\n",
        "        self.b4 = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "                                nn.LazyConv2d(c4, kernel_size=1),\n",
        "                                nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        o1 = self.b1(x)\n",
        "        o2 = self.b2(x)\n",
        "        o2_1 = self.b2_1(o2)\n",
        "        o2_2 = self.b2_2(o2)\n",
        "        o3 = self.b3(x)\n",
        "        o3_1 = self.b3_1(o3)\n",
        "        o3_2 = self.b3_2(o2)\n",
        "        o4 = self.b4(x)\n",
        "        return torch.cat((o1,o2_1,o2_2,o3_1,o3_2,o4),dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Xl7sGU37uBpy",
      "metadata": {
        "id": "Xl7sGU37uBpy"
      },
      "source": [
        "1.3 Use label smoothing for model regularization, as described in Szegedy et al. (2016)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Md9ieQawuDWT",
      "metadata": {
        "id": "Md9ieQawuDWT"
      },
      "outputs": [],
      "source": [
        "class LSRGoogleNet(GoogleNet):\n",
        "    def __init__(self, eps=0, lr=0.1, num_classes=10):\n",
        "        super().__init__(lr=lr, num_classes=num_classes)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def loss(self, y_hat, y, averaged=True):\n",
        "        y_hat = y_hat.reshape((-1, y_hat.shape[-1]))\n",
        "        y = y.reshape((-1,))\n",
        "        u = torch.ones(y.shape).tye(torch.float32)/y.shape[-1]\n",
        "        lsr_loss = (1-self.eps)*F.cross_entropy(y_hat, y, reduction='mean' if averaged else 'none')\n",
        "        +self.eps*F.cross_entropy(y_hat, u, reduction='mean' if averaged else 'none')\n",
        "        return lsr_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yyt33Hpxun0A",
      "metadata": {
        "id": "yyt33Hpxun0A"
      },
      "source": [
        "1.4 Make further adjustments to the Inception block by adding residual connection (Szegedy et al., 2017), as described later in Section 8.6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o5UQ24V9uE7G",
      "metadata": {
        "id": "o5UQ24V9uE7G"
      },
      "outputs": [],
      "source": [
        "class ResInception(nn.Module):\n",
        "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
        "        super().__init__(*kwargs)\n",
        "        self.b1 = nn.Sequential(nn.LazyConv2d(c1, kernel_size=1),\n",
        "                                nn.LazyBatchNorm2d(),\n",
        "                                nn.ReLU())\n",
        "        self.b2 = nn.Sequential(nn.LazyConv2d(c2[0], kernel_size=1),\n",
        "                                nn.LazyBatchNorm2d(),\n",
        "                                nn.ReLU(),\n",
        "                                nn.LazyConv2d(c2[1], kernel_size=3, padding=1),\n",
        "                                nn.LazyBatchNorm2d(),\n",
        "                                nn.ReLU())\n",
        "        self.b3 = nn.Sequential(nn.LazyConv2d(c3[0], kernel_size=1),\n",
        "                                nn.LazyBatchNorm2d(),\n",
        "                                nn.ReLU(),\n",
        "                                nn.LazyConv2d(c3[1], kernel_size=5, padding=2),\n",
        "                                nn.LazyBatchNorm2d(),\n",
        "                                nn.ReLU())\n",
        "        self.b4 = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "                                nn.LazyBatchNorm2d(),\n",
        "                                nn.LazyConv2d(c4, kernel_size=1),\n",
        "                                nn.LazyBatchNorm2d(),\n",
        "                                nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        o1 = self.b1(x)+x\n",
        "        o2 = self.b2(x)+x\n",
        "        o3 = self.b3(x)+x\n",
        "        o4 = self.b4(x)+x\n",
        "        return torch.cat((o1,o2,o3,o4),dim=1)\n",
        "\n",
        "class ResGoogleNet(d2l.Classifier):\n",
        "    def b1(self):\n",
        "        return nn.Sequential(nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "                             nn.LazyBatchNorm2d(),\n",
        "                             nn.ReLU(),\n",
        "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "    def b2(self):\n",
        "        return nn.Sequential(nn.LazyConv2d(64, kernel_size=1),\n",
        "                             nn.LazyBatchNorm2d(),nn.ReLU(),\n",
        "                             nn.LazyConv2d(192, kernel_size=3, padding=1),\n",
        "                             nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "    def b3(self):\n",
        "        return nn.Sequential(ResInception(64, (96, 128), (16, 32), 32),\n",
        "                             ResInception(128, (128, 192), (32, 96), 64),\n",
        "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "    def b4(self):\n",
        "        return nn.Sequential(ResInception(192, (96, 208), (16, 48), 64),\n",
        "                             ResInception(160, (112, 224), (24, 64), 64),\n",
        "                             ResInception(128, (128, 256), (24, 64), 64),\n",
        "                             ResInception(112, (144, 288), (32, 64), 64),\n",
        "                             ResInception(256, (160, 320), (32, 128), 128),\n",
        "                             nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "    def b5(self):\n",
        "        return nn.Sequential(ResInception(256, (160, 320), (32, 128), 128),\n",
        "                             ResInception(384, (192, 384), (48, 128), 128),\n",
        "                             nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())\n",
        "\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(self.b1(), self.b2(), self.b3(), self.b4(),\n",
        "                                 self.b5(), nn.LazyLinear(num_classes))\n",
        "        self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QEGVhTWrutZY",
      "metadata": {
        "id": "QEGVhTWrutZY"
      },
      "source": [
        " No. 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "raSOgzNnuvgR",
      "metadata": {
        "id": "raSOgzNnuvgR"
      },
      "source": [
        "2. As GoogleNet halve the image 5 times, so the mininum image size needed is 2^5=32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5VHVXKekuuwY",
      "metadata": {
        "id": "5VHVXKekuuwY"
      },
      "outputs": [],
      "source": [
        "model = GoogleNet(lr=0.01)\n",
        "X = torch.randn(1,1,32,32)\n",
        "model(X)\n",
        "for m in model.net:\n",
        "    X = m(X)\n",
        "    print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wrRPWjFGu50G",
      "metadata": {
        "id": "wrRPWjFGu50G"
      },
      "outputs": [],
      "source": [
        "model = GoogleNet(lr=0.01)\n",
        "X = torch.randn(1,1,64,64)\n",
        "model(X)\n",
        "for m in model.net:\n",
        "    X = m(X)\n",
        "    print(X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nGnXWXULu8c3",
      "metadata": {
        "id": "nGnXWXULu8c3"
      },
      "source": [
        " No. 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rSAsnNG7vYmi",
      "metadata": {
        "id": "rSAsnNG7vYmi"
      },
      "source": [
        "Can you design a variant of GoogLeNet that works on Fashion-MNIST’s native resolution of 28×28 pixels? How would you need to change the stem, the body, and the head of the network, if anything at all?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g6vxmiLZvdjG",
      "metadata": {
        "id": "g6vxmiLZvdjG"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ie5s5mjDvW0z",
      "metadata": {
        "id": "Ie5s5mjDvW0z"
      },
      "outputs": [],
      "source": [
        "class SmallGoogLeNet():\n",
        "    def b1(self):\n",
        "        return nn.Sequential(nn.LazyConv2d(64, kernel_size=5, stride=1, padding=2),\n",
        "                             nn.ReLU(),\n",
        "                             # nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "                            )\n",
        "\n",
        "     def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(self.b1(),self.b2(), self.b3(), self.b4(),\n",
        "                                 self.b5(), nn.LazyLinear(num_classes))\n",
        "        self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qrImsLcFv8yw",
      "metadata": {
        "id": "qrImsLcFv8yw"
      },
      "source": [
        "No. 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GHRAhTn4wAB2",
      "metadata": {
        "id": "GHRAhTn4wAB2"
      },
      "source": [
        "Compare the model parameter sizes of AlexNet, VGG, NiN, and GoogLeNet. How do the latter two network architectures significantly reduce the model parameter size?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B3vwkUGDwqD0",
      "metadata": {
        "id": "B3vwkUGDwqD0"
      },
      "source": [
        "NiN dan GoogLeNet secara signifikan mengurangi jumlah parameter melalui penggunaan konvolusi 1x1 dan modul inception. Teknik ini memungkinkan model menangkap fitur dengan efisien sambil menjaga jumlah parameter tetap terkendali. Konvolusi 1x1 berfungsi sebagai lapisan bottleneck yang mengurangi dimensi peta fitur, sehingga mengurangi jumlah parameter di lapisan berikutnya."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "duqBuGenwtAd",
      "metadata": {
        "id": "duqBuGenwtAd"
      },
      "source": [
        "Berikut adalah ukuran parameter dari keempat model tersebut:\n",
        "\n",
        "GoogLeNet: 5983802\n",
        "\n",
        "NiN: 2015398\n",
        "\n",
        "vgg: 128807306\n",
        "\n",
        "alexnet: 46787978"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jQqVlXTLv_nA",
      "metadata": {
        "id": "jQqVlXTLv_nA"
      },
      "outputs": [],
      "source": [
        "model = GoogleNet(lr=0.01)\n",
        "X = torch.randn(1,3, 224, 224)\n",
        "_ = model(X)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(\"Total parameters:\", total_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "onHYjeBew9u5",
      "metadata": {
        "id": "onHYjeBew9u5"
      },
      "source": [
        "No. 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yETjOpNPxBNV",
      "metadata": {
        "id": "yETjOpNPxBNV"
      },
      "source": [
        "Compare the amount of computation needed in GoogLeNet and AlexNet. How does this affect the design of an accelerator chip, e.g., in terms of memory size, memory bandwidth, cache size, the amount of computation, and the benefit of specialized operations?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YqgQ9wOoyCyZ",
      "metadata": {
        "id": "YqgQ9wOoyCyZ"
      },
      "source": [
        "GoogLeNet dan AlexNet memiliki perbedaan signifikan dalam kebutuhan komputasi akibat desain arsitekturnya. GoogLeNet menggunakan modul inception dengan jalur konvolusi paralel dan konvolusi 1x1, yang mengurangi jumlah parameter dan komputasi, serta meningkatkan efisiensi penggunaan memori dan bandwidth. Sebaliknya, AlexNet memiliki arsitektur yang lebih sederhana dengan lebih banyak lapisan konvolusi dan pooling, namun membutuhkan komputasi lebih tinggi karena ukuran filter yang seragam dan struktur yang lebih dalam.\n",
        "\n",
        "Dalam desain chip akselerator, GoogLeNet memerlukan ukuran memori lebih kecil karena penggunaan jalur paralel, sementara AlexNet mungkin membutuhkan memori lebih besar. GoogLeNet juga memanfaatkan bandwidth memori lebih efisien dan cache lebih besar bisa membantu kedua arsitektur. Akselerator juga dapat dioptimalkan untuk operasi khusus seperti konvolusi 1x1 di GoogLeNet untuk meningkatkan performa.\n",
        "\n",
        "Perbedaan ini mempengaruhi desain chip dalam hal ukuran memori, bandwidth, cache, dan operasi khusus untuk memaksimalkan efisiensi dan performa chip berdasarkan karakteristik model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ugE_6SLJyNkl",
      "metadata": {
        "id": "ugE_6SLJyNkl"
      },
      "source": [
        "#8.5 Batch Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8502f85",
      "metadata": {
        "id": "c8502f85"
      },
      "source": [
        "# Batch Normalization\n",
        ":label:`sec_batch_norm`\n",
        "\n",
        "Training deep neural networks is difficult.\n",
        "Getting them to converge in a reasonable amount of time can be tricky.\n",
        "In this section, we describe *batch normalization*, a popular and effective technique\n",
        "that consistently accelerates the convergence of deep networks :cite:`Ioffe.Szegedy.2015`.\n",
        "Together with residual blocks---covered later in :numref:`sec_resnet`---batch normalization\n",
        "has made it possible for practitioners to routinely train networks with over 100 layers.\n",
        "A secondary (serendipitous) benefit of batch normalization lies in its inherent regularization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K76HpfFxw_vl",
      "metadata": {
        "id": "K76HpfFxw_vl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85aa6aae",
      "metadata": {
        "id": "85aa6aae"
      },
      "source": [
        "## Training Deep Networks\n",
        "\n",
        "When working with data, we often preprocess before training.\n",
        "Choices regarding data preprocessing often make an enormous difference in the final results.\n",
        "Recall our application of MLPs to predicting house prices (:numref:`sec_kaggle_house`).\n",
        "Our first step when working with real data\n",
        "was to standardize our input features to have\n",
        "zero mean $\\boldsymbol{\\mu} = 0$ and unit variance $\\boldsymbol{\\Sigma} = \\boldsymbol{1}$ across multiple observations :cite:`friedman1987exploratory`, frequently rescaling the latter so  that the diagonal is unity, i.e., $\\Sigma_{ii} = 1$.\n",
        "Yet another strategy is to rescale vectors to unit length, possibly zero mean *per observation*.\n",
        "This can work well, e.g., for spatial sensor data. These preprocessing techniques and many others, are\n",
        "beneficial for keeping the estimation problem well controlled.\n",
        "For a review of feature selection and extraction see the article of :citet:`guyon2008feature`, for example.\n",
        "Standardizing vectors also has the nice side-effect of constraining the function complexity of functions that act upon it. For instance, the celebrated radius-margin bound :cite:`Vapnik95` in support vector machines and the Perceptron Convergence Theorem :cite:`Novikoff62` rely on inputs of bounded norm.\n",
        "\n",
        "Intuitively, this standardization plays nicely with our optimizers\n",
        "since it puts the parameters *a priori* on a similar scale.\n",
        "As such, it is only natural to ask whether a corresponding normalization step *inside* a deep network\n",
        "might not be beneficial. While this is not quite the reasoning that led to the invention of batch normalization :cite:`Ioffe.Szegedy.2015`, it is a useful way of understanding it and its cousin, layer normalization :cite:`Ba.Kiros.Hinton.2016`, within a unified framework.\n",
        "\n",
        "Second, for a typical MLP or CNN, as we train,\n",
        "the variables\n",
        "in intermediate layers (e.g., affine transformation outputs in MLP)\n",
        "may take values with widely varying magnitudes:\n",
        "whether along the layers from input to output, across units in the same layer,\n",
        "and over time due to our updates to the model parameters.\n",
        "The inventors of batch normalization postulated informally\n",
        "that this drift in the distribution of such variables could hamper the convergence of the network.\n",
        "Intuitively, we might conjecture that if one\n",
        "layer has variable activations that are 100 times that of another layer,\n",
        "this might necessitate compensatory adjustments in the learning rates. Adaptive solvers\n",
        "such as AdaGrad :cite:`Duchi.Hazan.Singer.2011`, Adam :cite:`Kingma.Ba.2014`, Yogi :cite:`Zaheer.Reddi.Sachan.ea.2018`, or Distributed Shampoo :cite:`anil2020scalable` aim to address this from the viewpoint of optimization, e.g., by adding aspects of second-order methods.\n",
        "The alternative is to prevent the problem from occurring, simply by adaptive normalization.\n",
        "\n",
        "Third, deeper networks are complex and tend to be more liable to overfitting.\n",
        "This means that regularization becomes more critical. A common technique for regularization is noise\n",
        "injection. This has been known for a long time, e.g., with regard to noise injection for the\n",
        "inputs :cite:`Bishop.1995`. It also forms the basis of dropout in :numref:`sec_dropout`. As it turns out, quite serendipitously, batch normalization conveys all three benefits: preprocessing, numerical stability, and regularization.\n",
        "\n",
        "Batch normalization is applied to individual layers, or optionally, to all of them:\n",
        "In each training iteration,\n",
        "we first normalize the inputs (of batch normalization)\n",
        "by subtracting their mean and\n",
        "dividing by their standard deviation,\n",
        "where both are estimated based on the statistics of the current minibatch.\n",
        "Next, we apply a scale coefficient and an offset to recover the lost degrees\n",
        "of freedom. It is precisely due to this *normalization* based on *batch* statistics\n",
        "that *batch normalization* derives its name.\n",
        "\n",
        "Note that if we tried to apply batch normalization with minibatches of size 1,\n",
        "we would not be able to learn anything.\n",
        "That is because after subtracting the means,\n",
        "each hidden unit would take value 0.\n",
        "As you might guess, since we are devoting a whole section to batch normalization,\n",
        "with large enough minibatches the approach proves effective and stable.\n",
        "One takeaway here is that when applying batch normalization,\n",
        "the choice of batch size is\n",
        "even more significant than without batch normalization, or at least,\n",
        "suitable calibration is needed as we might adjust batch size.\n",
        "\n",
        "Denote by $\\mathcal{B}$ a minibatch and let $\\mathbf{x} \\in \\mathcal{B}$ be an input to\n",
        "batch normalization ($\\textrm{BN}$). In this case the batch normalization is defined as follows:\n",
        "\n",
        "$$\\textrm{BN}(\\mathbf{x}) = \\boldsymbol{\\gamma} \\odot \\frac{\\mathbf{x} - \\hat{\\boldsymbol{\\mu}}_\\mathcal{B}}{\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}} + \\boldsymbol{\\beta}.$$\n",
        ":eqlabel:`eq_batchnorm`\n",
        "\n",
        "In :eqref:`eq_batchnorm`,\n",
        "$\\hat{\\boldsymbol{\\mu}}_\\mathcal{B}$ is the  sample mean\n",
        "and $\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}$ is the sample standard deviation of the minibatch $\\mathcal{B}$.\n",
        "After applying standardization,\n",
        "the resulting minibatch\n",
        "has zero mean and unit variance.\n",
        "The choice of unit variance\n",
        "(rather than some other magic number) is arbitrary. We recover this degree of freedom\n",
        "by including an elementwise\n",
        "*scale parameter* $\\boldsymbol{\\gamma}$ and *shift parameter* $\\boldsymbol{\\beta}$\n",
        "that have the same shape as $\\mathbf{x}$. Both are parameters that\n",
        "need to be learned as part of model training.\n",
        "\n",
        "The variable magnitudes\n",
        "for intermediate layers cannot diverge during training\n",
        "since batch normalization actively centers and rescales them back\n",
        "to a given mean and size (via $\\hat{\\boldsymbol{\\mu}}_\\mathcal{B}$ and ${\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}}$).\n",
        "Practical experience confirms that, as alluded to when discussing feature rescaling, batch normalization seems to allow for more aggressive learning rates.\n",
        "We calculate $\\hat{\\boldsymbol{\\mu}}_\\mathcal{B}$ and ${\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}}$ in :eqref:`eq_batchnorm` as follows:\n",
        "\n",
        "$$\\hat{\\boldsymbol{\\mu}}_\\mathcal{B} = \\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x} \\in \\mathcal{B}} \\mathbf{x}\n",
        "\\textrm{ and }\n",
        "\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}^2 = \\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x} \\in \\mathcal{B}} (\\mathbf{x} - \\hat{\\boldsymbol{\\mu}}_{\\mathcal{B}})^2 + \\epsilon.$$\n",
        "\n",
        "Note that we add a small constant $\\epsilon > 0$\n",
        "to the variance estimate\n",
        "to ensure that we never attempt division by zero,\n",
        "even in cases where the empirical variance estimate might be very small or vanish.\n",
        "The estimates $\\hat{\\boldsymbol{\\mu}}_\\mathcal{B}$ and ${\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}}$ counteract the scaling issue\n",
        "by using noisy estimates of mean and variance.\n",
        "You might think that this noisiness should be a problem.\n",
        "On the contrary, it is actually beneficial.\n",
        "\n",
        "This turns out to be a recurring theme in deep learning.\n",
        "For reasons that are not yet well-characterized theoretically,\n",
        "various sources of noise in optimization\n",
        "often lead to faster training and less overfitting:\n",
        "this variation appears to act as a form of regularization.\n",
        ":citet:`Teye.Azizpour.Smith.2018` and :citet:`Luo.Wang.Shao.ea.2018`\n",
        "related the properties of batch normalization to Bayesian priors and penalties, respectively.\n",
        "In particular, this sheds some light on the puzzle\n",
        "of why batch normalization works best for moderate minibatch sizes in the 50--100 range.\n",
        "This particular size of minibatch seems to inject just the \"right amount\" of noise per layer, both in terms of scale via $\\hat{\\boldsymbol{\\sigma}}$, and in terms of offset via $\\hat{\\boldsymbol{\\mu}}$: a\n",
        "larger minibatch regularizes less due to the more stable estimates, whereas tiny minibatches\n",
        "destroy useful signal due to high variance. Exploring this direction further, considering alternative types\n",
        "of preprocessing and filtering may yet lead to other effective types of regularization.\n",
        "\n",
        "Fixing a trained model, you might think\n",
        "that we would prefer using the entire dataset\n",
        "to estimate the mean and variance.\n",
        "Once training is complete, why would we want\n",
        "the same image to be classified differently,\n",
        "depending on the batch in which it happens to reside?\n",
        "During training, such exact calculation is infeasible\n",
        "because the intermediate variables\n",
        "for all data examples\n",
        "change every time we update our model.\n",
        "However, once the model is trained,\n",
        "we can calculate the means and variances\n",
        "of each layer's variables based on the entire dataset.\n",
        "Indeed this is standard practice for\n",
        "models employing batch normalization;\n",
        "thus batch normalization layers function differently\n",
        "in *training mode* (normalizing by minibatch statistics)\n",
        "than in *prediction mode* (normalizing by dataset statistics).\n",
        "In this form they closely resemble the behavior of dropout regularization of :numref:`sec_dropout`,\n",
        "where noise is only injected during training.\n",
        "\n",
        "\n",
        "## Batch Normalization Layers\n",
        "\n",
        "Batch normalization implementations for fully connected layers\n",
        "and convolutional layers are slightly different.\n",
        "One key difference between batch normalization and other layers\n",
        "is that because the former operates on a full minibatch at a time,\n",
        "we cannot just ignore the batch dimension\n",
        "as we did before when introducing other layers.\n",
        "\n",
        "### Fully Connected Layers\n",
        "\n",
        "When applying batch normalization to fully connected layers,\n",
        ":citet:`Ioffe.Szegedy.2015`, in their original paper inserted batch normalization after the affine transformation\n",
        "and *before* the nonlinear activation function. Later applications experimented with\n",
        "inserting batch normalization right *after* activation functions.\n",
        "Denoting the input to the fully connected layer by $\\mathbf{x}$,\n",
        "the affine transformation\n",
        "by $\\mathbf{W}\\mathbf{x} + \\mathbf{b}$ (with the weight parameter $\\mathbf{W}$ and the bias parameter $\\mathbf{b}$),\n",
        "and the activation function by $\\phi$,\n",
        "we can express the computation of a batch-normalization-enabled,\n",
        "fully connected layer output $\\mathbf{h}$ as follows:\n",
        "\n",
        "$$\\mathbf{h} = \\phi(\\textrm{BN}(\\mathbf{W}\\mathbf{x} + \\mathbf{b}) ).$$\n",
        "\n",
        "Recall that mean and variance are computed\n",
        "on the *same* minibatch\n",
        "on which the transformation is applied.\n",
        "\n",
        "### Convolutional Layers\n",
        "\n",
        "Similarly, with convolutional layers,\n",
        "we can apply batch normalization after the convolution\n",
        "but before the nonlinear activation function. The key difference from batch normalization\n",
        "in fully connected layers is that we apply the operation on a per-channel basis\n",
        "*across all locations*. This is compatible with our assumption of translation\n",
        "invariance that led to convolutions: we assumed that the specific location of a pattern\n",
        "within an image was not critical for the purpose of understanding.\n",
        "\n",
        "Assume that our minibatches contain $m$ examples\n",
        "and that for each channel,\n",
        "the output of the convolution has height $p$ and width $q$.\n",
        "For convolutional layers, we carry out each batch normalization\n",
        "over the $m \\cdot p \\cdot q$ elements per output channel simultaneously.\n",
        "Thus, we collect the values over all spatial locations\n",
        "when computing the mean and variance\n",
        "and consequently\n",
        "apply the same mean and variance\n",
        "within a given channel\n",
        "to normalize the value at each spatial location.\n",
        "Each channel has its own scale and shift parameters,\n",
        "both of which are scalars.\n",
        "\n",
        "### Layer Normalization\n",
        ":label:`subsec_layer-normalization-in-bn`\n",
        "\n",
        "Note that in the context of convolutions the batch normalization is well defined even for\n",
        "minibatches of size 1: after all, we have all the locations across an image to average. Consequently,\n",
        "mean and variance are well defined, even if it is just within a single observation. This consideration\n",
        "led :citet:`Ba.Kiros.Hinton.2016` to introduce the notion of *layer normalization*. It works just like\n",
        "a batch norm, only that it is applied to one observation at a time. Consequently both the offset and the scaling factor are scalars. For an $n$-dimensional vector $\\mathbf{x}$, layer norms are given by\n",
        "\n",
        "$$\\mathbf{x} \\rightarrow \\textrm{LN}(\\mathbf{x}) =  \\frac{\\mathbf{x} - \\hat{\\mu}}{\\hat\\sigma},$$\n",
        "\n",
        "where scaling and offset are applied coefficient-wise\n",
        "and given by\n",
        "\n",
        "$$\\hat{\\mu} \\stackrel{\\textrm{def}}{=} \\frac{1}{n} \\sum_{i=1}^n x_i \\textrm{ and }\n",
        "\\hat{\\sigma}^2 \\stackrel{\\textrm{def}}{=} \\frac{1}{n} \\sum_{i=1}^n (x_i - \\hat{\\mu})^2 + \\epsilon.$$\n",
        "\n",
        "As before we add a small offset $\\epsilon > 0$ to prevent division by zero. One of the major benefits of using layer normalization is that it prevents divergence. After all, ignoring $\\epsilon$, the output of the layer normalization is scale independent. That is, we have $\\textrm{LN}(\\mathbf{x}) \\approx \\textrm{LN}(\\alpha \\mathbf{x})$ for any choice of $\\alpha \\neq 0$. This becomes an equality for $|\\alpha| \\to \\infty$ (the approximate equality is due to the offset $\\epsilon$ for the variance).\n",
        "\n",
        "Another advantage of the layer normalization is that it does not depend on the minibatch size. It is also independent of whether we are in training or test regime. In other words, it is simply a deterministic transformation that standardizes the activations to a given scale. This can be very beneficial in preventing divergence in optimization. We skip further details and recommend that interested readers consult the original paper.\n",
        "\n",
        "### Batch Normalization During Prediction\n",
        "\n",
        "As we mentioned earlier, batch normalization typically behaves differently\n",
        "in training mode than in prediction mode.\n",
        "First, the noise in the sample mean and the sample variance\n",
        "arising from estimating each on minibatches\n",
        "is no longer desirable once we have trained the model.\n",
        "Second, we might not have the luxury\n",
        "of computing per-batch normalization statistics.\n",
        "For example,\n",
        "we might need to apply our model to make one prediction at a time.\n",
        "\n",
        "Typically, after training, we use the entire dataset\n",
        "to compute stable estimates of the variable statistics\n",
        "and then fix them at prediction time.\n",
        "Hence, batch normalization behaves differently during training than at test time.\n",
        "Recall that dropout also exhibits this characteristic.\n",
        "\n",
        "## (**Implementation from Scratch**)\n",
        "\n",
        "To see how batch normalization works in practice, we implement one from scratch below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4pSMO-ARye3r",
      "metadata": {
        "id": "4pSMO-ARye3r"
      },
      "outputs": [],
      "source": [
        "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
        "    # Use is_grad_enabled to determine whether we are in training mode\n",
        "    if not torch.is_grad_enabled():\n",
        "        # In prediction mode, use mean and variance obtained by moving average\n",
        "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
        "    else:\n",
        "        assert len(X.shape) in (2, 4)\n",
        "        if len(X.shape) == 2:\n",
        "            # When using a fully connected layer, calculate the mean and\n",
        "            # variance on the feature dimension\n",
        "            mean = X.mean(dim=0)\n",
        "            var = ((X - mean) ** 2).mean(dim=0)\n",
        "        else:\n",
        "            # When using a two-dimensional convolutional layer, calculate the\n",
        "            # mean and variance on the channel dimension (axis=1). Here we\n",
        "            # need to maintain the shape of X, so that the broadcasting\n",
        "            # operation can be carried out later\n",
        "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
        "            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
        "        # In training mode, the current mean and variance are used\n",
        "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
        "        # Update the mean and variance using moving average\n",
        "        moving_mean = (1.0 - momentum) * moving_mean + momentum * mean\n",
        "        moving_var = (1.0 - momentum) * moving_var + momentum * var\n",
        "    Y = gamma * X_hat + beta  # Scale and shift\n",
        "    return Y, moving_mean.data, moving_var.data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49370dea",
      "metadata": {
        "id": "49370dea"
      },
      "source": [
        "We can now [**create a proper `BatchNorm` layer.**]\n",
        "Our layer will maintain proper parameters\n",
        "for scale `gamma` and shift `beta`,\n",
        "both of which will be updated in the course of training.\n",
        "Additionally, our layer will maintain\n",
        "moving averages of the means and variances\n",
        "for subsequent use during model prediction.\n",
        "\n",
        "Putting aside the algorithmic details,\n",
        "note the design pattern underlying our implementation of the layer.\n",
        "Typically, we define the mathematics in a separate function, say `batch_norm`.\n",
        "We then integrate this functionality into a custom layer,\n",
        "whose code mostly addresses bookkeeping matters,\n",
        "such as moving data to the right device context,\n",
        "allocating and initializing any required variables,\n",
        "keeping track of moving averages (here for mean and variance), and so on.\n",
        "This pattern enables a clean separation of mathematics from boilerplate code.\n",
        "Also note that for the sake of convenience\n",
        "we did not worry about automatically inferring the input shape here;\n",
        "thus we need to specify the number of features throughout.\n",
        "By now all modern deep learning frameworks offer automatic detection of size and shape in the\n",
        "high-level batch normalization APIs (in practice we will use this instead).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Tr6gwldjyoYO",
      "metadata": {
        "id": "Tr6gwldjyoYO"
      },
      "outputs": [],
      "source": [
        "class BatchNorm(nn.Module):\n",
        "    # num_features: the number of outputs for a fully connected layer or the\n",
        "    # number of output channels for a convolutional layer. num_dims: 2 for a\n",
        "    # fully connected layer and 4 for a convolutional layer\n",
        "    def __init__(self, num_features, num_dims):\n",
        "        super().__init__()\n",
        "        if num_dims == 2:\n",
        "            shape = (1, num_features)\n",
        "        else:\n",
        "            shape = (1, num_features, 1, 1)\n",
        "        # The scale parameter and the shift parameter (model parameters) are\n",
        "        # initialized to 1 and 0, respectively\n",
        "        self.gamma = nn.Parameter(torch.ones(shape))\n",
        "        self.beta = nn.Parameter(torch.zeros(shape))\n",
        "        # The variables that are not model parameters are initialized to 0 and\n",
        "        # 1\n",
        "        self.moving_mean = torch.zeros(shape)\n",
        "        self.moving_var = torch.ones(shape)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # If X is not on the main memory, copy moving_mean and moving_var to\n",
        "        # the device where X is located\n",
        "        if self.moving_mean.device != X.device:\n",
        "            self.moving_mean = self.moving_mean.to(X.device)\n",
        "            self.moving_var = self.moving_var.to(X.device)\n",
        "        # Save the updated moving_mean and moving_var\n",
        "        Y, self.moving_mean, self.moving_var = batch_norm(\n",
        "            X, self.gamma, self.beta, self.moving_mean,\n",
        "            self.moving_var, eps=1e-5, momentum=0.1)\n",
        "        return Y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e8bc89f",
      "metadata": {
        "id": "7e8bc89f"
      },
      "source": [
        "We used `momentum` to govern the aggregation over past mean and variance estimates. This is somewhat of a misnomer as it has nothing whatsoever to do with the *momentum* term of optimization. Nonetheless, it is the commonly adopted name for this term and in deference to API naming convention we use the same variable name in our code.\n",
        "\n",
        "## [**LeNet with Batch Normalization**]\n",
        "\n",
        "To see how to apply `BatchNorm` in context,\n",
        "below we apply it to a traditional LeNet model (:numref:`sec_lenet`).\n",
        "Recall that batch normalization is applied\n",
        "after the convolutional layers or fully connected layers\n",
        "but before the corresponding activation functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zz7IXGGsytMO",
      "metadata": {
        "id": "zz7IXGGsytMO"
      },
      "outputs": [],
      "source": [
        "class BNLeNetScratch(d2l.Classifier):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(6, kernel_size=5), BatchNorm(6, num_dims=4),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.LazyConv2d(16, kernel_size=5), BatchNorm(16, num_dims=4),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(), nn.LazyLinear(120),\n",
        "            BatchNorm(120, num_dims=2), nn.Sigmoid(), nn.LazyLinear(84),\n",
        "            BatchNorm(84, num_dims=2), nn.Sigmoid(),\n",
        "            nn.LazyLinear(num_classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e842386f",
      "metadata": {
        "id": "e842386f"
      },
      "source": [
        "As before, we will [**train our network on the Fashion-MNIST dataset**].\n",
        "This code is virtually identical to that when we first trained LeNet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O0w_c5EMyxxk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "O0w_c5EMyxxk",
        "outputId": "f736ebc3-25e1-451a-8324-886d134b2fb0"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-10-03T14:34:33.424436</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 238.965625 183.35625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"mce5387b435\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mce5387b435\" x=\"30.103125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.921875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#mce5387b435\" x=\"69.163125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(65.981875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#mce5387b435\" x=\"108.223125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(105.041875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#mce5387b435\" x=\"147.283125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(144.101875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#mce5387b435\" x=\"186.343125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(183.161875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#mce5387b435\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m850e417156\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m850e417156\" x=\"30.103125\" y=\"118.693022\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 122.492241) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m850e417156\" x=\"30.103125\" y=\"79.215213\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 83.014432) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m850e417156\" x=\"30.103125\" y=\"39.737404\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 43.536623) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_10\">\n    <path d=\"M 34.954394 13.5 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_11\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 49.633125 74.209267 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_14\"/>\n   <g id=\"line2d_15\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 49.633125 74.209267 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 49.633125 43.028523 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 49.633125 74.209267 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 49.633125 43.028523 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 49.633125 74.209267 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 49.633125 43.028523 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path d=\"M 49.633125 43.028523 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_34\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_35\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_40\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_44\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_45\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_46\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_47\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_48\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_50\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_53\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_54\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_56\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_57\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_58\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_59\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_60\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_61\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_62\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_63\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_64\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_65\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_66\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_67\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_68\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_69\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_70\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_71\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_72\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_73\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_74\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_75\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_76\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_77\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \nL 147.283125 32.23381 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_78\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \nL 151.884543 132.399359 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_79\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_80\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \nL 147.283125 32.23381 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_81\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \nL 151.884543 132.399359 \nL 161.628722 133.476607 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_82\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_83\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \nL 147.283125 32.23381 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_84\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \nL 151.884543 132.399359 \nL 161.628722 133.476607 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_85\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \nL 166.813125 94.976673 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_86\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \nL 147.283125 32.23381 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_87\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \nL 151.884543 132.399359 \nL 161.628722 133.476607 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_88\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \nL 166.813125 94.976673 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_89\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \nL 147.283125 32.23381 \nL 166.813125 40.471367 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_90\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \nL 151.884543 132.399359 \nL 161.628722 133.476607 \nL 171.372901 135.31518 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_91\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \nL 166.813125 94.976673 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_92\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \nL 147.283125 32.23381 \nL 166.813125 40.471367 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_93\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \nL 151.884543 132.399359 \nL 161.628722 133.476607 \nL 171.372901 135.31518 \nL 181.11708 135.573012 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_94\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \nL 166.813125 94.976673 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_95\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \nL 147.283125 32.23381 \nL 166.813125 40.471367 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_96\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \nL 151.884543 132.399359 \nL 161.628722 133.476607 \nL 171.372901 135.31518 \nL 181.11708 135.573012 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_97\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \nL 166.813125 94.976673 \nL 186.343125 118.152607 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_98\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \nL 147.283125 32.23381 \nL 166.813125 40.471367 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_99\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \nL 151.884543 132.399359 \nL 161.628722 133.476607 \nL 171.372901 135.31518 \nL 181.11708 135.573012 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_100\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \nL 166.813125 94.976673 \nL 186.343125 118.152607 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_101\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \nL 147.283125 32.23381 \nL 166.813125 40.471367 \nL 186.343125 28.934883 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_102\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \nL 151.884543 132.399359 \nL 161.628722 133.476607 \nL 171.372901 135.31518 \nL 181.11708 135.573012 \nL 190.861259 137.007875 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_103\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \nL 166.813125 94.976673 \nL 186.343125 118.152607 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_104\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \nL 147.283125 32.23381 \nL 166.813125 40.471367 \nL 186.343125 28.934883 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_105\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \nL 151.884543 132.399359 \nL 161.628722 133.476607 \nL 171.372901 135.31518 \nL 181.11708 135.573012 \nL 190.861259 137.007875 \nL 200.605438 138.183872 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_106\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \nL 166.813125 94.976673 \nL 186.343125 118.152607 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_107\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \nL 147.283125 32.23381 \nL 166.813125 40.471367 \nL 186.343125 28.934883 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_108\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \nL 151.884543 132.399359 \nL 161.628722 133.476607 \nL 171.372901 135.31518 \nL 181.11708 135.573012 \nL 190.861259 137.007875 \nL 200.605438 138.183872 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_109\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \nL 166.813125 94.976673 \nL 186.343125 118.152607 \nL 205.873125 130.024299 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_110\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \nL 147.283125 32.23381 \nL 166.813125 40.471367 \nL 186.343125 28.934883 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_111\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \nL 151.884543 132.399359 \nL 161.628722 133.476607 \nL 171.372901 135.31518 \nL 181.11708 135.573012 \nL 190.861259 137.007875 \nL 200.605438 138.183872 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_112\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \nL 166.813125 94.976673 \nL 186.343125 118.152607 \nL 205.873125 130.024299 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_113\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \nL 147.283125 32.23381 \nL 166.813125 40.471367 \nL 186.343125 28.934883 \nL 205.873125 24.718503 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_114\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \nL 151.884543 132.399359 \nL 161.628722 133.476607 \nL 171.372901 135.31518 \nL 181.11708 135.573012 \nL 190.861259 137.007875 \nL 200.605438 138.183872 \nL 210.349618 139.5 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_115\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \nL 166.813125 94.976673 \nL 186.343125 118.152607 \nL 205.873125 130.024299 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_116\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \nL 147.283125 32.23381 \nL 166.813125 40.471367 \nL 186.343125 28.934883 \nL 205.873125 24.718503 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_117\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \nL 151.884543 132.399359 \nL 161.628722 133.476607 \nL 171.372901 135.31518 \nL 181.11708 135.573012 \nL 190.861259 137.007875 \nL 200.605438 138.183872 \nL 210.349618 139.5 \nL 220.093797 139.040161 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_118\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \nL 166.813125 94.976673 \nL 186.343125 118.152607 \nL 205.873125 130.024299 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_119\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \nL 147.283125 32.23381 \nL 166.813125 40.471367 \nL 186.343125 28.934883 \nL 205.873125 24.718503 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_120\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \nL 151.884543 132.399359 \nL 161.628722 133.476607 \nL 171.372901 135.31518 \nL 181.11708 135.573012 \nL 190.861259 137.007875 \nL 200.605438 138.183872 \nL 210.349618 139.5 \nL 220.093797 139.040161 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_121\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \nL 166.813125 94.976673 \nL 186.343125 118.152607 \nL 205.873125 130.024299 \nL 225.403125 117.560245 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_122\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \nL 147.283125 32.23381 \nL 166.813125 40.471367 \nL 186.343125 28.934883 \nL 205.873125 24.718503 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_123\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 77.018202 \nL 54.442752 93.435757 \nL 64.186931 101.854116 \nL 73.93111 107.900682 \nL 83.675289 114.247052 \nL 93.419468 118.724998 \nL 103.163647 120.849458 \nL 112.907826 124.914549 \nL 122.652006 126.546386 \nL 132.396185 129.934337 \nL 142.140364 129.967108 \nL 151.884543 132.399359 \nL 161.628722 133.476607 \nL 171.372901 135.31518 \nL 181.11708 135.573012 \nL 190.861259 137.007875 \nL 200.605438 138.183872 \nL 210.349618 139.5 \nL 220.093797 139.040161 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_124\">\n    <path d=\"M 49.633125 74.209267 \nL 69.163125 81.352 \nL 88.693125 103.184407 \nL 108.223125 103.568538 \nL 127.753125 97.452994 \nL 147.283125 113.334204 \nL 166.813125 94.976673 \nL 186.343125 118.152607 \nL 205.873125 130.024299 \nL 225.403125 117.560245 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_125\">\n    <path d=\"M 49.633125 43.028523 \nL 69.163125 38.5779 \nL 88.693125 34.654324 \nL 108.223125 34.40056 \nL 127.753125 35.04473 \nL 147.283125 32.23381 \nL 166.813125 40.471367 \nL 186.343125 28.934883 \nL 205.873125 24.718503 \nL 225.403125 29.266727 \n\" clip-path=\"url(#pa327afba0e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 145.8 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 138.8125 100.434375 \nL 218.403125 100.434375 \nQ 220.403125 100.434375 220.403125 98.434375 \nL 220.403125 54.565625 \nQ 220.403125 52.565625 218.403125 52.565625 \nL 138.8125 52.565625 \nQ 136.8125 52.565625 136.8125 54.565625 \nL 136.8125 98.434375 \nQ 136.8125 100.434375 138.8125 100.434375 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_126\">\n     <path d=\"M 140.8125 60.664063 \nL 150.8125 60.664063 \nL 160.8125 60.664063 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_11\">\n     <!-- train_loss -->\n     <g transform=\"translate(168.8125 64.164063) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_127\">\n     <path d=\"M 140.8125 75.620313 \nL 150.8125 75.620313 \nL 160.8125 75.620313 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- val_loss -->\n     <g transform=\"translate(168.8125 79.120313) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n    <g id=\"line2d_128\">\n     <path d=\"M 140.8125 90.576563 \nL 150.8125 90.576563 \nL 160.8125 90.576563 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- val_acc -->\n     <g transform=\"translate(168.8125 94.076563) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pa327afba0e\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128)\n",
        "model = BNLeNetScratch(lr=0.1)\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27eb3037",
      "metadata": {
        "id": "27eb3037"
      },
      "source": [
        "Let's [**have a look at the scale parameter `gamma`\n",
        "and the shift parameter `beta`**] learned\n",
        "from the first batch normalization layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SV-p_R_Ty2DG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV-p_R_Ty2DG",
        "outputId": "fa159bfd-7019-46ab-d4c9-2ce2194e2b35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1.5203, 1.6631, 2.0408, 2.1231, 2.5169, 2.0203], device='cuda:0',\n",
              "        grad_fn=<ViewBackward0>),\n",
              " tensor([ 1.3502,  0.4369, -1.4063, -1.2190,  0.8170, -0.5103], device='cuda:0',\n",
              "        grad_fn=<ViewBackward0>))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.net[1].gamma.reshape((-1,)), model.net[1].beta.reshape((-1,))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6befcbce",
      "metadata": {
        "id": "6befcbce"
      },
      "source": [
        "## [**Concise Implementation**]\n",
        "\n",
        "Compared with the `BatchNorm` class,\n",
        "which we just defined ourselves,\n",
        "we can use the `BatchNorm` class defined in high-level APIs from the deep learning framework directly.\n",
        "The code looks virtually identical\n",
        "to our implementation above, except that we no longer need to provide additional arguments for it to get the dimensions right.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef2ab147",
      "metadata": {
        "id": "ef2ab147"
      },
      "outputs": [],
      "source": [
        "class BNLeNet(d2l.Classifier):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(6, kernel_size=5), nn.LazyBatchNorm2d(),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.LazyConv2d(16, kernel_size=5), nn.LazyBatchNorm2d(),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(), nn.LazyLinear(120), nn.LazyBatchNorm1d(),\n",
        "            nn.Sigmoid(), nn.LazyLinear(84), nn.LazyBatchNorm1d(),\n",
        "            nn.Sigmoid(), nn.LazyLinear(num_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d6aaf49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "0d6aaf49",
        "outputId": "035abf37-5abb-46c6-b996-bd44a2ee6441"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-10-03T14:39:13.930731</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 238.965625 183.35625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"md34dd9e5cd\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#md34dd9e5cd\" x=\"30.103125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.921875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#md34dd9e5cd\" x=\"69.163125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(65.981875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#md34dd9e5cd\" x=\"108.223125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(105.041875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#md34dd9e5cd\" x=\"147.283125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(144.101875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#md34dd9e5cd\" x=\"186.343125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(183.161875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#md34dd9e5cd\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m0b24e32a14\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m0b24e32a14\" x=\"30.103125\" y=\"121.041842\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 124.841061) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m0b24e32a14\" x=\"30.103125\" y=\"82.554479\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 86.353698) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m0b24e32a14\" x=\"30.103125\" y=\"44.067116\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 47.866335) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_10\">\n    <path d=\"M 34.954394 13.5 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_11\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 49.633125 82.041897 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_14\"/>\n   <g id=\"line2d_15\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 49.633125 82.041897 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 49.633125 44.573328 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 49.633125 82.041897 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 49.633125 44.573328 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 49.633125 82.041897 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 49.633125 44.573328 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path d=\"M 49.633125 44.573328 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_34\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_35\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_40\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_44\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_45\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_46\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_47\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_48\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_50\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_53\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_54\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_56\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_57\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_58\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_59\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_60\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_61\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_62\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_63\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_64\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_65\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_66\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_67\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_68\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_69\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_70\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_71\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_72\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_73\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_74\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_75\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_76\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_77\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \nL 147.283125 31.91802 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_78\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \nL 151.884543 132.178746 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_79\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_80\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \nL 147.283125 31.91802 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_81\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \nL 151.884543 132.178746 \nL 161.628722 132.699684 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_82\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_83\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \nL 147.283125 31.91802 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_84\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \nL 151.884543 132.178746 \nL 161.628722 132.699684 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_85\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \nL 166.813125 88.054329 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_86\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \nL 147.283125 31.91802 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_87\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \nL 151.884543 132.178746 \nL 161.628722 132.699684 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_88\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \nL 166.813125 88.054329 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_89\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \nL 147.283125 31.91802 \nL 166.813125 43.241191 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_90\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \nL 151.884543 132.178746 \nL 161.628722 132.699684 \nL 171.372901 134.680412 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_91\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \nL 166.813125 88.054329 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_92\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \nL 147.283125 31.91802 \nL 166.813125 43.241191 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_93\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \nL 151.884543 132.178746 \nL 161.628722 132.699684 \nL 171.372901 134.680412 \nL 181.11708 134.306656 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_94\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \nL 166.813125 88.054329 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_95\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \nL 147.283125 31.91802 \nL 166.813125 43.241191 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_96\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \nL 151.884543 132.178746 \nL 161.628722 132.699684 \nL 171.372901 134.680412 \nL 181.11708 134.306656 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_97\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \nL 166.813125 88.054329 \nL 186.343125 124.570352 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_98\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \nL 147.283125 31.91802 \nL 166.813125 43.241191 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_99\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \nL 151.884543 132.178746 \nL 161.628722 132.699684 \nL 171.372901 134.680412 \nL 181.11708 134.306656 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_100\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \nL 166.813125 88.054329 \nL 186.343125 124.570352 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_101\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \nL 147.283125 31.91802 \nL 166.813125 43.241191 \nL 186.343125 32.146386 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_102\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \nL 151.884543 132.178746 \nL 161.628722 132.699684 \nL 171.372901 134.680412 \nL 181.11708 134.306656 \nL 190.861259 136.589031 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_103\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \nL 166.813125 88.054329 \nL 186.343125 124.570352 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_104\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \nL 147.283125 31.91802 \nL 166.813125 43.241191 \nL 186.343125 32.146386 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_105\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \nL 151.884543 132.178746 \nL 161.628722 132.699684 \nL 171.372901 134.680412 \nL 181.11708 134.306656 \nL 190.861259 136.589031 \nL 200.605438 137.256127 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_106\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \nL 166.813125 88.054329 \nL 186.343125 124.570352 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_107\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \nL 147.283125 31.91802 \nL 166.813125 43.241191 \nL 186.343125 32.146386 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_108\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \nL 151.884543 132.178746 \nL 161.628722 132.699684 \nL 171.372901 134.680412 \nL 181.11708 134.306656 \nL 190.861259 136.589031 \nL 200.605438 137.256127 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_109\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \nL 166.813125 88.054329 \nL 186.343125 124.570352 \nL 205.873125 111.153598 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_110\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \nL 147.283125 31.91802 \nL 166.813125 43.241191 \nL 186.343125 32.146386 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_111\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \nL 151.884543 132.178746 \nL 161.628722 132.699684 \nL 171.372901 134.680412 \nL 181.11708 134.306656 \nL 190.861259 136.589031 \nL 200.605438 137.256127 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_112\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \nL 166.813125 88.054329 \nL 186.343125 124.570352 \nL 205.873125 111.153598 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_113\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \nL 147.283125 31.91802 \nL 166.813125 43.241191 \nL 186.343125 32.146386 \nL 205.873125 35.724127 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_114\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \nL 151.884543 132.178746 \nL 161.628722 132.699684 \nL 171.372901 134.680412 \nL 181.11708 134.306656 \nL 190.861259 136.589031 \nL 200.605438 137.256127 \nL 210.349618 138.235857 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_115\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \nL 166.813125 88.054329 \nL 186.343125 124.570352 \nL 205.873125 111.153598 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_116\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \nL 147.283125 31.91802 \nL 166.813125 43.241191 \nL 186.343125 32.146386 \nL 205.873125 35.724127 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_117\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \nL 151.884543 132.178746 \nL 161.628722 132.699684 \nL 171.372901 134.680412 \nL 181.11708 134.306656 \nL 190.861259 136.589031 \nL 200.605438 137.256127 \nL 210.349618 138.235857 \nL 220.093797 139.5 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_118\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \nL 166.813125 88.054329 \nL 186.343125 124.570352 \nL 205.873125 111.153598 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_119\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \nL 147.283125 31.91802 \nL 166.813125 43.241191 \nL 186.343125 32.146386 \nL 205.873125 35.724127 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_120\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \nL 151.884543 132.178746 \nL 161.628722 132.699684 \nL 171.372901 134.680412 \nL 181.11708 134.306656 \nL 190.861259 136.589031 \nL 200.605438 137.256127 \nL 210.349618 138.235857 \nL 220.093797 139.5 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_121\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \nL 166.813125 88.054329 \nL 186.343125 124.570352 \nL 205.873125 111.153598 \nL 225.403125 131.931138 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_122\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \nL 147.283125 31.91802 \nL 166.813125 43.241191 \nL 186.343125 32.146386 \nL 205.873125 35.724127 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_123\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 78.921544 \nL 54.442752 95.766348 \nL 64.186931 106.106064 \nL 73.93111 112.147556 \nL 83.675289 113.900447 \nL 93.419468 118.457277 \nL 103.163647 122.124324 \nL 112.907826 124.414097 \nL 122.652006 126.038902 \nL 132.396185 127.192495 \nL 142.140364 130.444517 \nL 151.884543 132.178746 \nL 161.628722 132.699684 \nL 171.372901 134.680412 \nL 181.11708 134.306656 \nL 190.861259 136.589031 \nL 200.605438 137.256127 \nL 210.349618 138.235857 \nL 220.093797 139.5 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_124\">\n    <path d=\"M 49.633125 82.041897 \nL 69.163125 93.410926 \nL 88.693125 110.284422 \nL 108.223125 96.591184 \nL 127.753125 109.408384 \nL 147.283125 123.448594 \nL 166.813125 88.054329 \nL 186.343125 124.570352 \nL 205.873125 111.153598 \nL 225.403125 131.931138 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_125\">\n    <path d=\"M 49.633125 44.573328 \nL 69.163125 44.059504 \nL 88.693125 36.028616 \nL 108.223125 38.769014 \nL 127.753125 38.007792 \nL 147.283125 31.91802 \nL 166.813125 43.241191 \nL 186.343125 32.146386 \nL 205.873125 35.724127 \nL 225.403125 29.46308 \n\" clip-path=\"url(#p25154ddd84)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 145.8 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 138.8125 100.434375 \nL 218.403125 100.434375 \nQ 220.403125 100.434375 220.403125 98.434375 \nL 220.403125 54.565625 \nQ 220.403125 52.565625 218.403125 52.565625 \nL 138.8125 52.565625 \nQ 136.8125 52.565625 136.8125 54.565625 \nL 136.8125 98.434375 \nQ 136.8125 100.434375 138.8125 100.434375 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_126\">\n     <path d=\"M 140.8125 60.664063 \nL 150.8125 60.664063 \nL 160.8125 60.664063 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_11\">\n     <!-- train_loss -->\n     <g transform=\"translate(168.8125 64.164063) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_127\">\n     <path d=\"M 140.8125 75.620313 \nL 150.8125 75.620313 \nL 160.8125 75.620313 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- val_loss -->\n     <g transform=\"translate(168.8125 79.120313) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n    <g id=\"line2d_128\">\n     <path d=\"M 140.8125 90.576563 \nL 150.8125 90.576563 \nL 160.8125 90.576563 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- val_acc -->\n     <g transform=\"translate(168.8125 94.076563) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p25154ddd84\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128)\n",
        "model = BNLeNet(lr=0.1)\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "353f1805",
      "metadata": {
        "id": "353f1805"
      },
      "source": [
        "## Discussion\n",
        "\n",
        "Intuitively, batch normalization is thought\n",
        "to make the optimization landscape smoother.\n",
        "However, we must be careful to distinguish between\n",
        "speculative intuitions and true explanations\n",
        "for the phenomena that we observe when training deep models.\n",
        "Recall that we do not even know why simpler\n",
        "deep neural networks (MLPs and conventional CNNs)\n",
        "generalize well in the first place.\n",
        "Even with dropout and weight decay,\n",
        "they remain so flexible that their ability to generalize to unseen data\n",
        "likely needs significantly more refined learning-theoretic generalization guarantees.\n",
        "\n",
        "The original paper proposing batch normalization :cite:`Ioffe.Szegedy.2015`, in addition to introducing a powerful and useful tool,\n",
        "offered an explanation for why it works:\n",
        "by reducing *internal covariate shift*.\n",
        "Presumably by *internal covariate shift* they\n",
        "meant something like the intuition expressed above---the\n",
        "notion that the distribution of variable values changes\n",
        "over the course of training.\n",
        "However, there were two problems with this explanation:\n",
        "i) This drift is very different from *covariate shift*,\n",
        "rendering the name a misnomer. If anything, it is closer to concept drift.\n",
        "ii) The explanation offers an under-specified intuition\n",
        "but leaves the question of *why precisely this technique works*\n",
        "an open question wanting for a rigorous explanation.\n",
        "Throughout this book, we aim to convey the intuitions that practitioners\n",
        "use to guide their development of deep neural networks.\n",
        "However, we believe that it is important\n",
        "to separate these guiding intuitions\n",
        "from established scientific fact.\n",
        "Eventually, when you master this material\n",
        "and start writing your own research papers\n",
        "you will want to be clear to delineate\n",
        "between technical claims and hunches.\n",
        "\n",
        "Following the success of batch normalization,\n",
        "its explanation in terms of *internal covariate shift*\n",
        "has repeatedly surfaced in debates in the technical literature\n",
        "and broader discourse about how to present machine learning research.\n",
        "In a memorable speech given while accepting a Test of Time Award\n",
        "at the 2017 NeurIPS conference,\n",
        "Ali Rahimi used *internal covariate shift*\n",
        "as a focal point in an argument likening\n",
        "the modern practice of deep learning to alchemy.\n",
        "Subsequently, the example was revisited in detail\n",
        "in a position paper outlining\n",
        "troubling trends in machine learning :cite:`Lipton.Steinhardt.2018`.\n",
        "Other authors\n",
        "have proposed alternative explanations for the success of batch normalization,\n",
        "some :cite:`Santurkar.Tsipras.Ilyas.ea.2018`\n",
        "claiming that batch normalization's success comes despite exhibiting behavior\n",
        "that is in some ways opposite to those claimed in the original paper.\n",
        "\n",
        "\n",
        "We note that the *internal covariate shift*\n",
        "is no more worthy of criticism than any of\n",
        "thousands of similarly vague claims\n",
        "made every year in the technical machine learning literature.\n",
        "Likely, its resonance as a focal point of these debates\n",
        "owes to its broad recognizability for the target audience.\n",
        "Batch normalization has proven an indispensable method,\n",
        "applied in nearly all deployed image classifiers,\n",
        "earning the paper that introduced the technique\n",
        "tens of thousands of citations. We conjecture, though, that the guiding principles\n",
        "of regularization through noise injection, acceleration through rescaling and lastly preprocessing\n",
        "may well lead to further inventions of layers and techniques in the future.\n",
        "\n",
        "On a more practical note, there are a number of aspects worth remembering about batch normalization:\n",
        "\n",
        "* During model training, batch normalization continuously adjusts the intermediate output of\n",
        "  the network by utilizing the mean and standard deviation of the minibatch, so that the\n",
        "  values of the intermediate output in each layer throughout the neural network are more stable.\n",
        "* Batch normalization is slightly different for fully connected layers than for convolutional layers. In fact,\n",
        "  for convolutional layers, layer normalization can sometimes be used as an alternative.\n",
        "* Like a dropout layer, batch normalization layers have different behaviors\n",
        "  in training mode than in prediction mode.\n",
        "* Batch normalization is useful for regularization and improving convergence in optimization. By contrast,\n",
        "  the original motivation of reducing internal covariate shift seems not to be a valid explanation.\n",
        "* For more robust models that are less sensitive to input perturbations, consider removing batch normalization :cite:`wang2022removing`.\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Should we remove the bias parameter from the fully connected layer or the convolutional layer before the batch normalization? Why?\n",
        "1. Compare the learning rates for LeNet with and without batch normalization.\n",
        "    1. Plot the increase in validation accuracy.\n",
        "    1. How large can you make the learning rate before the optimization fails in both cases?\n",
        "1. Do we need batch normalization in every layer? Experiment with it.\n",
        "1. Implement a \"lite\" version of batch normalization that only removes the mean, or alternatively one that\n",
        "   only removes the variance. How does it behave?\n",
        "1. Fix the parameters `beta` and `gamma`. Observe and analyze the results.\n",
        "1. Can you replace dropout by batch normalization? How does the behavior change?\n",
        "1. Research ideas: think of other normalization transforms that you can apply:\n",
        "    1. Can you apply the probability integral transform?\n",
        "    1. Can you use a full-rank covariance estimate? Why should you probably not do that?\n",
        "    1. Can you use other compact matrix variants (block-diagonal, low-displacement rank, Monarch, etc.)?\n",
        "    1. Does a sparsification compression act as a regularizer?\n",
        "    1. Are there other projections (e.g., convex cone, symmetry group-specific transforms) that you can use?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MvP75SNIzp6t",
      "metadata": {
        "id": "MvP75SNIzp6t"
      },
      "source": [
        "No. 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RbencPL8zuTk",
      "metadata": {
        "id": "RbencPL8zuTk"
      },
      "source": [
        "Should we remove the bias parameter from the fully connected layer or the convolutional layer before the batch normalization? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0pWIOczU0G0h",
      "metadata": {
        "id": "0pWIOczU0G0h"
      },
      "source": [
        "\n",
        "Batch normalization membantu menstabilkan dan mempercepat pelatihan jaringan saraf dengan menormalkan aktivasi. Karena batch normalization sudah memiliki parameter untuk menggeser dan mengatur skala (beta dan gamma), disarankan untuk menghapus parameter bias dari lapisan fully connected sebelum menerapkan batch normalization. Menambahkan bias bisa menyebabkan redundansi dan memengaruhi proses pembelajaran.\n",
        "\n",
        "Pada lapisan konvolusi, penggunaan bias lebih fleksibel. Kita bisa tetap menggunakan bias, terutama di tahap awal jaringan, atau menghapusnya agar batch normalization menangani pengaturan dan pergeseran aktivasi. Keputusan ini tergantung pada desain arsitektur dan eksperimen."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ly2tmoDj0L9y",
      "metadata": {
        "id": "ly2tmoDj0L9y"
      },
      "source": [
        " No. 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nLqDY3B90NyJ",
      "metadata": {
        "id": "nLqDY3B90NyJ"
      },
      "source": [
        "Compare the learning rates for LeNet with and without batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbj8-5iRzrOx",
      "metadata": {
        "id": "cbj8-5iRzrOx"
      },
      "outputs": [],
      "source": [
        "class LeNet(d2l.Classifier):\n",
        "    \"\"\"The LeNet-5 model.\"\"\"\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.LazyConv2d(16, kernel_size=5), nn.Sigmoid(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.LazyLinear(120), nn.Sigmoid(),\n",
        "            nn.LazyLinear(84), nn.Sigmoid(),\n",
        "            nn.LazyLinear(num_classes))\n",
        "\n",
        "class BNLeNet(d2l.Classifier):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(6, kernel_size=5), nn.LazyBatchNorm2d(),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.LazyConv2d(16, kernel_size=5), nn.LazyBatchNorm2d(),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(), nn.LazyLinear(120), nn.LazyBatchNorm1d(),\n",
        "            nn.Sigmoid(), nn.LazyLinear(84), nn.LazyBatchNorm1d(),\n",
        "            nn.Sigmoid(), nn.LazyLinear(num_classes))\n",
        "\n",
        "def stat_model_acc(model, data, plot_flag):\n",
        "    model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "    trainer = d2l.Trainer(max_epochs=10, num_gpus=1,plot_flag=plot_flag)\n",
        "    trainer.fit(model, data)\n",
        "    X,y = next(iter(data.get_dataloader(False)))\n",
        "    X = X.to('cuda')\n",
        "    y = y.to('cuda')\n",
        "    y_hat = model(X)\n",
        "    return model.accuracy(y_hat,y).item()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rwPgt6f90XYe",
      "metadata": {
        "id": "rwPgt6f90XYe"
      },
      "source": [
        "2.1 Plot the increase in validation in accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZkPICdeP0ZzM",
      "metadata": {
        "id": "ZkPICdeP0ZzM"
      },
      "outputs": [],
      "source": [
        "data = d2l.FashionMNIST(batch_size=128)\n",
        "lr_list = [0.001,0.01,0.03,0.1,0.3]\n",
        "le_accs= []\n",
        "ble_accs = []\n",
        "for lr in lr_list[:1]:\n",
        "    le = LeNet(lr=lr)\n",
        "    ble = BNLeNet(lr=lr)\n",
        "    le_acc.append(stat_model_acc(le, data, False))\n",
        "    ble_acc.append(stat_model_acc(ble, data, False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BiEU4nf10cbc",
      "metadata": {
        "id": "BiEU4nf10cbc"
      },
      "source": [
        "2.2 How large can you make the learning rate before the optimization fails in both cases?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gnvAK9y_1bps",
      "metadata": {
        "id": "gnvAK9y_1bps"
      },
      "source": [
        "\n",
        "LeNet dengan batch normalization dapat menggunakan learning rate yang lebih besar dibandingkan tanpa batch normalization. Batch normalization membantu stabilisasi pelatihan, sehingga memungkinkan penggunaan learning rate yang lebih tinggi sebelum optimisasi gagal. Tanpa batch normalization, learning rate yang terlalu besar lebih cepat menyebabkan ketidakstabilan dan kegagalan optimisasi. Jadi, batas maksimal learning rate pada LeNet dengan batch normalization lebih tinggi dibandingkan tanpa batch normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iHCK1ekd1piH",
      "metadata": {
        "id": "iHCK1ekd1piH"
      },
      "source": [
        "No. 3\n",
        "\n",
        "Do we need batch normalization in every layer? Experiment with it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6XIslxhK2AZz",
      "metadata": {
        "id": "6XIslxhK2AZz"
      },
      "source": [
        "Menentukan apakah kita perlu menerapkan batch normalization di setiap layer jaringan saraf bergantung pada desain model, masalah yang dihadapi, dan dinamika pelatihan. Batch normalization dapat membantu menstabilkan pelatihan, mempercepat konvergensi, dan mencegah overfitting, terutama pada jaringan yang dalam. Namun, jika diterapkan terlalu sering, dapat mengurangi kapasitas model, memperlambat pelatihan, atau menyebabkan underfitting.\n",
        "\n",
        "Pada jaringan yang lebih dalam, batch normalization di setiap layer sering kali bermanfaat, tetapi pada jaringan yang lebih kecil, penerapan selektif mungkin lebih efektif. Sebaiknya lakukan eksperimen untuk menilai dampaknya terhadap kinerja dan kecepatan pelatihan model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "knN7sVSq2KdZ",
      "metadata": {
        "id": "knN7sVSq2KdZ"
      },
      "source": [
        "No. 4\n",
        "\n",
        "Implement a “lite” version of batch normalization that only removes the mean, or alternatively one that only removes the variance. How does it behave?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oWzMCjx80e_P",
      "metadata": {
        "id": "oWzMCjx80e_P"
      },
      "outputs": [],
      "source": [
        "def lite_batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum, mean_flag):\n",
        "    # Use is_grad_enabled to determine whether we are in training mode\n",
        "    if not torch.is_grad_enabled():\n",
        "        # In prediction mode, use mean and variance obtained by moving average\n",
        "        if mean_flag:\n",
        "            X_hat = X - moving_mean\n",
        "        else:\n",
        "            X_hat = X / torch.sqrt(moving_var + eps)\n",
        "    else:\n",
        "        assert len(X.shape) in (2, 4)\n",
        "        if len(X.shape) == 2:\n",
        "            # When using a fully connected layer, calculate the mean and\n",
        "            # variance on the feature dimension\n",
        "            mean = X.mean(dim=0)\n",
        "            var = ((X - mean) ** 2).mean(dim=0)\n",
        "        else:\n",
        "            # When using a two-dimensional convolutional layer, calculate the\n",
        "            # mean and variance on the channel dimension (axis=1). Here we\n",
        "            # need to maintain the shape of X, so that the broadcasting\n",
        "            # operation can be carried out later\n",
        "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
        "            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
        "        # In training mode, the current mean and variance are used\n",
        "        if mean_flag:\n",
        "            X_hat = X - mean\n",
        "        else:\n",
        "            X_hat = X / torch.sqrt(moving_var + eps)\n",
        "        # Update the mean and variance using moving average\n",
        "        moving_mean = (1.0 - momentum) * moving_mean + momentum * mean\n",
        "        moving_var = (1.0 - momentum) * moving_var + momentum * var\n",
        "    Y = gamma * X_hat + beta  # Scale and shift\n",
        "    return Y, moving_mean.data, moving_var.data\n",
        "\n",
        "class LiteBatchNorm(nn.Module):\n",
        "    # num_features: the number of outputs for a fully connected layer or the\n",
        "    # number of output channels for a convolutional layer. num_dims: 2 for a\n",
        "    # fully connected layer and 4 for a convolutional layer\n",
        "    def __init__(self, num_features, num_dims, mean_flag=True):\n",
        "        super().__init__()\n",
        "        if num_dims == 2:\n",
        "            shape = (1, num_features)\n",
        "        else:\n",
        "            shape = (1, num_features, 1, 1)\n",
        "        # The scale parameter and the shift parameter (model parameters) are\n",
        "        # initialized to 1 and 0, respectively\n",
        "        self.gamma = nn.Parameter(torch.ones(shape))\n",
        "        self.beta = nn.Parameter(torch.zeros(shape))\n",
        "        # The variables that are not model parameters are initialized to 0 and\n",
        "        # 1\n",
        "        self.moving_mean = torch.zeros(shape)\n",
        "        self.moving_var = torch.ones(shape)\n",
        "        self.mean_flag = mean_flag\n",
        "\n",
        "    def forward(self, X):\n",
        "        # If X is not on the main memory, copy moving_mean and moving_var to\n",
        "        # the device where X is located\n",
        "        if self.moving_mean.device != X.device:\n",
        "            self.moving_mean = self.moving_mean.to(X.device)\n",
        "            self.moving_var = self.moving_var.to(X.device)\n",
        "        # Save the updated moving_mean and moving_var\n",
        "        Y, self.moving_mean, self.moving_var = batch_norm(\n",
        "            X, self.gamma, self.beta, self.moving_mean,\n",
        "            self.moving_var, eps=1e-5, momentum=0.1, mean_flag=self.mean_flag)\n",
        "        return Y\n",
        "\n",
        "\n",
        "class LiteBNLeNetScratch(d2l.Classifier):\n",
        "    def __init__(self, lr=0.1, num_classes=10, mean_flag=True):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(6, kernel_size=5), LiteBatchNorm(6, num_dims=4, mean_flag=mean_flag),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.LazyConv2d(16, kernel_size=5), LiteBatchNorm(16, num_dims=4, mean_flag=mean_flag),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(), nn.LazyLinear(120),\n",
        "            LiteBatchNorm(120, num_dims=2, mean_flag=mean_flag), nn.Sigmoid(), nn.LazyLinear(84),\n",
        "            LiteBatchNorm(84, num_dims=2, mean_flag=mean_flag), nn.Sigmoid(),\n",
        "            nn.LazyLinear(num_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c-oi1y9A2Yzb",
      "metadata": {
        "id": "c-oi1y9A2Yzb"
      },
      "outputs": [],
      "source": [
        "model = LiteBNLeNetScratch(lr=0.1)\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "trainer.fit(model, data)\n",
        "X,y = next(iter(data.get_dataloader(False)))\n",
        "X = X.to('cuda')\n",
        "y = y.to('cuda')\n",
        "y_hat = model(X)\n",
        "model.accuracy(y_hat,y).item()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qz2whomf2erJ",
      "metadata": {
        "id": "qz2whomf2erJ"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E_XMeoe-2e_L",
      "metadata": {
        "id": "E_XMeoe-2e_L"
      },
      "outputs": [],
      "source": [
        "model = LiteBNLeNetScratch(lr=0.1,mean_flag=False)\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "trainer.fit(model, data)\n",
        "X,y = next(iter(data.get_dataloader(False)))\n",
        "X = X.to('cuda')\n",
        "y = y.to('cuda')\n",
        "y_hat = model(X)\n",
        "model.accuracy(y_hat,y).item()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WsabKzSL2hiI",
      "metadata": {
        "id": "WsabKzSL2hiI"
      },
      "source": [
        "No. 5\n",
        "\n",
        "Fix the parameters beta and gamma. Observe and analyze the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WtbUOw_N2kUG",
      "metadata": {
        "id": "WtbUOw_N2kUG"
      },
      "outputs": [],
      "source": [
        "class FixedBatchNorm(nn.Module):\n",
        "    # num_features: the number of outputs for a fully connected layer or the\n",
        "    # number of output channels for a convolutional layer. num_dims: 2 for a\n",
        "    # fully connected layer and 4 for a convolutional layer\n",
        "    def __init__(self, num_features, num_dims, beta=None, gamma=None):\n",
        "        super().__init__()\n",
        "        if num_dims == 2:\n",
        "            shape = (1, num_features)\n",
        "        else:\n",
        "            shape = (1, num_features, 1, 1)\n",
        "        # The scale parameter and the shift parameter (model parameters) are\n",
        "        # initialized to 1 and 0, respectively\n",
        "        self.gamma = torch.ones(shape) if gamma is None else gamma\n",
        "        self.beta = torch.zeros(shape) if beta is None else beta\n",
        "        # The variables that are not model parameters are initialized to 0 and\n",
        "        # 1\n",
        "        self.moving_mean = torch.zeros(shape)\n",
        "        self.moving_var = torch.ones(shape)\n",
        "        self.mean_flag = mean_flag\n",
        "\n",
        "    def forward(self, X):\n",
        "        # If X is not on the main memory, copy moving_mean and moving_var to\n",
        "        # the device where X is located\n",
        "        if self.moving_mean.device != X.device:\n",
        "            self.moving_mean = self.moving_mean.to(X.device)\n",
        "            self.moving_var = self.moving_var.to(X.device)\n",
        "        # Save the updated moving_mean and moving_var\n",
        "        Y, self.moving_mean, self.moving_var = batch_norm(\n",
        "            X, self.gamma, self.beta, self.moving_mean,\n",
        "            self.moving_var, eps=1e-5, momentum=0.1, mean_flag=self.mean_flag)\n",
        "        return Y\n",
        "\n",
        "\n",
        "class FixedBNLeNetScratch(d2l.Classifier):\n",
        "    def __init__(self, lr=0.1, num_classes=10, beta=None, gamma=None):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(6, kernel_size=5), FixedBatchNorm(6, num_dims=4, beta=beta, gamma=gamma),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.LazyConv2d(16, kernel_size=5), FixedBatchNorm(16, num_dims=4, beta=beta, gamma=gamma),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(), nn.LazyLinear(120),\n",
        "            FixedBatchNorm(120, num_dims=2, beta=beta, gamma=gamma), nn.Sigmoid(), nn.LazyLinear(84),\n",
        "            FixedBatchNorm(84, num_dims=2, beta=beta, gamma=gamma), nn.Sigmoid(),\n",
        "            nn.LazyLinear(num_classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z3DsQLqt2ogn",
      "metadata": {
        "id": "Z3DsQLqt2ogn"
      },
      "source": [
        "No. 6\n",
        "Can you replace dropout by batch normalization? How does the behavior change?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mw0prI6P27XM",
      "metadata": {
        "id": "mw0prI6P27XM"
      },
      "source": [
        "No. 7\n",
        "\n",
        "Research ideas: think of other normalization transforms that you can apply:\n",
        "\n",
        "7.1 Can you apply the probability integral transform?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kbHY8I0y2rlN",
      "metadata": {
        "id": "kbHY8I0y2rlN"
      },
      "outputs": [],
      "source": [
        "def gen_sort_cdf(data):\n",
        "    sorts = []\n",
        "    cdfs = []\n",
        "    for i in range(data.shape[1]):\n",
        "        sort = np.sort(data[:, i])\n",
        "        cdf = np.arange(1, len(sort) + 1) / len(sort)\n",
        "        sorts.append(torch.tensor(sort).reshape(-1,1))\n",
        "        cdfs.append(torch.tensor(cdf).reshape(-1,1))\n",
        "    return torch.cat(sorts, dim=1), torch.cat(cdfs, dim=1)\n",
        "\n",
        "def pit_col(sorted_data, cdf_values, data):\n",
        "    # sorted_data = np.sort(org_data)\n",
        "    # cdf_values = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n",
        "    transformed_data = np.interp(data, sorted_data, cdf_values)\n",
        "    return\n",
        "\n",
        "def pit(sorted_data, cdf_values, data):\n",
        "    return torch.cat([pit_col(sorted_data[:,i], cdf_values[:,i], data[:, i]) for i in range(data.shape[1])], dim=1)\n",
        "\n",
        "def batch_pit_norm(X, gamma, beta, moving_sorted, moving_cdf, momentum):\n",
        "    # Use is_grad_enabled to determine whether we are in training mode\n",
        "    assert len(X.shape) in (2, 4)\n",
        "    shape  = X.shape\n",
        "    if len(shape) == 4:\n",
        "        X = torch.transpose(X,0,1).reshape(shape[1],-1)\n",
        "    if not torch.is_grad_enabled():\n",
        "        # In prediction mode, use mean and variance obtained by moving average\n",
        "        X_hat = pit(moving_sorted, moving_cdf, cdfs, X)\n",
        "    else:\n",
        "        sorts, cdfs = gen_sort_cdf(data)\n",
        "        X_hat = pit(sorts, cdfs, X)\n",
        "        moving_sorted = (1.0 - momentum) * moving_sorted + momentum * sorts\n",
        "        moving_cdf = (1.0 - momentum) * moving_cdf + momentum * cdfs\n",
        "    X_hat = X.reshape(shape)\n",
        "        # Update the mean and variance using moving average\n",
        "    Y = gamma * X_hat + beta  # Scale and shift\n",
        "    return Y, moving_sorted, moving_cdf\n",
        "\n",
        "class PitBatchNorm(nn.Module):\n",
        "    # num_features: the number of outputs for a fully connected layer or the\n",
        "    # number of output channels for a convolutional layer. num_dims: 2 for a\n",
        "    # fully connected layer and 4 for a convolutional layer\n",
        "    def __init__(self, num_features, num_dims):\n",
        "        super().__init__()\n",
        "        if num_dims == 2:\n",
        "            shape = (1, num_features)\n",
        "        else:\n",
        "            shape = (1, num_features, 1, 1)\n",
        "        # The scale parameter and the shift parameter (model parameters) are\n",
        "        # initialized to 1 and 0, respectively\n",
        "        self.gamma = nn.Parameter(torch.ones(shape))\n",
        "        self.beta = nn.Parameter(torch.zeros(shape))\n",
        "        # The variables that are not model parameters are initialized to 0\n",
        "        self.moving_sorted = torch.zeros(shape)\n",
        "        self.moving_cdf = torch.zeros(shape)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # If X is not on the main memory, copy moving_mean and moving_var to\n",
        "        # the device where X is located\n",
        "        if self.moving_sorted.device != X.device:\n",
        "            self.moving_sorted = self.moving_sorted.to(X.device)\n",
        "            self.moving_cdf = self.moving_cdf.to(X.device)\n",
        "        # Save the updated moving_mean and moving_var\n",
        "        Y, self.moving_sorted, self.moving_cdf = batch_pit_norm(\n",
        "            X, self.gamma, self.beta, self.moving_sorted,\n",
        "            self.moving_cdf, momentum=0.1)\n",
        "        return Y\n",
        "\n",
        "\n",
        "class PitBNLeNetScratch(d2l.Classifier):\n",
        "    def __init__(self, lr=0.1, num_classes=10, mean_flag=True):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(6, kernel_size=5), PitBatchNorm(6, num_dims=4),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.LazyConv2d(16, kernel_size=5), PitBatchNorm(6, num_dims=4),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(), nn.LazyLinear(120),\n",
        "            PitBatchNorm(6, num_dims=4), nn.Sigmoid(), nn.LazyLinear(84),\n",
        "            PitBatchNorm(6, num_dims=4), nn.Sigmoid(),\n",
        "            nn.LazyLinear(num_classes))\n",
        "\n",
        "# model = PitBNLeNetScratch(lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tdMpV-783Kbq",
      "metadata": {
        "id": "tdMpV-783Kbq"
      },
      "source": [
        "7.2 Can you use a full-rank covariance estimate? Why should you probably not do that?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vkz7AEMR7kln",
      "metadata": {
        "id": "vkz7AEMR7kln"
      },
      "source": [
        "\n",
        "Menggunakan estimasi kovarian full-rank alih-alih transformasi normalisasi standar (rata-rata dan varians) dalam batch normalization tidak disarankan karena beberapa alasan. Pertama, kompleksitas komputasionalnya lebih tinggi karena perhitungan matriks kovarian bersifat kuadratik terhadap dimensi input, sementara rata-rata dan varians bersifat linier, sehingga memperlambat pelatihan. Selain itu, perhitungan kovarian antar channel bisa menyebabkan ketidakstabilan numerik, terutama pada batch kecil atau data berdimensi tinggi, serta berisiko menyebabkan overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Nzmb8yLk3MLR",
      "metadata": {
        "id": "Nzmb8yLk3MLR"
      },
      "outputs": [],
      "source": [
        "def batch_frcov_norm(X, gamma, beta, moving_cov_matrix, momentum):\n",
        "    # Use is_grad_enabled to determine whether we are in training mode\n",
        "    assert len(X.shape) in (2, 4)\n",
        "    shape  = X.shape\n",
        "    if len(shape) == 4:\n",
        "        X = torch.transpose(X,0,1).reshape(shape[1],-1)\n",
        "    if not torch.is_grad_enabled():\n",
        "        # In prediction mode, use mean and variance obtained by moving average\n",
        "        eigenvalues, eigenvectors = torch.linalg.eig(moving_cov_matrix)\n",
        "        X_hat = X @ eigenvectors.type(torch.float32)\n",
        "    else:\n",
        "        centered_data = X - X.mean(dim=0)\n",
        "        cov_matrix = (centered_data.conj().T @ centered_data) / (X.shape[0] - 1)\n",
        "        eigenvalues, eigenvectors = torch.linalg.eig(cov_matrix)\n",
        "        X_hat = X @ eigenvectors.type(torch.float32)\n",
        "        moving_cov_matrix = (1.0 - momentum) * moving_cov_matrix + momentum * cov_matrix\n",
        "    X_hat = X.reshape(shape)\n",
        "        # Update the mean and variance using moving average\n",
        "    Y = gamma * X_hat + beta  # Scale and shift\n",
        "    return Y, moving_cov_matrix\n",
        "\n",
        "class FrcovBatchNorm(nn.Module):\n",
        "    # num_features: the number of outputs for a fully connected layer or the\n",
        "    # number of output channels for a convolutional layer. num_dims: 2 for a\n",
        "    # fully connected layer and 4 for a convolutional layer\n",
        "    def __init__(self, num_features, num_dims):\n",
        "        super().__init__()\n",
        "        if num_dims == 2:\n",
        "            shape = (1, num_features)\n",
        "        else:\n",
        "            shape = (1, num_features, 1, 1)\n",
        "        # The scale parameter and the shift parameter (model parameters) are\n",
        "        # initialized to 1 and 0, respectively\n",
        "        self.gamma = nn.Parameter(torch.ones(shape))\n",
        "        self.beta = nn.Parameter(torch.zeros(shape))\n",
        "        # The variables that are not model parameters are initialized to 0\n",
        "        self.moving_cov_matrix = torch.zeros(shape)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # If X is not on the main memory, copy moving_mean and moving_var to\n",
        "        # the device where X is located\n",
        "        if self.moving_cov_matrix.device != X.device:\n",
        "            self.moving_cov_matrix = self.moving_cov_matrix.to(X.device)\n",
        "        # Save the updated moving_mean and moving_var\n",
        "        Y, self.moving_cov_matrix = batch_frcov_norm(\n",
        "            X, self.gamma, self.beta, self.moving_cov_matrix,\n",
        "            momentum=0.1)\n",
        "        return Y\n",
        "\n",
        "\n",
        "class FrcovBNLeNetScratch(d2l.Classifier):\n",
        "    def __init__(self, lr=0.1, num_classes=10, mean_flag=True):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(6, kernel_size=5), FrcovBatchNorm(6, num_dims=4),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.LazyConv2d(16, kernel_size=5), FrcovBatchNorm(6, num_dims=4),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(), nn.LazyLinear(120),\n",
        "            FrcovBatchNorm(6, num_dims=4), nn.Sigmoid(), nn.LazyLinear(84),\n",
        "            FrcovBatchNorm(6, num_dims=4), nn.Sigmoid(),\n",
        "            nn.LazyLinear(num_classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GKIcFz9C7x3X",
      "metadata": {
        "id": "GKIcFz9C7x3X"
      },
      "source": [
        "7.3 Can you use other compact matrix variants (block-diagonal, low-displacement rank, Monarch, etc.)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bxoukDP7z0r",
      "metadata": {
        "id": "2bxoukDP7z0r"
      },
      "outputs": [],
      "source": [
        "def batch_bdcov_norm(X, gamma, beta, moving_cov_matrix, momentum):\n",
        "    # Use is_grad_enabled to determine whether we are in training mode\n",
        "    assert len(X.shape) in (2, 4)\n",
        "    shape  = X.shape\n",
        "    if len(shape) == 4:\n",
        "        X = torch.transpose(X,0,1).reshape(shape[1],-1)\n",
        "    if not torch.is_grad_enabled():\n",
        "        # In prediction mode, use mean and variance obtained by moving average\n",
        "        diagonal_matrix = torch.diag_embed(moving_cov_matrix)\n",
        "        block_diagonal_matrix = torch.sum(diagonal_matrix, dim=0)\n",
        "        X_hat = X @ block_diagonal_matrix\n",
        "    else:\n",
        "        centered_data = X - X.mean(dim=0)\n",
        "        cov_matrix = (centered_data.conj().T @ centered_data) / (X.shape[0] - 1)\n",
        "        diagonal_matrix = torch.diag_embed(moving_cov_matrix)\n",
        "        block_diagonal_matrix = torch.sum(diagonal_matrix, dim=0)\n",
        "        X_hat = X @ block_diagonal_matrix\n",
        "        moving_cov_matrix = (1.0 - momentum) * moving_cov_matrix + momentum * cov_matrix\n",
        "    X_hat = X.reshape(shape)\n",
        "        # Update the mean and variance using moving average\n",
        "    Y = gamma * X_hat + beta  # Scale and shift\n",
        "    return Y, moving_cov_matrix\n",
        "\n",
        "class BdcovBatchNorm(nn.Module):\n",
        "    # num_features: the number of outputs for a fully connected layer or the\n",
        "    # number of output channels for a convolutional layer. num_dims: 2 for a\n",
        "    # fully connected layer and 4 for a convolutional layer\n",
        "    def __init__(self, num_features, num_dims):\n",
        "        super().__init__()\n",
        "        if num_dims == 2:\n",
        "            shape = (1, num_features)\n",
        "        else:\n",
        "            shape = (1, num_features, 1, 1)\n",
        "        # The scale parameter and the shift parameter (model parameters) are\n",
        "        # initialized to 1 and 0, respectively\n",
        "        self.gamma = nn.Parameter(torch.ones(shape))\n",
        "        self.beta = nn.Parameter(torch.zeros(shape))\n",
        "        # The variables that are not model parameters are initialized to 0\n",
        "        self.moving_cov_matrix = torch.zeros(shape)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # If X is not on the main memory, copy moving_mean and moving_var to\n",
        "        # the device where X is located\n",
        "        if self.moving_cov_matrix.device != X.device:\n",
        "            self.moving_cov_matrix = self.moving_cov_matrix.to(X.device)\n",
        "        # Save the updated moving_mean and moving_var\n",
        "        Y, self.moving_cov_matrix = batch_bdcov_norm(\n",
        "            X, self.gamma, self.beta, self.moving_cov_matrix,\n",
        "            momentum=0.1)\n",
        "        return Y\n",
        "\n",
        "\n",
        "class BdcovBNLeNetScratch(d2l.Classifier):\n",
        "    def __init__(self, lr=0.1, num_classes=10, mean_flag=True):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(6, kernel_size=5), BdcovBatchNorm(6, num_dims=4),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.LazyConv2d(16, kernel_size=5), BdcovBatchNorm(6, num_dims=4),\n",
        "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(), nn.LazyLinear(120),\n",
        "            BdcovBatchNorm(6, num_dims=4), nn.Sigmoid(), nn.LazyLinear(84),\n",
        "            BdcovBatchNorm(6, num_dims=4), nn.Sigmoid(),\n",
        "            nn.LazyLinear(num_classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7CzJw8FC77Vm",
      "metadata": {
        "id": "7CzJw8FC77Vm"
      },
      "source": [
        "7.4 Does a sparsification compression act as a regularizer?\n",
        "\n",
        "\n",
        "Kompresi sparsifikasi dapat berfungsi sebagai bentuk regularisasi dalam model pembelajaran mesin. Sparsifikasi adalah proses mengubah beberapa bobot atau parameter dalam model menjadi nol, menciptakan representasi yang lebih sederhana. Proses ini bisa membantu mencegah overfitting dengan mengurangi kompleksitas model.\n",
        "\n",
        "Sparsifikasi mengurangi jumlah parameter aktif, sehingga model lebih fokus pada fitur yang relevan dan kurang menangkap noise pada data pelatihan. Ini membantu meningkatkan generalisasi, membuat model lebih robust terhadap data baru yang belum pernah dilihat. Selain itu, model yang jarang (sparse) lebih mudah diinterpretasikan karena menyoroti fitur-fitur paling berpengaruh dan lebih efisien secara komputasi."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ZdoktAi8pbV",
      "metadata": {
        "id": "5ZdoktAi8pbV"
      },
      "source": [
        "7.5 Are there other projections (e.g., convex cone, symmetry group-specific transforms) that you can use?\n",
        "\n",
        "Ada berbagai jenis proyeksi dan transformasi lain yang dapat digunakan dalam konteks matematis dan komputasional. Proyeksi ini sering digunakan untuk mencapai properti, struktur, atau batasan tertentu pada data atau objek matematis.\n",
        "\n",
        "Misalnya, proyeksi konveks melibatkan menemukan titik dalam kerucut konveks yang paling dekat dengan vektor tertentu, sering digunakan dalam masalah optimisasi yang memerlukan pemenuhan batasan tertentu. Selain itu, transformasi spesifik grup simetri digunakan untuk menghormati simetri tertentu, seperti dalam krystallografi dan pemrosesan citra. Proyeksi ortogonal membantu menemukan titik terdekat dalam subruang terhadap vektor yang diberikan.\n",
        "\n",
        "Quantization adalah operasi yang memetakan nilai kontinu ke set nilai diskrit, berguna dalam pemrosesan sinyal dan kompresi data. Teknik pembelajaran manifold, seperti t-SNE, bertujuan untuk menyematkan data berdimensi tinggi ke ruang berdimensi lebih rendah sambil mempertahankan struktur tertentu. Sementara itu, masalah Procrustes ortogonal digunakan untuk menyelaraskan dua set titik dengan transformasi ortogonal. Pilihan proyeksi atau transformasi tergantung pada masalah yang dihadapi dan properti atau batasan yang ingin dicapai."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w7NZpnb_9a4p",
      "metadata": {
        "id": "w7NZpnb_9a4p"
      },
      "source": [
        "#8.6 Residual Networks (ResNet) and ResNeXt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e11b4915",
      "metadata": {
        "id": "e11b4915"
      },
      "source": [
        "# Residual Networks (ResNet) and ResNeXt\n",
        ":label:`sec_resnet`\n",
        "\n",
        "As we design ever deeper networks it becomes imperative to understand how adding layers can increase the complexity and expressiveness of the network.\n",
        "Even more important is the ability to design networks where adding layers makes networks strictly more expressive rather than just different.\n",
        "To make some progress we need a bit of mathematics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6e5d075",
      "metadata": {
        "id": "d6e5d075"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f46d0878",
      "metadata": {
        "id": "f46d0878"
      },
      "source": [
        "## Function Classes\n",
        "\n",
        "Consider $\\mathcal{F}$, the class of functions that a specific network architecture (together with learning rates and other hyperparameter settings) can reach.\n",
        "That is, for all $f \\in \\mathcal{F}$ there exists some set of parameters (e.g., weights and biases) that can be obtained through training on a suitable dataset.\n",
        "Let's assume that $f^*$ is the \"truth\" function that we really would like to find.\n",
        "If it is in $\\mathcal{F}$, we are in good shape but typically we will not be quite so lucky.\n",
        "Instead, we will try to find some $f^*_\\mathcal{F}$ which is our best bet within $\\mathcal{F}$.\n",
        "For instance,\n",
        "given a dataset with features $\\mathbf{X}$\n",
        "and labels $\\mathbf{y}$,\n",
        "we might try finding it by solving the following optimization problem:\n",
        "\n",
        "$$f^*_\\mathcal{F} \\stackrel{\\textrm{def}}{=} \\mathop{\\mathrm{argmin}}_f L(\\mathbf{X}, \\mathbf{y}, f) \\textrm{ subject to } f \\in \\mathcal{F}.$$\n",
        "\n",
        "We know that regularization :cite:`tikhonov1977solutions,morozov2012methods` may control complexity of $\\mathcal{F}$\n",
        "and achieve consistency, so a larger size of training data\n",
        "generally leads to better $f^*_\\mathcal{F}$.\n",
        "It is only reasonable to assume that if we design a different and more powerful architecture $\\mathcal{F}'$ we should arrive at a better outcome. In other words, we would expect that $f^*_{\\mathcal{F}'}$ is \"better\" than $f^*_{\\mathcal{F}}$. However, if $\\mathcal{F} \\not\\subseteq \\mathcal{F}'$ there is no guarantee that this should even happen. In fact, $f^*_{\\mathcal{F}'}$ might well be worse.\n",
        "As illustrated by :numref:`fig_functionclasses`,\n",
        "for non-nested function classes, a larger function class does not always move closer to the \"truth\" function $f^*$. For instance,\n",
        "on the left of :numref:`fig_functionclasses`,\n",
        "though $\\mathcal{F}_3$ is closer to $f^*$ than $\\mathcal{F}_1$, $\\mathcal{F}_6$ moves away and there is no guarantee that further increasing the complexity can reduce the distance from $f^*$.\n",
        "With nested function classes\n",
        "where $\\mathcal{F}_1 \\subseteq \\cdots \\subseteq \\mathcal{F}_6$\n",
        "on the right of :numref:`fig_functionclasses`,\n",
        "we can avoid the aforementioned issue from the non-nested function classes.\n",
        "\n",
        "\n",
        "![For non-nested function classes, a larger (indicated by area) function class does not guarantee we will get closer to the \"truth\" function ($\\mathit{f}^*$). This does not happen in nested function classes.](http://d2l.ai/_images/functionclasses.svg)\n",
        ":label:`fig_functionclasses`\n",
        "\n",
        "Thus,\n",
        "only if larger function classes contain the smaller ones are we guaranteed that increasing them strictly increases the expressive power of the network.\n",
        "For deep neural networks,\n",
        "if we can\n",
        "train the newly-added layer into an identity function $f(\\mathbf{x}) = \\mathbf{x}$, the new model will be as effective as the original model. As the new model may get a better solution to fit the training dataset, the added layer might make it easier to reduce training errors.\n",
        "\n",
        "This is the question that :citet:`He.Zhang.Ren.ea.2016` considered when working on very deep computer vision models.\n",
        "At the heart of their proposed *residual network* (*ResNet*) is the idea that every additional layer should\n",
        "more easily\n",
        "contain the identity function as one of its elements.\n",
        "These considerations are rather profound but they led to a surprisingly simple\n",
        "solution, a *residual block*.\n",
        "With it, ResNet won the ImageNet Large Scale Visual Recognition Challenge in 2015. The design had a profound influence on how to\n",
        "build deep neural networks. For instance, residual blocks have been added to recurrent networks :cite:`prakash2016neural,kim2017residual`. Likewise, Transformers :cite:`Vaswani.Shazeer.Parmar.ea.2017` use them to stack many layers of networks efficiently. It is also used in graph neural networks :cite:`Kipf.Welling.2016` and, as a basic concept, it has been used extensively in computer vision :cite:`Redmon.Farhadi.2018,Ren.He.Girshick.ea.2015`.\n",
        "Note that residual networks are predated by highway networks :cite:`srivastava2015highway` that share some of the motivation, albeit without the elegant parametrization around the identity function.\n",
        "\n",
        "\n",
        "## (**Residual Blocks**)\n",
        ":label:`subsec_residual-blks`\n",
        "\n",
        "Let's focus on a local part of a neural network, as depicted in :numref:`fig_residual_block`. Denote the input by $\\mathbf{x}$.\n",
        "We assume that $f(\\mathbf{x})$, the desired underlying mapping we want to obtain by learning, is to be used as input to the activation function on the top.\n",
        "On the left,\n",
        "the portion within the dotted-line box\n",
        "must directly learn $f(\\mathbf{x})$.\n",
        "On the right,\n",
        "the portion within the dotted-line box\n",
        "needs to\n",
        "learn the *residual mapping* $g(\\mathbf{x}) = f(\\mathbf{x}) - \\mathbf{x}$,\n",
        "which is how the residual block derives its name.\n",
        "If the identity mapping $f(\\mathbf{x}) = \\mathbf{x}$ is the desired underlying mapping,\n",
        "the residual mapping amounts to $g(\\mathbf{x}) = 0$ and it is thus easier to learn:\n",
        "we only need to push the weights and biases\n",
        "of the\n",
        "upper weight layer (e.g., fully connected layer and convolutional layer)\n",
        "within the dotted-line box\n",
        "to zero.\n",
        "The right figure illustrates the *residual block* of ResNet,\n",
        "where the solid line carrying the layer input\n",
        "$\\mathbf{x}$ to the addition operator\n",
        "is called a *residual connection* (or *shortcut connection*).\n",
        "With residual blocks, inputs can\n",
        "forward propagate faster through the residual connections across layers.\n",
        "In fact,\n",
        "the residual block\n",
        "can be thought of as\n",
        "a special case of the multi-branch Inception block:\n",
        "it has two branches\n",
        "one of which is the identity mapping.\n",
        "\n",
        "![In a regular block (left), the portion within the dotted-line box must directly learn the mapping $\\mathit{f}(\\mathbf{x})$. In a residual block (right), the portion within the dotted-line box needs to learn the residual mapping $\\mathit{g}(\\mathbf{x}) = \\mathit{f}(\\mathbf{x}) - \\mathbf{x}$, making the identity mapping $\\mathit{f}(\\mathbf{x}) = \\mathbf{x}$ easier to learn.](https://github.com/mdaffaalghiffari23/KomputasiIntelegensia/blob/img/residual-block.svg?raw=1)\n",
        ":label:`fig_residual_block`\n",
        "\n",
        "\n",
        "ResNet has VGG's full $3\\times 3$ convolutional layer design. The residual block has two $3\\times 3$ convolutional layers with the same number of output channels. Each convolutional layer is followed by a batch normalization layer and a ReLU activation function. Then, we skip these two convolution operations and add the input directly before the final ReLU activation function.\n",
        "This kind of design requires that the output of the two convolutional layers has to be of the same shape as the input, so that they can be added together. If we want to change the number of channels, we need to introduce an additional $1\\times 1$ convolutional layer to transform the input into the desired shape for the addition operation. Let's have a look at the code below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35fa7497",
      "metadata": {
        "id": "35fa7497"
      },
      "outputs": [],
      "source": [
        "class Residual(nn.Module):  #save\n",
        "    \"\"\"The Residual block of ResNet models.\"\"\"\n",
        "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1,\n",
        "                                   stride=strides)\n",
        "        self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)\n",
        "        if use_1x1conv:\n",
        "            self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
        "                                       stride=strides)\n",
        "        else:\n",
        "            self.conv3 = None\n",
        "        self.bn1 = nn.LazyBatchNorm2d()\n",
        "        self.bn2 = nn.LazyBatchNorm2d()\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "        if self.conv3:\n",
        "            X = self.conv3(X)\n",
        "        Y += X\n",
        "        return F.relu(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5a254f6",
      "metadata": {
        "id": "d5a254f6"
      },
      "source": [
        "This code generates two types of networks: one where we add the input to the output before applying the ReLU nonlinearity whenever `use_1x1conv=False`; and one where we adjust channels and resolution by means of a $1 \\times 1$ convolution before adding. :numref:`fig_resnet_block` illustrates this.\n",
        "\n",
        "![ResNet block with and without $1 \\times 1$ convolution, which transforms the input into the desired shape for the addition operation.](https://github.com/mdaffaalghiffari23/KomputasiIntelegensia/blob/img/resnet-block.svg?raw=1)\n",
        ":label:`fig_resnet_block`\n",
        "\n",
        "Now let's look at [**a situation where the input and output are of the same shape**], where $1 \\times 1$ convolution is not needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2057b8bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2057b8bc",
        "outputId": "c32505a6-2303-4c97-bb42-0c1cc31e5222"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 3, 6, 6])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "blk = Residual(3)\n",
        "X = torch.randn(4, 3, 6, 6)\n",
        "blk(X).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81b3b8b1",
      "metadata": {
        "id": "81b3b8b1"
      },
      "source": [
        "We also have the option to [**halve the output height and width while increasing the number of output channels**].\n",
        "In this case we use $1 \\times 1$ convolutions via `use_1x1conv=True`. This comes in handy at the beginning of each ResNet block to reduce the spatial dimensionality via `strides=2`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "341c1c55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "341c1c55",
        "outputId": "1b1029f3-8579-4e5e-f9f0-731e200990b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 6, 3, 3])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "blk = Residual(6, use_1x1conv=True, strides=2)\n",
        "blk(X).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "735745a2",
      "metadata": {
        "id": "735745a2"
      },
      "source": [
        "## [**ResNet Model**]\n",
        "\n",
        "The first two layers of ResNet are the same as those of the GoogLeNet we described before: the $7\\times 7$ convolutional layer with 64 output channels and a stride of 2 is followed by the $3\\times 3$ max-pooling layer with a stride of 2. The difference is the batch normalization layer added after each convolutional layer in ResNet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "393dd8de",
      "metadata": {
        "id": "393dd8de"
      },
      "outputs": [],
      "source": [
        "class ResNet(d2l.Classifier):\n",
        "    def b1(self):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "537173c6",
      "metadata": {
        "id": "537173c6"
      },
      "source": [
        "GoogLeNet uses four modules made up of Inception blocks.\n",
        "However, ResNet uses four modules made up of residual blocks, each of which uses several residual blocks with the same number of output channels.\n",
        "The number of channels in the first module is the same as the number of input channels. Since a max-pooling layer with a stride of 2 has already been used, it is not necessary to reduce the height and width. In the first residual block for each of the subsequent modules, the number of channels is doubled compared with that of the previous module, and the height and width are halved.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d92b69c",
      "metadata": {
        "id": "4d92b69c"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(ResNet)\n",
        "def block(self, num_residuals, num_channels, first_block=False):\n",
        "    blk = []\n",
        "    for i in range(num_residuals):\n",
        "        if i == 0 and not first_block:\n",
        "            blk.append(Residual(num_channels, use_1x1conv=True, strides=2))\n",
        "        else:\n",
        "            blk.append(Residual(num_channels))\n",
        "    return nn.Sequential(*blk)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "582781fd",
      "metadata": {
        "id": "582781fd"
      },
      "source": [
        "Then, we add all the modules to ResNet. Here, two residual blocks are used for each module. Lastly, just like GoogLeNet, we add a global average pooling layer, followed by the fully connected layer output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0019ee3f",
      "metadata": {
        "id": "0019ee3f"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(ResNet)\n",
        "def __init__(self, arch, lr=0.1, num_classes=10):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.save_hyperparameters()\n",
        "    self.net = nn.Sequential(self.b1())\n",
        "    for i, b in enumerate(arch):\n",
        "        self.net.add_module(f'b{i+2}', self.block(*b, first_block=(i==0)))\n",
        "    self.net.add_module('last', nn.Sequential(\n",
        "        nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "        nn.LazyLinear(num_classes)))\n",
        "    self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91a9c2ac",
      "metadata": {
        "id": "91a9c2ac"
      },
      "source": [
        "There are four convolutional layers in each module (excluding the $1\\times 1$ convolutional layer). Together with the first $7\\times 7$ convolutional layer and the final fully connected layer, there are 18 layers in total. Therefore, this model is commonly known as ResNet-18.\n",
        "By configuring different numbers of channels and residual blocks in the module, we can create different ResNet models, such as the deeper 152-layer ResNet-152. Although the main architecture of ResNet is similar to that of GoogLeNet, ResNet's structure is simpler and easier to modify. All these factors have resulted in the rapid and widespread use of ResNet. :numref:`fig_resnet18` depicts the full ResNet-18.\n",
        "\n",
        "![The ResNet-18 architecture.](https://github.com/mdaffaalghiffari23/KomputasiIntelegensia/blob/img/resnet18-90.svg?raw=1)\n",
        ":label:`fig_resnet18`\n",
        "\n",
        "Before training ResNet, let's [**observe how the input shape changes across different modules in ResNet**]. As in all the previous architectures, the resolution decreases while the number of channels increases up until the point where a global average pooling layer aggregates all features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61e60e34",
      "metadata": {
        "id": "61e60e34"
      },
      "outputs": [],
      "source": [
        "class ResNet18(ResNet):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__(((2, 64), (2, 128), (2, 256), (2, 512)),\n",
        "                       lr, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f153f6ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f153f6ed",
        "outputId": "e7609118-ae1e-462e-a06e-efbd7a374281"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential output shape:\t torch.Size([1, 64, 24, 24])\n",
            "Sequential output shape:\t torch.Size([1, 64, 24, 24])\n",
            "Sequential output shape:\t torch.Size([1, 128, 12, 12])\n",
            "Sequential output shape:\t torch.Size([1, 256, 6, 6])\n",
            "Sequential output shape:\t torch.Size([1, 512, 3, 3])\n",
            "Sequential output shape:\t torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "ResNet18().layer_summary((1, 1, 96, 96))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c04c33c9",
      "metadata": {
        "id": "c04c33c9"
      },
      "source": [
        "## [**Training**]\n",
        "\n",
        "We train ResNet on the Fashion-MNIST dataset, just like before. ResNet is quite a powerful and flexible architecture. The plot capturing training and validation loss illustrates a significant gap between both graphs, with the training loss being considerably lower. For a network of this flexibility, more training data would offer distinct benefit in closing the gap and improving accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61b87bb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "61b87bb9",
        "outputId": "5a350b56-7f37-4d54-97fe-3ae4a2394223"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-10-03T15:29:46.967798</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 238.965625 183.35625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"md7348a6d12\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#md7348a6d12\" x=\"30.103125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.921875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#md7348a6d12\" x=\"69.163125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(65.981875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#md7348a6d12\" x=\"108.223125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(105.041875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#md7348a6d12\" x=\"147.283125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(144.101875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#md7348a6d12\" x=\"186.343125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(183.161875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#md7348a6d12\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m5c2e22f107\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m5c2e22f107\" x=\"30.103125\" y=\"142.394652\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.0 -->\n      <g transform=\"translate(7.2 146.193871) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m5c2e22f107\" x=\"30.103125\" y=\"114.237756\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.2 -->\n      <g transform=\"translate(7.2 118.036975) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m5c2e22f107\" x=\"30.103125\" y=\"86.08086\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 89.880079) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m5c2e22f107\" x=\"30.103125\" y=\"57.923964\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 61.723183) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m5c2e22f107\" x=\"30.103125\" y=\"29.767068\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 33.566286) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 34.954394 63.182188 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 49.633125 89.679791 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_16\"/>\n   <g id=\"line2d_17\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 49.633125 89.679791 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 49.633125 21.310531 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 49.633125 89.679791 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 49.633125 21.310531 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 49.633125 89.679791 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 49.633125 21.310531 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path d=\"M 49.633125 21.310531 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_34\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_35\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_40\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_44\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_45\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_46\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_47\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_48\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_50\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_53\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_54\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_56\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_57\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_58\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_59\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_60\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_61\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_62\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_63\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_64\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_65\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_66\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_67\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_68\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_69\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_70\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_71\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_72\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_73\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_74\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_75\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_76\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_77\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_78\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_79\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \nL 147.283125 14.641646 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_80\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \nL 151.884543 133.333433 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_81\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_82\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \nL 147.283125 14.641646 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_83\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \nL 151.884543 133.333433 \nL 161.628722 131.461522 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_84\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_85\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \nL 147.283125 14.641646 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_86\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \nL 151.884543 133.333433 \nL 161.628722 131.461522 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_87\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \nL 166.813125 93.330536 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_88\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \nL 147.283125 14.641646 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_89\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \nL 151.884543 133.333433 \nL 161.628722 131.461522 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_90\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \nL 166.813125 93.330536 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_91\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \nL 147.283125 14.641646 \nL 166.813125 16.771791 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_92\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \nL 151.884543 133.333433 \nL 161.628722 131.461522 \nL 171.372901 135.550915 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_93\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \nL 166.813125 93.330536 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_94\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \nL 147.283125 14.641646 \nL 166.813125 16.771791 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_95\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \nL 151.884543 133.333433 \nL 161.628722 131.461522 \nL 171.372901 135.550915 \nL 181.11708 134.673924 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_96\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \nL 166.813125 93.330536 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_97\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \nL 147.283125 14.641646 \nL 166.813125 16.771791 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_98\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \nL 151.884543 133.333433 \nL 161.628722 131.461522 \nL 171.372901 135.550915 \nL 181.11708 134.673924 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_99\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \nL 166.813125 93.330536 \nL 186.343125 102.360569 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_100\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \nL 147.283125 14.641646 \nL 166.813125 16.771791 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_101\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \nL 151.884543 133.333433 \nL 161.628722 131.461522 \nL 171.372901 135.550915 \nL 181.11708 134.673924 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_102\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \nL 166.813125 93.330536 \nL 186.343125 102.360569 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_103\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \nL 147.283125 14.641646 \nL 166.813125 16.771791 \nL 186.343125 14.015133 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_104\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \nL 151.884543 133.333433 \nL 161.628722 131.461522 \nL 171.372901 135.550915 \nL 181.11708 134.673924 \nL 190.861259 137.829557 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_105\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \nL 166.813125 93.330536 \nL 186.343125 102.360569 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_106\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \nL 147.283125 14.641646 \nL 166.813125 16.771791 \nL 186.343125 14.015133 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_107\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \nL 151.884543 133.333433 \nL 161.628722 131.461522 \nL 171.372901 135.550915 \nL 181.11708 134.673924 \nL 190.861259 137.829557 \nL 200.605438 137.563801 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_108\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \nL 166.813125 93.330536 \nL 186.343125 102.360569 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_109\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \nL 147.283125 14.641646 \nL 166.813125 16.771791 \nL 186.343125 14.015133 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_110\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \nL 151.884543 133.333433 \nL 161.628722 131.461522 \nL 171.372901 135.550915 \nL 181.11708 134.673924 \nL 190.861259 137.829557 \nL 200.605438 137.563801 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_111\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \nL 166.813125 93.330536 \nL 186.343125 102.360569 \nL 205.873125 90.006108 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_112\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \nL 147.283125 14.641646 \nL 166.813125 16.771791 \nL 186.343125 14.015133 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_113\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \nL 151.884543 133.333433 \nL 161.628722 131.461522 \nL 171.372901 135.550915 \nL 181.11708 134.673924 \nL 190.861259 137.829557 \nL 200.605438 137.563801 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_114\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \nL 166.813125 93.330536 \nL 186.343125 102.360569 \nL 205.873125 90.006108 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_115\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \nL 147.283125 14.641646 \nL 166.813125 16.771791 \nL 186.343125 14.015133 \nL 205.873125 16.187046 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_116\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \nL 151.884543 133.333433 \nL 161.628722 131.461522 \nL 171.372901 135.550915 \nL 181.11708 134.673924 \nL 190.861259 137.829557 \nL 200.605438 137.563801 \nL 210.349618 139.5 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_117\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \nL 166.813125 93.330536 \nL 186.343125 102.360569 \nL 205.873125 90.006108 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_118\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \nL 147.283125 14.641646 \nL 166.813125 16.771791 \nL 186.343125 14.015133 \nL 205.873125 16.187046 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_119\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \nL 151.884543 133.333433 \nL 161.628722 131.461522 \nL 171.372901 135.550915 \nL 181.11708 134.673924 \nL 190.861259 137.829557 \nL 200.605438 137.563801 \nL 210.349618 139.5 \nL 220.093797 139.038949 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_120\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \nL 166.813125 93.330536 \nL 186.343125 102.360569 \nL 205.873125 90.006108 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_121\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \nL 147.283125 14.641646 \nL 166.813125 16.771791 \nL 186.343125 14.015133 \nL 205.873125 16.187046 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_122\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \nL 151.884543 133.333433 \nL 161.628722 131.461522 \nL 171.372901 135.550915 \nL 181.11708 134.673924 \nL 190.861259 137.829557 \nL 200.605438 137.563801 \nL 210.349618 139.5 \nL 220.093797 139.038949 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_123\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \nL 166.813125 93.330536 \nL 186.343125 102.360569 \nL 205.873125 90.006108 \nL 225.403125 98.535184 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_124\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \nL 147.283125 14.641646 \nL 166.813125 16.771791 \nL 186.343125 14.015133 \nL 205.873125 16.187046 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_125\">\n    <path d=\"M 34.954394 63.182188 \nL 44.698573 93.76243 \nL 54.442752 104.095567 \nL 64.186931 105.298058 \nL 73.93111 113.333348 \nL 83.675289 112.881076 \nL 93.419468 119.168659 \nL 103.163647 119.060542 \nL 112.907826 125.058757 \nL 122.652006 123.488934 \nL 132.396185 129.474484 \nL 142.140364 127.72816 \nL 151.884543 133.333433 \nL 161.628722 131.461522 \nL 171.372901 135.550915 \nL 181.11708 134.673924 \nL 190.861259 137.829557 \nL 200.605438 137.563801 \nL 210.349618 139.5 \nL 220.093797 139.038949 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_126\">\n    <path d=\"M 49.633125 89.679791 \nL 69.163125 95.935318 \nL 88.693125 103.292168 \nL 108.223125 104.736014 \nL 127.753125 89.52809 \nL 147.283125 102.623086 \nL 166.813125 93.330536 \nL 186.343125 102.360569 \nL 205.873125 90.006108 \nL 225.403125 98.535184 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_127\">\n    <path d=\"M 49.633125 21.310531 \nL 69.163125 18.470338 \nL 88.693125 15.37954 \nL 108.223125 15.296005 \nL 127.753125 19.444914 \nL 147.283125 14.641646 \nL 166.813125 16.771791 \nL 186.343125 14.015133 \nL 205.873125 16.187046 \nL 225.403125 13.5 \n\" clip-path=\"url(#p5d330d9e69)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 145.8 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 138.8125 100.434375 \nL 218.403125 100.434375 \nQ 220.403125 100.434375 220.403125 98.434375 \nL 220.403125 54.565625 \nQ 220.403125 52.565625 218.403125 52.565625 \nL 138.8125 52.565625 \nQ 136.8125 52.565625 136.8125 54.565625 \nL 136.8125 98.434375 \nQ 136.8125 100.434375 138.8125 100.434375 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_128\">\n     <path d=\"M 140.8125 60.664063 \nL 150.8125 60.664063 \nL 160.8125 60.664063 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- train_loss -->\n     <g transform=\"translate(168.8125 64.164063) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_129\">\n     <path d=\"M 140.8125 75.620313 \nL 150.8125 75.620313 \nL 160.8125 75.620313 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_14\">\n     <!-- val_loss -->\n     <g transform=\"translate(168.8125 79.120313) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n    <g id=\"line2d_130\">\n     <path d=\"M 140.8125 90.576563 \nL 150.8125 90.576563 \nL 160.8125 90.576563 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_15\">\n     <!-- val_acc -->\n     <g transform=\"translate(168.8125 94.076563) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p5d330d9e69\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = ResNet18(lr=0.01)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(96, 96))\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc09eb06",
      "metadata": {
        "id": "bc09eb06"
      },
      "source": [
        "## ResNeXt\n",
        ":label:`subsec_resnext`\n",
        "\n",
        "One of the challenges one encounters in the design of ResNet is the trade-off between nonlinearity and dimensionality within a given block. That is, we could add more nonlinearity by increasing the number of layers, or by increasing the width of the convolutions. An alternative strategy is to increase the number of channels that can carry information between blocks. Unfortunately, the latter comes with a quadratic penalty since the computational cost of ingesting $c_\\textrm{i}$ channels and emitting $c_\\textrm{o}$ channels is proportional to $\\mathcal{O}(c_\\textrm{i} \\cdot c_\\textrm{o})$ (see our discussion in :numref:`sec_channels`).\n",
        "\n",
        "We can take some inspiration from the Inception block of :numref:`fig_inception` which has information flowing through the block in separate groups. Applying the idea of multiple independent groups to the ResNet block of :numref:`fig_resnet_block` led to the design of ResNeXt :cite:`Xie.Girshick.Dollar.ea.2017`.\n",
        "Different from the smorgasbord of transformations in Inception,\n",
        "ResNeXt adopts the *same* transformation in all branches,\n",
        "thus minimizing the need for manual tuning of each branch.\n",
        "\n",
        "![The ResNeXt block. The use of grouped convolution with $\\mathit{g}$ groups is $\\mathit{g}$ times faster than a dense convolution. It is a bottleneck residual block when the number of intermediate channels $\\mathit{b}$ is less than $\\mathit{c}$.](https://github.com/mdaffaalghiffari23/KomputasiIntelegensia/blob/img/resnext-block.svg?raw=1)\n",
        ":label:`fig_resnext_block`\n",
        "\n",
        "Breaking up a convolution from $c_\\textrm{i}$ to $c_\\textrm{o}$ channels into one of $g$ groups of size $c_\\textrm{i}/g$ generating $g$ outputs of size $c_\\textrm{o}/g$ is called, quite fittingly, a *grouped convolution*. The computational cost (proportionally) is reduced from $\\mathcal{O}(c_\\textrm{i} \\cdot c_\\textrm{o})$ to $\\mathcal{O}(g \\cdot (c_\\textrm{i}/g) \\cdot (c_\\textrm{o}/g)) = \\mathcal{O}(c_\\textrm{i} \\cdot c_\\textrm{o} / g)$, i.e., it is $g$ times faster. Even better, the number of parameters needed to generate the output is also reduced from a $c_\\textrm{i} \\times c_\\textrm{o}$ matrix to $g$ smaller matrices of size $(c_\\textrm{i}/g) \\times (c_\\textrm{o}/g)$, again a $g$ times reduction. In what follows we assume that both $c_\\textrm{i}$ and $c_\\textrm{o}$ are divisible by $g$.\n",
        "\n",
        "The only challenge in this design is that no information is exchanged between the $g$ groups. The ResNeXt block of\n",
        ":numref:`fig_resnext_block` amends this in two ways: the grouped convolution with a $3 \\times 3$ kernel is sandwiched in between two $1 \\times 1$ convolutions. The second one serves double duty in changing the number of channels back. The benefit is that we only pay the $\\mathcal{O}(c \\cdot b)$ cost for $1 \\times 1$ kernels and can make do with an $\\mathcal{O}(b^2 / g)$ cost for $3 \\times 3$ kernels. Similar to the residual block implementation in\n",
        ":numref:`subsec_residual-blks`, the residual connection is replaced (thus generalized) by a $1 \\times 1$ convolution.\n",
        "\n",
        "The right-hand figure in :numref:`fig_resnext_block` provides a much more concise summary of the resulting network block. It will also play a major role in the design of generic modern CNNs in :numref:`sec_cnn-design`. Note that the idea of grouped convolutions dates back to the implementation of AlexNet :cite:`Krizhevsky.Sutskever.Hinton.2012`. When distributing the network across two GPUs with limited memory, the implementation treated each GPU as its own channel with no ill effects.\n",
        "\n",
        "The following implementation of the `ResNeXtBlock` class takes as argument `groups` ($g$), with\n",
        "`bot_channels` ($b$) intermediate (bottleneck) channels. Lastly, when we need to reduce the height and width of the representation, we add a stride of $2$ by setting `use_1x1conv=True, strides=2`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa67ceaf",
      "metadata": {
        "id": "aa67ceaf"
      },
      "outputs": [],
      "source": [
        "class ResNeXtBlock(nn.Module):  #@save\n",
        "    \"\"\"The ResNeXt block.\"\"\"\n",
        "    def __init__(self, num_channels, groups, bot_mul, use_1x1conv=False,\n",
        "                 strides=1):\n",
        "        super().__init__()\n",
        "        bot_channels = int(round(num_channels * bot_mul))\n",
        "        self.conv1 = nn.LazyConv2d(bot_channels, kernel_size=1, stride=1)\n",
        "        self.conv2 = nn.LazyConv2d(bot_channels, kernel_size=3,\n",
        "                                   stride=strides, padding=1,\n",
        "                                   groups=bot_channels//groups)\n",
        "        self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1, stride=1)\n",
        "        self.bn1 = nn.LazyBatchNorm2d()\n",
        "        self.bn2 = nn.LazyBatchNorm2d()\n",
        "        self.bn3 = nn.LazyBatchNorm2d()\n",
        "        if use_1x1conv:\n",
        "            self.conv4 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
        "                                       stride=strides)\n",
        "            self.bn4 = nn.LazyBatchNorm2d()\n",
        "        else:\n",
        "            self.conv4 = None\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\n",
        "        Y = F.relu(self.bn2(self.conv2(Y)))\n",
        "        Y = self.bn3(self.conv3(Y))\n",
        "        if self.conv4:\n",
        "            X = self.bn4(self.conv4(X))\n",
        "        return F.relu(Y + X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03b62951",
      "metadata": {
        "id": "03b62951"
      },
      "source": [
        "Its use is entirely analogous to that of the `ResNetBlock` discussed previously. For instance, when using (`use_1x1conv=False, strides=1`), the input and output are of the same shape. Alternatively, setting `use_1x1conv=True, strides=2` halves the output height and width.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec6906e4",
      "metadata": {
        "id": "ec6906e4",
        "outputId": "add4e16c-9651-44b3-a45f-d9e4ae94e045"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 32, 96, 96])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "blk = ResNeXtBlock(32, 16, 1)\n",
        "X = torch.randn(4, 32, 96, 96)\n",
        "blk(X).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94a2283f",
      "metadata": {
        "id": "94a2283f"
      },
      "source": [
        "## Summary and Discussion\n",
        "\n",
        "Nested function classes are desirable since they allow us to obtain strictly *more powerful* rather than also subtly *different* function classes when adding capacity. One way of accomplishing this is by letting additional layers to simply pass through the input to the output. Residual connections allow for this. As a consequence, this changes the inductive bias from simple functions being of the form $f(\\mathbf{x}) = 0$ to simple functions looking like $f(\\mathbf{x}) = \\mathbf{x}$.\n",
        "\n",
        "\n",
        "The residual mapping can learn the identity function more easily, such as pushing parameters in the weight layer to zero. We can train an effective *deep* neural network by having residual blocks. Inputs can forward propagate faster through the residual connections across layers. As a consequence, we can thus train much deeper networks. For instance, the original ResNet paper :cite:`He.Zhang.Ren.ea.2016` allowed for up to 152 layers. Another benefit of residual networks is that it allows us to add layers, initialized as the identity function, *during* the training process. After all, the default behavior of a layer is to let the data pass through unchanged. This can accelerate the training of very large networks in some cases.\n",
        "\n",
        "Prior to residual connections,\n",
        "bypassing paths with gating units were introduced\n",
        "to effectively train highway networks with over 100 layers\n",
        ":cite:`srivastava2015highway`.\n",
        "Using identity functions as bypassing paths,\n",
        "ResNet performed remarkably well\n",
        "on multiple computer vision tasks.\n",
        "Residual connections had a major influence on the design of subsequent deep neural networks, of either convolutional or sequential nature.\n",
        "As we will introduce later,\n",
        "the Transformer architecture :cite:`Vaswani.Shazeer.Parmar.ea.2017`\n",
        "adopts residual connections (together with other design choices) and is pervasive\n",
        "in areas as diverse as\n",
        "language, vision, speech, and reinforcement learning.\n",
        "\n",
        "ResNeXt is an example for how the design of convolutional neural networks has evolved over time: by being more frugal with computation and trading it off against the size of the activations (number of channels), it allows for faster and more accurate networks at lower cost. An alternative way of viewing grouped convolutions is to think of a block-diagonal matrix for the convolutional weights. Note that there are quite a few such \"tricks\" that lead to more efficient networks. For instance, ShiftNet :cite:`wu2018shift` mimicks the effects of a $3 \\times 3$ convolution, simply by adding shifted activations to the channels, offering increased function complexity, this time without any computational cost.\n",
        "\n",
        "A common feature of the designs we have discussed so far is that the network design is fairly manual, primarily relying on the ingenuity of the designer to find the \"right\" network hyperparameters. While clearly feasible, it is also very costly in terms of human time and there is no guarantee that the outcome is optimal in any sense. In :numref:`sec_cnn-design` we will discuss a number of strategies for obtaining high quality networks in a more automated fashion. In particular, we will review the notion of *network design spaces* that led to the RegNetX/Y models\n",
        ":cite:`Radosavovic.Kosaraju.Girshick.ea.2020`.\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. What are the major differences between the Inception block in :numref:`fig_inception` and the residual block? How do they compare in terms of computation, accuracy, and the classes of functions they can describe?\n",
        "1. Refer to Table 1 in the ResNet paper :cite:`He.Zhang.Ren.ea.2016` to implement different variants of the network.\n",
        "1. For deeper networks, ResNet introduces a \"bottleneck\" architecture to reduce model complexity. Try to implement it.\n",
        "1. In subsequent versions of ResNet, the authors changed the \"convolution, batch normalization, and activation\" structure to the \"batch normalization, activation, and convolution\" structure. Make this improvement yourself. See Figure 1 in :citet:`He.Zhang.Ren.ea.2016*1` for details.\n",
        "1. Why can't we just increase the complexity of functions without bound, even if the function classes are nested?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GCVNjXW3-utI",
      "metadata": {
        "id": "GCVNjXW3-utI"
      },
      "source": [
        " No. 1\n",
        "\n",
        "1. What are the major differences between the Inception block in Fig. 8.4.1 and the residual block? How do they compare in terms of computation, accuracy, and the classes of functions they can describe?\n",
        "\n",
        "\n",
        "Blok Inception dan blok residual adalah dua komponen arsitektur yang berbeda dalam jaringan saraf dalam. Blok Inception, diperkenalkan dalam GoogLeNet, dirancang untuk menangkap fitur pada berbagai skala melalui konvolusi paralel dengan ukuran kernel yang berbeda dan operasi pooling. Ini memungkinkan penggabungan informasi dari berbagai bidang penerimaan.\n",
        "\n",
        "Sementara itu, blok residual, yang diperkenalkan dalam ResNet, fokus pada mengatasi masalah vanishing gradient dengan menggunakan koneksi lompatan yang mengalirkan input langsung ke lapisan berikutnya. Koneksi ini membantu model mempelajari transformasi residual dan mempercepat pelatihan melalui normalisasi batch.\n",
        "\n",
        "Secara keseluruhan, blok Inception menekankan penangkapan fitur skala berbeda, sedangkan blok residual memfasilitasi pelatihan jaringan yang dalam dengan koneksi lompatan. Keduanya sangat berkontribusi dalam meningkatkan kinerja jaringan saraf dalam berbagai tugas."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kh82uuZX-iRc",
      "metadata": {
        "id": "kh82uuZX-iRc"
      },
      "source": [
        "No. 2\n",
        "\n",
        "Refer to Table 1 in the ResNet paper (He et al., 2016) to implement different variants of the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h8rNAkNPBWuV",
      "metadata": {
        "id": "h8rNAkNPBWuV"
      },
      "outputs": [],
      "source": [
        "class Residual(nn.Module):\n",
        "    def __init__(self, convs, conv_1x1_channel, strides=1):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        for i,conv in enumerate(convs):\n",
        "            num_channels, kernel_size, padding = conv\n",
        "            conv_strides = 1 if i != 0 else strides\n",
        "            layers.append(nn.LazyConv2d(num_channels, kernel_size=3, padding=1, stride=conv_strides))\n",
        "            layers.append(nn.LazyBatchNorm2d())\n",
        "            layers.append(nn.ReLU())\n",
        "        self.net = nn.Sequential(*layers[:-1])\n",
        "        self.conv = None\n",
        "        if conv_1x1_channel:\n",
        "            self.conv = nn.LazyConv2d(conv_1x1_channel, kernel_size=1, stride=strides)\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = self.net(X)\n",
        "        if self.conv:\n",
        "            X = self.conv(X)\n",
        "        Y += X\n",
        "        return F.relu(Y)\n",
        "\n",
        "class ResNet(d2l.Classifier):\n",
        "    def block(self, num_residuals, convs, conv_1x1_channel, first_block=False):\n",
        "        blk = []\n",
        "        for i in range(num_residuals):\n",
        "            if i == 0 and not first_block:\n",
        "                blk.append(Residual(convs, conv_1x1_channel,strides=2))\n",
        "            else:\n",
        "                blk.append(Residual(convs, conv_1x1_channel))\n",
        "        return nn.Sequential(*blk)\n",
        "\n",
        "    def __init__(self, arch, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "        for i, b in enumerate(arch):\n",
        "            self.net.add_module(f'b{i+2}', self.block(*b, first_block=(i==0)))\n",
        "        self.net.add_module('last', nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "            nn.LazyLinear(num_classes)))\n",
        "        self.net.apply(d2l.init_cnn)\n",
        "\n",
        "def experiment(data, model):\n",
        "    model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "    trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "    trainer.fit(model, data)\n",
        "    X,y = next(iter(data.get_dataloader(False)))\n",
        "    X = X.to('cuda')\n",
        "    y = y.to('cuda')\n",
        "    y_hat = model(X)\n",
        "    return model.accuracy(y_hat,y).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l3xKiRLTBix-",
      "metadata": {
        "id": "l3xKiRLTBix-"
      },
      "outputs": [],
      "source": [
        "data = d2l.FashionMNIST(batch_size=64, resize=(224, 224))\n",
        "arch18 = [(2,[(64,3,1)]*2,None),(2,[(128,3,1)]*2,None),(2,[(256,3,1)]*2,None),(2,[(512,3,1)]*2,None)]\n",
        "resnet18 = ResNet(arch=arch18, lr=0.01)\n",
        "experiment(data, resnet18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RgXHfDg1Bnw7",
      "metadata": {
        "id": "RgXHfDg1Bnw7"
      },
      "outputs": [],
      "source": [
        "arch34 = [(3,[(64,3,1)]*2,None),(4,[(128,3,1)]*2,None),(6,[(256,3,1)]*2,None),(3,[(512,3,1)]*2,None)]\n",
        "resnet34 = ResNet(arch=arch34, lr=0.01)\n",
        "experiment(data, resnet34)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CRS3P_CjBpLc",
      "metadata": {
        "id": "CRS3P_CjBpLc"
      },
      "source": [
        "No. 3\n",
        "\n",
        "For deeper networks, ResNet introduces a “bottleneck” architecture to reduce model complexity. Try to implement it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k_8SMAyFBr2G",
      "metadata": {
        "id": "k_8SMAyFBr2G"
      },
      "outputs": [],
      "source": [
        "arch50 = [(3,[(64,1,0),(64,3,1)],256),(4,[(128,1,0),(128,3,1)],512),(6,[(256,1,0),(256,3,1)],1024),(3,[(512,1,0),(512,3,1)],2048)]\n",
        "resnet50 = ResNet(arch=arch50, lr=0.01)\n",
        "experiment(data, resnet50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dP09dS-2CF9q",
      "metadata": {
        "id": "dP09dS-2CF9q"
      },
      "outputs": [],
      "source": [
        "arch101 = [(3,[(64,1,0),(64,3,1)],256),(4,[(128,1,0),(128,3,1)],512),(23,[(256,1,0),(256,3,1)],1024),(3,[(512,1,0),(512,3,1)],2048)]\n",
        "resnet101 = ResNet(arch=arch101, lr=0.01)\n",
        "experiment(data, resnet101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-XKD0JEaCHaC",
      "metadata": {
        "id": "-XKD0JEaCHaC"
      },
      "outputs": [],
      "source": [
        "arch152 = [(3,[(64,1,0),(64,3,1)],256),(8,[(128,1,0),(128,3,1)],512),(36,[(256,1,0),(256,3,1)],1024),(3,[(512,1,0),(512,3,1)],2048)]\n",
        "resnet152 = ResNet(arch=arch152, lr=0.01)\n",
        "experiment(data, resnet152)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2qVpIiNCKIy",
      "metadata": {
        "id": "a2qVpIiNCKIy"
      },
      "source": [
        "No. 4\n",
        "\n",
        "In subsequent versions of ResNet, the authors changed the “convolution, batch normalization, and activation” structure to the “batch normalization, activation, and convolution” structure. Make this improvement yourself. See Figure 1 in He et al. (2016) for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lrXA25dECM5q",
      "metadata": {
        "id": "lrXA25dECM5q"
      },
      "outputs": [],
      "source": [
        "class SubResidual(nn.Module):\n",
        "    def __init__(self, convs, conv_1x1_channel, strides=1):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        for i,conv in enumerate(convs):\n",
        "            num_channels, kernel_size, padding = conv\n",
        "            conv_strides = 1 if i != 0 else strides\n",
        "            layers.append(nn.LazyBatchNorm2d())\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.LazyConv2d(num_channels, kernel_size=3, padding=1, stride=conv_strides))\n",
        "        self.net = nn.Sequential(*layers[:-1])\n",
        "        self.conv = None\n",
        "        if conv_1x1_channel:\n",
        "            self.conv = nn.LazyConv2d(conv_1x1_channel, kernel_size=1, stride=strides)\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = self.net(X)\n",
        "        if self.conv:\n",
        "            X = self.conv(X)\n",
        "        Y += X\n",
        "        return F.relu(Y)\n",
        "\n",
        "class SubResNet(d2l.Classifier):\n",
        "    def block(self, num_residuals, convs, conv_1x1_channel, first_block=False):\n",
        "        blk = []\n",
        "        for i in range(num_residuals):\n",
        "            if i == 0 and not first_block:\n",
        "                blk.append(SubResidual(convs, conv_1x1_channel,strides=2))\n",
        "            else:\n",
        "                blk.append(SubResidual(convs, conv_1x1_channel))\n",
        "        return nn.Sequential(*blk)\n",
        "\n",
        "    def __init__(self, arch, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "        for i, b in enumerate(arch):\n",
        "            self.net.add_module(f'b{i+2}', self.block(*b, first_block=(i==0)))\n",
        "        self.net.add_module('last', nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "            nn.LazyLinear(num_classes)))\n",
        "        self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JuOBMJOaCT9U",
      "metadata": {
        "id": "JuOBMJOaCT9U"
      },
      "outputs": [],
      "source": [
        "arch18 = [(2,[(64,3,1)]*2,None),(2,[(128,3,1)]*2,None),(2,[(256,3,1)]*2,None),(2,[(512,3,1)]*2,None)]\n",
        "resnet18 = SubResNet(arch=arch18, lr=0.01)\n",
        "experiment(data, resnet18)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cKX_M41TCXAk",
      "metadata": {
        "id": "cKX_M41TCXAk"
      },
      "source": [
        " No. 5\n",
        "\n",
        "Why can’t we just increase the complexity of functions without bound, even if the function classes are nested?\n",
        "\n",
        "Meningkatkan kompleksitas fungsi tanpa batas dapat menyebabkan masalah dalam pembelajaran mesin. Pertama, kompleksitas yang berlebihan dapat mengakibatkan overfitting, di mana model menyesuaikan diri terlalu baik dengan data pelatihan dan gagal menggeneralisasi pada data baru. Selain itu, model kompleks memerlukan lebih banyak sumber daya komputasi dan waktu pelatihan.\n",
        "\n",
        "Tambahan kompleksitas tidak selalu sebanding dengan peningkatan kinerja; ada titik di mana peningkatan hanya memberikan akurasi marginal. Model yang terlalu kompleks juga sulit diinterpretasikan dan mungkin memerlukan banyak data pelatihan untuk berfungsi dengan baik. Oleh karena itu, lebih baik memilih arsitektur model yang seimbang antara kapasitas dan generalisasi. Teknik seperti regularisasi dan cross-validation dapat meningkatkan kinerja tanpa meningkatkan kompleksitas secara berlebihan. Tujuannya adalah membangun model yang menangkap pola mendasar dalam data tanpa overfitting dan ketidak efisienan komputasi."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9jFgDik1DQ66",
      "metadata": {
        "id": "9jFgDik1DQ66"
      },
      "source": [
        "#8.7 Densely Connected Networks (DenseNet)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f122fb8e",
      "metadata": {
        "id": "f122fb8e"
      },
      "source": [
        "# Densely Connected Networks (DenseNet)\n",
        ":label:`sec_densenet`\n",
        "\n",
        "ResNet significantly changed the view of how to parametrize the functions in deep networks. *DenseNet* (dense convolutional network) is to some extent the logical extension of this :cite:`Huang.Liu.Van-Der-Maaten.ea.2017`.\n",
        "DenseNet is characterized by both the connectivity pattern where\n",
        "each layer connects to all the preceding layers\n",
        "and the concatenation operation (rather than the addition operator in ResNet) to preserve and reuse features\n",
        "from earlier layers.\n",
        "To understand how to arrive at it, let's take a small detour to mathematics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "898d7836",
      "metadata": {
        "id": "898d7836"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abbc7e4b",
      "metadata": {
        "id": "abbc7e4b"
      },
      "source": [
        "## From ResNet to DenseNet\n",
        "\n",
        "Recall the Taylor expansion for functions. At the point $x = 0$ it can be written as\n",
        "\n",
        "$$f(x) = f(0) + x \\cdot \\left[f'(0) + x \\cdot \\left[\\frac{f''(0)}{2!}  + x \\cdot \\left[\\frac{f'''(0)}{3!}  + \\cdots \\right]\\right]\\right].$$\n",
        "\n",
        "\n",
        "The key point is that it decomposes a function into terms of increasingly higher order. In a similar vein, ResNet decomposes functions into\n",
        "\n",
        "$$f(\\mathbf{x}) = \\mathbf{x} + g(\\mathbf{x}).$$\n",
        "\n",
        "That is, ResNet decomposes $f$ into a simple linear term and a more complex\n",
        "nonlinear one.\n",
        "What if we wanted to capture (not necessarily add) information beyond two terms?\n",
        "One such solution is DenseNet :cite:`Huang.Liu.Van-Der-Maaten.ea.2017`.\n",
        "\n",
        "![The main difference between ResNet (left) and DenseNet (right) in cross-layer connections: use of addition and use of concatenation. ](https://github.com/mdaffaalghiffari23/KomputasiIntelegensia/blob/img/densenet-block.svg?raw=1)\n",
        ":label:`fig_densenet_block`\n",
        "\n",
        "As shown in :numref:`fig_densenet_block`, the key difference between ResNet and DenseNet is that in the latter case outputs are *concatenated* (denoted by $[,]$) rather than added.\n",
        "As a result, we perform a mapping from $\\mathbf{x}$ to its values after applying an increasingly complex sequence of functions:\n",
        "\n",
        "$$\\mathbf{x} \\to \\left[\n",
        "\\mathbf{x},\n",
        "f_1(\\mathbf{x}),\n",
        "f_2\\left(\\left[\\mathbf{x}, f_1\\left(\\mathbf{x}\\right)\\right]\\right), f_3\\left(\\left[\\mathbf{x}, f_1\\left(\\mathbf{x}\\right), f_2\\left(\\left[\\mathbf{x}, f_1\\left(\\mathbf{x}\\right)\\right]\\right)\\right]\\right), \\ldots\\right].$$\n",
        "\n",
        "In the end, all these functions are combined in MLP to reduce the number of features again. In terms of implementation this is quite simple:\n",
        "rather than adding terms, we concatenate them. The name DenseNet arises from the fact that the dependency graph between variables becomes quite dense. The final layer of such a chain is densely connected to all previous layers. The dense connections are shown in :numref:`fig_densenet`.\n",
        "\n",
        "![Dense connections in DenseNet. Note how the dimensionality increases with depth.](http://d2l.ai/_images/densenet.svg)\n",
        ":label:`fig_densenet`\n",
        "\n",
        "The main components that comprise a DenseNet are *dense blocks* and *transition layers*. The former define how the inputs and outputs are concatenated, while the latter control the number of channels so that it is not too large,\n",
        "since the expansion $\\mathbf{x} \\to \\left[\\mathbf{x}, f_1(\\mathbf{x}),\n",
        "f_2\\left(\\left[\\mathbf{x}, f_1\\left(\\mathbf{x}\\right)\\right]\\right), \\ldots \\right]$ can be quite high-dimensional.\n",
        "\n",
        "\n",
        "## [**Dense Blocks**]\n",
        "\n",
        "DenseNet uses the modified \"batch normalization, activation, and convolution\"\n",
        "structure of ResNet (see the exercise in :numref:`sec_resnet`).\n",
        "First, we implement this convolution block structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d95675e",
      "metadata": {
        "id": "7d95675e"
      },
      "outputs": [],
      "source": [
        "def conv_block(num_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "        nn.LazyConv2d(num_channels, kernel_size=3, padding=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4e66d06",
      "metadata": {
        "id": "b4e66d06"
      },
      "source": [
        "A *dense block* consists of multiple convolution blocks, each using the same number of output channels. In the forward propagation, however, we concatenate the input and output of each convolution block on the channel dimension. Lazy evaluation allows us to adjust the dimensionality automatically.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "805394e3",
      "metadata": {
        "id": "805394e3"
      },
      "outputs": [],
      "source": [
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, num_convs, num_channels):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        layer = []\n",
        "        for i in range(num_convs):\n",
        "            layer.append(conv_block(num_channels))\n",
        "        self.net = nn.Sequential(*layer)\n",
        "\n",
        "    def forward(self, X):\n",
        "        for blk in self.net:\n",
        "            Y = blk(X)\n",
        "            # Concatenate input and output of each block along the channels\n",
        "            X = torch.cat((X, Y), dim=1)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b17dfe15",
      "metadata": {
        "id": "b17dfe15"
      },
      "source": [
        "In the following example,\n",
        "we [**define a `DenseBlock` instance**] with two convolution blocks of 10 output channels.\n",
        "When using an input with three channels, we will get an output with  $3 + 10 + 10=23$ channels. The number of convolution block channels controls the growth in the number of output channels relative to the number of input channels. This is also referred to as the *growth rate*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e369c1ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e369c1ad",
        "outputId": "eb42b4d5-d93f-4559-f2b4-adcb9ec03d01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 23, 8, 8])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "blk = DenseBlock(2, 10)\n",
        "X = torch.randn(4, 3, 8, 8)\n",
        "Y = blk(X)\n",
        "Y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69c8df7b",
      "metadata": {
        "id": "69c8df7b"
      },
      "source": [
        "## [**Transition Layers**]\n",
        "\n",
        "Since each dense block will increase the number of channels, adding too many of them will lead to an excessively complex model. A *transition layer* is used to control the complexity of the model. It reduces the number of channels by using a $1\\times 1$ convolution. Moreover, it halves the height and width via average pooling with a stride of 2.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6160cc48",
      "metadata": {
        "id": "6160cc48"
      },
      "outputs": [],
      "source": [
        "def transition_block(num_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "        nn.LazyConv2d(num_channels, kernel_size=1),\n",
        "        nn.AvgPool2d(kernel_size=2, stride=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "280d3329",
      "metadata": {
        "id": "280d3329"
      },
      "source": [
        "[**Apply a transition layer**] with 10 channels to the output of the dense block in the previous example.  This reduces the number of output channels to 10, and halves the height and width.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc0cacfc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc0cacfc",
        "outputId": "7e3aa030-f395-4440-e397-8dd0fa85e546"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 10, 4, 4])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "blk = transition_block(10)\n",
        "blk(Y).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9bc8e5c",
      "metadata": {
        "id": "b9bc8e5c"
      },
      "source": [
        "## [**DenseNet Model**]\n",
        "\n",
        "Next, we will construct a DenseNet model. DenseNet first uses the same single convolutional layer and max-pooling layer as in ResNet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79e0aaa1",
      "metadata": {
        "id": "79e0aaa1"
      },
      "outputs": [],
      "source": [
        "class DenseNet(d2l.Classifier):\n",
        "    def b1(self):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dccb085",
      "metadata": {
        "id": "6dccb085"
      },
      "source": [
        "Then, similar to the four modules made up of residual blocks that ResNet uses,\n",
        "DenseNet uses four dense blocks.\n",
        "As with ResNet, we can set the number of convolutional layers used in each dense block. Here, we set it to 4, consistent with the ResNet-18 model in :numref:`sec_resnet`. Furthermore, we set the number of channels (i.e., growth rate) for the convolutional layers in the dense block to 32, so 128 channels will be added to each dense block.\n",
        "\n",
        "In ResNet, the height and width are reduced between each module by a residual block with a stride of 2. Here, we use the transition layer to halve the height and width and halve the number of channels. Similar to ResNet, a global pooling layer and a fully connected layer are connected at the end to produce the output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58137883",
      "metadata": {
        "id": "58137883"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(DenseNet)\n",
        "def __init__(self, num_channels=64, growth_rate=32, arch=(4, 4, 4, 4),\n",
        "             lr=0.1, num_classes=10):\n",
        "    super(DenseNet, self).__init__()\n",
        "    self.save_hyperparameters()\n",
        "    self.net = nn.Sequential(self.b1())\n",
        "    for i, num_convs in enumerate(arch):\n",
        "        self.net.add_module(f'dense_blk{i+1}', DenseBlock(num_convs,\n",
        "                                                          growth_rate))\n",
        "        # The number of output channels in the previous dense block\n",
        "        num_channels += num_convs * growth_rate\n",
        "        # A transition layer that halves the number of channels is added\n",
        "        # between the dense blocks\n",
        "        if i != len(arch) - 1:\n",
        "            num_channels //= 2\n",
        "            self.net.add_module(f'tran_blk{i+1}', transition_block(\n",
        "                num_channels))\n",
        "    self.net.add_module('last', nn.Sequential(\n",
        "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "        nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "        nn.LazyLinear(num_classes)))\n",
        "    self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a04e481f",
      "metadata": {
        "id": "a04e481f"
      },
      "source": [
        "## [**Training**]\n",
        "\n",
        "Since we are using a deeper network here, in this section, we will reduce the input height and width from 224 to 96 to simplify the computation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef87c44e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ef87c44e",
        "outputId": "e140c960-fdab-48c4-c1b1-f1c172c6d973"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-10-03T15:54:36.151664</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 238.965625 183.35625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"mb8448ab885\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mb8448ab885\" x=\"30.103125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.921875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#mb8448ab885\" x=\"69.163125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(65.981875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#mb8448ab885\" x=\"108.223125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(105.041875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#mb8448ab885\" x=\"147.283125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(144.101875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#mb8448ab885\" x=\"186.343125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(183.161875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#mb8448ab885\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"mb372bbd91f\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mb372bbd91f\" x=\"30.103125\" y=\"131.617191\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.2 -->\n      <g transform=\"translate(7.2 135.41641) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#mb372bbd91f\" x=\"30.103125\" y=\"100.248361\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 104.04758) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#mb372bbd91f\" x=\"30.103125\" y=\"68.879531\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 72.67875) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#mb372bbd91f\" x=\"30.103125\" y=\"37.510701\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 41.309919) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_11\">\n    <path d=\"M 34.954394 13.5 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 49.633125 80.408031 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_15\"/>\n   <g id=\"line2d_16\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 49.633125 80.408031 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 49.633125 36.217109 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 49.633125 80.408031 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 49.633125 36.217109 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 49.633125 80.408031 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 49.633125 36.217109 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path d=\"M 49.633125 36.217109 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_34\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_35\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_40\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_44\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_45\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_46\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_47\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_48\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_50\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_53\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_54\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_56\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_57\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_58\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_59\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_60\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_61\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_62\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_63\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_64\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_65\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_66\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_67\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_68\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_69\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_70\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_71\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_72\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_73\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_74\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_75\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_76\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_77\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_78\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \nL 147.283125 26.584967 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_79\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \nL 151.884543 133.765796 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_80\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_81\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \nL 147.283125 26.584967 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_82\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \nL 151.884543 133.765796 \nL 161.628722 132.71378 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_83\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_84\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \nL 147.283125 26.584967 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_85\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \nL 151.884543 133.765796 \nL 161.628722 132.71378 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_86\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \nL 166.813125 123.596609 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_87\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \nL 147.283125 26.584967 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_88\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \nL 151.884543 133.765796 \nL 161.628722 132.71378 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_89\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \nL 166.813125 123.596609 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_90\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \nL 147.283125 26.584967 \nL 166.813125 20.19456 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_91\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \nL 151.884543 133.765796 \nL 161.628722 132.71378 \nL 171.372901 135.739632 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_92\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \nL 166.813125 123.596609 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_93\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \nL 147.283125 26.584967 \nL 166.813125 20.19456 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_94\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \nL 151.884543 133.765796 \nL 161.628722 132.71378 \nL 171.372901 135.739632 \nL 181.11708 134.645607 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_95\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \nL 166.813125 123.596609 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_96\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \nL 147.283125 26.584967 \nL 166.813125 20.19456 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_97\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \nL 151.884543 133.765796 \nL 161.628722 132.71378 \nL 171.372901 135.739632 \nL 181.11708 134.645607 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_98\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \nL 166.813125 123.596609 \nL 186.343125 118.790199 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_99\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \nL 147.283125 26.584967 \nL 166.813125 20.19456 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_100\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \nL 151.884543 133.765796 \nL 161.628722 132.71378 \nL 171.372901 135.739632 \nL 181.11708 134.645607 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_101\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \nL 166.813125 123.596609 \nL 186.343125 118.790199 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_102\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \nL 147.283125 26.584967 \nL 166.813125 20.19456 \nL 186.343125 21.885226 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_103\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \nL 151.884543 133.765796 \nL 161.628722 132.71378 \nL 171.372901 135.739632 \nL 181.11708 134.645607 \nL 190.861259 137.308991 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_104\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \nL 166.813125 123.596609 \nL 186.343125 118.790199 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_105\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \nL 147.283125 26.584967 \nL 166.813125 20.19456 \nL 186.343125 21.885226 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_106\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \nL 151.884543 133.765796 \nL 161.628722 132.71378 \nL 171.372901 135.739632 \nL 181.11708 134.645607 \nL 190.861259 137.308991 \nL 200.605438 136.761395 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_107\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \nL 166.813125 123.596609 \nL 186.343125 118.790199 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_108\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \nL 147.283125 26.584967 \nL 166.813125 20.19456 \nL 186.343125 21.885226 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_109\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \nL 151.884543 133.765796 \nL 161.628722 132.71378 \nL 171.372901 135.739632 \nL 181.11708 134.645607 \nL 190.861259 137.308991 \nL 200.605438 136.761395 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_110\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \nL 166.813125 123.596609 \nL 186.343125 118.790199 \nL 205.873125 118.979747 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_111\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \nL 147.283125 26.584967 \nL 166.813125 20.19456 \nL 186.343125 21.885226 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_112\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \nL 151.884543 133.765796 \nL 161.628722 132.71378 \nL 171.372901 135.739632 \nL 181.11708 134.645607 \nL 190.861259 137.308991 \nL 200.605438 136.761395 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_113\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \nL 166.813125 123.596609 \nL 186.343125 118.790199 \nL 205.873125 118.979747 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_114\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \nL 147.283125 26.584967 \nL 166.813125 20.19456 \nL 186.343125 21.885226 \nL 205.873125 21.96278 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_115\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \nL 151.884543 133.765796 \nL 161.628722 132.71378 \nL 171.372901 135.739632 \nL 181.11708 134.645607 \nL 190.861259 137.308991 \nL 200.605438 136.761395 \nL 210.349618 139.5 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_116\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \nL 166.813125 123.596609 \nL 186.343125 118.790199 \nL 205.873125 118.979747 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_117\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \nL 147.283125 26.584967 \nL 166.813125 20.19456 \nL 186.343125 21.885226 \nL 205.873125 21.96278 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_118\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \nL 151.884543 133.765796 \nL 161.628722 132.71378 \nL 171.372901 135.739632 \nL 181.11708 134.645607 \nL 190.861259 137.308991 \nL 200.605438 136.761395 \nL 210.349618 139.5 \nL 220.093797 138.378554 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_119\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \nL 166.813125 123.596609 \nL 186.343125 118.790199 \nL 205.873125 118.979747 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_120\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \nL 147.283125 26.584967 \nL 166.813125 20.19456 \nL 186.343125 21.885226 \nL 205.873125 21.96278 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_121\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \nL 151.884543 133.765796 \nL 161.628722 132.71378 \nL 171.372901 135.739632 \nL 181.11708 134.645607 \nL 190.861259 137.308991 \nL 200.605438 136.761395 \nL 210.349618 139.5 \nL 220.093797 138.378554 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_122\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \nL 166.813125 123.596609 \nL 186.343125 118.790199 \nL 205.873125 118.979747 \nL 225.403125 115.481883 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_123\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \nL 147.283125 26.584967 \nL 166.813125 20.19456 \nL 186.343125 21.885226 \nL 205.873125 21.96278 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_124\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 89.921015 \nL 54.442752 105.979335 \nL 64.186931 112.30036 \nL 73.93111 118.449871 \nL 83.675289 119.695343 \nL 93.419468 124.236508 \nL 103.163647 124.46348 \nL 112.907826 127.705308 \nL 122.652006 128.163985 \nL 132.396185 130.77214 \nL 142.140364 130.649015 \nL 151.884543 133.765796 \nL 161.628722 132.71378 \nL 171.372901 135.739632 \nL 181.11708 134.645607 \nL 190.861259 137.308991 \nL 200.605438 136.761395 \nL 210.349618 139.5 \nL 220.093797 138.378554 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_125\">\n    <path d=\"M 49.633125 80.408031 \nL 69.163125 107.873648 \nL 88.693125 94.268337 \nL 108.223125 83.399454 \nL 127.753125 103.715434 \nL 147.283125 105.054537 \nL 166.813125 123.596609 \nL 186.343125 118.790199 \nL 205.873125 118.979747 \nL 225.403125 115.481883 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_126\">\n    <path d=\"M 49.633125 36.217109 \nL 69.163125 25.840453 \nL 88.693125 31.517368 \nL 108.223125 34.805635 \nL 127.753125 28.2291 \nL 147.283125 26.584967 \nL 166.813125 20.19456 \nL 186.343125 21.885226 \nL 205.873125 21.96278 \nL 225.403125 22.567697 \n\" clip-path=\"url(#pef6eace757)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 145.8 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 138.8125 100.434375 \nL 218.403125 100.434375 \nQ 220.403125 100.434375 220.403125 98.434375 \nL 220.403125 54.565625 \nQ 220.403125 52.565625 218.403125 52.565625 \nL 138.8125 52.565625 \nQ 136.8125 52.565625 136.8125 54.565625 \nL 136.8125 98.434375 \nQ 136.8125 100.434375 138.8125 100.434375 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_127\">\n     <path d=\"M 140.8125 60.664063 \nL 150.8125 60.664063 \nL 160.8125 60.664063 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- train_loss -->\n     <g transform=\"translate(168.8125 64.164063) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_128\">\n     <path d=\"M 140.8125 75.620313 \nL 150.8125 75.620313 \nL 160.8125 75.620313 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- val_loss -->\n     <g transform=\"translate(168.8125 79.120313) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n    <g id=\"line2d_129\">\n     <path d=\"M 140.8125 90.576563 \nL 150.8125 90.576563 \nL 160.8125 90.576563 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_14\">\n     <!-- val_acc -->\n     <g transform=\"translate(168.8125 94.076563) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pef6eace757\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = DenseNet(lr=0.01)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(96, 96))\n",
        "trainer.fit(model, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bacabdce",
      "metadata": {
        "id": "bacabdce"
      },
      "source": [
        "## Summary and Discussion\n",
        "\n",
        "The main components that comprise DenseNet are dense blocks and transition layers. For the latter, we need to keep the dimensionality under control when composing the network by adding transition layers that shrink the number of channels again.\n",
        "In terms of cross-layer connections, in contrast to ResNet, where inputs and outputs are added together, DenseNet concatenates inputs and outputs on the channel dimension.\n",
        "Although these concatenation operations\n",
        "reuse features to achieve computational efficiency,\n",
        "unfortunately they lead to heavy GPU memory consumption.\n",
        "As a result,\n",
        "applying DenseNet may require more memory-efficient implementations that may increase training time :cite:`pleiss2017memory`.\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Why do we use average pooling rather than max-pooling in the transition layer?\n",
        "1. One of the advantages mentioned in the DenseNet paper is that its model parameters are smaller than those of ResNet. Why is this the case?\n",
        "1. One problem for which DenseNet has been criticized is its high memory consumption.\n",
        "    1. Is this really the case? Try to change the input shape to $224\\times 224$ to compare the actual GPU memory consumption empirically.\n",
        "    1. Can you think of an alternative means of reducing the memory consumption? How would you need to change the framework?\n",
        "1. Implement the various DenseNet versions presented in Table 1 of the DenseNet paper :cite:`Huang.Liu.Van-Der-Maaten.ea.2017`.\n",
        "1. Design an MLP-based model by applying the DenseNet idea. Apply it to the housing price prediction task in :numref:`sec_kaggle_house`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1kzkEBS_EqYW",
      "metadata": {
        "id": "1kzkEBS_EqYW"
      },
      "source": [
        "###Answer No. 1\n",
        "Why do we use average pooling rather than max-pooling in the transition layer?\n",
        "\n",
        "Dalam arsitektur DenseNet, lapisan transisi mengurangi dimensi spasial dan jumlah peta fitur sebelum melanjutkan ke blok padat berikutnya. Rata-rata pooling lebih dipilih daripada max-pooling karena mempertahankan lebih banyak informasi dengan menghitung nilai rata-rata, sedangkan max-pooling hanya memilih nilai maksimum. Rata-rata pooling juga membantu mengurangi risiko overfitting dengan memperhalus peta fitur, lebih stabil terhadap pencilan, dan memberikan invariansi translasi. Meskipun max-pooling efektif dalam arsitektur seperti jaringan saraf konvolusional, rata-rata pooling lebih sesuai untuk DenseNet yang fokus pada aliran informasi yang kaya dan mengurangi kehilangan informasi. Pilihan antara kedua metode ini bergantung pada tujuan spesifik jaringan dan karakteristik data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_KgN5O-0FJNX",
      "metadata": {
        "id": "_KgN5O-0FJNX"
      },
      "source": [
        " No. 2\n",
        "One of the advantages mentioned in the DenseNet paper is that its model parameters are smaller than those of ResNet. Why is this the case?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ysQKqvBdFVD7",
      "metadata": {
        "id": "ysQKqvBdFVD7"
      },
      "outputs": [],
      "source": [
        "def conv_block(num_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "        nn.LazyConv2d(num_channels, kernel_size=3, padding=1))\n",
        "\n",
        "def transition_block(num_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "        nn.LazyConv2d(num_channels, kernel_size=1),\n",
        "        nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, num_convs, num_channels):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        layer = []\n",
        "        for i in range(num_convs):\n",
        "            layer.append(conv_block(num_channels))\n",
        "        self.net = nn.Sequential(*layer)\n",
        "\n",
        "    def forward(self, X):\n",
        "        for blk in self.net:\n",
        "            Y = blk(X)\n",
        "            # Concatenate input and output of each block along the channels\n",
        "            X = torch.cat((X, Y), dim=1)\n",
        "        return X\n",
        "\n",
        "class DenseNet(d2l.Classifier):\n",
        "    def b1(self):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "    def __init__(self, num_channels=64, growth_rate=32, arch=(4, 4, 4, 4),\n",
        "                 lr=0.1, num_classes=10):\n",
        "        super(DenseNet, self).__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(self.b1())\n",
        "        for i, num_convs in enumerate(arch):\n",
        "            self.net.add_module(f'dense_blk{i+1}', DenseBlock(num_convs,\n",
        "                                                              growth_rate))\n",
        "            # The number of output channels in the previous dense block\n",
        "            num_channels += num_convs * growth_rate\n",
        "            # A transition layer that halves the number of channels is added\n",
        "            # between the dense blocks\n",
        "            if i != len(arch) - 1:\n",
        "                num_channels //= 2\n",
        "                self.net.add_module(f'tran_blk{i+1}', transition_block(\n",
        "                    num_channels))\n",
        "        self.net.add_module('last', nn.Sequential(\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "            nn.LazyLinear(num_classes)))\n",
        "        self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qdXXcbj-GCCB",
      "metadata": {
        "id": "qdXXcbj-GCCB"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "data = d2l.FashionMNIST(batch_size=32, resize=(224, 224))\n",
        "arch18 = [(2,[(64,3,1)]*2,None),(2,[(128,3,1)]*2,128),(2,[(256,3,1)]*2,256),(2,[(512,3,1)]*2,512)]\n",
        "resnet18 = d2l.ResNet(arch=arch18, lr=0.01)\n",
        "resnet18.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "print(count_parameters(resnet18))\n",
        "summary(resnet18, (1, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SEQ_kG1bFgdU",
      "metadata": {
        "id": "SEQ_kG1bFgdU"
      },
      "outputs": [],
      "source": [
        "model = DenseNet(lr=0.01)\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "print(count_parameters(model))\n",
        "summary(model, (1, 224, 224))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59RM13eaGj5h",
      "metadata": {
        "id": "59RM13eaGj5h"
      },
      "source": [
        "DenseNet memiliki jumlah parameter model yang lebih sedikit dibandingkan ResNet karena penerapan koneksi padat antar lapisan. Dalam DenseNet, setiap lapisan menerima peta fitur dari semua lapisan sebelumnya dan juga mengirimkan peta fiturnya sendiri ke semua lapisan setelahnya. Dengan cara ini, jumlah saluran (filter) di setiap lapisan dapat diminimalkan karena lapisan dapat menggunakan kembali fitur yang sudah ada. Di sisi lain, ResNet mengandalkan koneksi residual, di mana setiap lapisan hanya menerima output dari lapisan sebelumnya dan menambahkannya ke output-nya sendiri. Hal ini mengharuskan setiap lapisan memiliki lebih banyak saluran untuk mempelajari fitur baru, karena tidak bisa mengakses fitur dari lapisan yang lebih awal. Berdasarkan penelitian mengenai DenseNet, model dengan 121 lapisan hanya memiliki 7,98 juta parameter, sementara ResNet dengan 152 lapisan memiliki 60,19 juta parameter, menunjukkan perbedaan yang signifikan dalam ukuran dan kompleksitas model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z55tRE4YGmCj",
      "metadata": {
        "id": "Z55tRE4YGmCj"
      },
      "source": [
        "No. 3\n",
        "\n",
        "One problem for which DenseNet has been criticized is its high memory consumption.\n",
        "\n",
        "3.1 Is this really the case? Try to change the input shape to 224×224 to compare the actual GPU memory consumption empirically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JOyTtfmVG0DT",
      "metadata": {
        "id": "JOyTtfmVG0DT"
      },
      "outputs": [],
      "source": [
        "data = d2l.FashionMNIST(batch_size=32, resize=(28, 28))\n",
        "model = DenseNet(lr=0.01)\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "torch.cuda.empty_cache()\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "trainer.fit(model, data)\n",
        "memory_stats = torch.cuda.memory_stats(device=device)\n",
        "# Print peak memory usage and other memory statistics\n",
        "print(\"Peak memory usage:\", memory_stats[\"allocated_bytes.all.peak\"] / (1024 ** 2), \"MB\")\n",
        "print(\"Current memory usage:\", memory_stats[\"allocated_bytes.all.current\"] / (1024 ** 2), \"MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wp1guDNyG4Vl",
      "metadata": {
        "id": "Wp1guDNyG4Vl"
      },
      "outputs": [],
      "source": [
        "data = d2l.FashionMNIST(batch_size=32, resize=(224, 224))\n",
        "model = DenseNet(lr=0.01)\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "torch.cuda.empty_cache()\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "trainer.fit(model, data)\n",
        "memory_stats = torch.cuda.memory_stats(device=device)\n",
        "# Print peak memory usage and other memory statistics\n",
        "print(\"Peak memory usage:\", memory_stats[\"allocated_bytes.all.peak\"] / (1024 ** 2), \"MB\")\n",
        "print(\"Current memory usage:\", memory_stats[\"allocated_bytes.all.current\"] / (1024 ** 2), \"MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xWFWryzXG7c_",
      "metadata": {
        "id": "xWFWryzXG7c_"
      },
      "source": [
        "3.2 Can you think of an alternative means of reducing the memory consumption? How would you need to change the framework?\n",
        "\n",
        "Mengurangi konsumsi memori dalam arsitektur DenseNet dapat dilakukan dengan beberapa strategi. Salah satunya adalah memperkenalkan koneksi jarang di dalam blok padat, di mana tidak semua lapisan terhubung satu sama lain. Ini dapat dicapai dengan memilih subset peta fitur dari lapisan sebelumnya untuk digabungkan dengan lapisan saat ini, sehingga mengurangi koneksi dan konsumsi memori.\n",
        "\n",
        "Teknik pemangkasan saluran juga dapat diterapkan untuk menghapus saluran yang kurang penting. Selain itu, regularisasi L1 dapat digunakan untuk mendorong bobot menjadi nol, sementara kompresi model seperti distilasi pengetahuan atau kuantisasi dapat mengurangi jejak memori.\n",
        "\n",
        "Faktorisasi matriks peringkat rendah pada bobot dalam blok padat dan pengalokasian memori secara dinamis selama inferensi dapat membantu mengurangi penggunaan memori. Penggunaan fungsi aktivasi yang mendorong kepadatan, seperti ReLU6, serta desain blok padat adaptif yang menyesuaikan pola koneksi berdasarkan distribusi data, juga merupakan solusi potensial.\n",
        "\n",
        "Implementasi strategi ini memerlukan perubahan pada arsitektur dan pelatihan, serta eksperimen untuk menemukan keseimbangan antara pengurangan memori dan kinerja model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "prXBruf0HmY1",
      "metadata": {
        "id": "prXBruf0HmY1"
      },
      "source": [
        "No. 4\n",
        "\n",
        "Implement the various DenseNet versions presented in Table 1 of the DenseNet paper (Huang et al., 2017)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ueDJY_qZG9bQ",
      "metadata": {
        "id": "ueDJY_qZG9bQ"
      },
      "outputs": [],
      "source": [
        "def conv_block(num_channels, kernel_size, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "        nn.LazyConv2d(num_channels, kernel_size=kernel_size, padding=padding))\n",
        "\n",
        "def transition_block(num_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "        nn.LazyConv2d(num_channels, kernel_size=1),\n",
        "        nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, convs, num_channels):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        layer = []\n",
        "        for kernel_size, padding in convs:\n",
        "            layer.append(conv_block(num_channels, kernel_size, padding))\n",
        "        self.net = nn.Sequential(*layer)\n",
        "\n",
        "    def forward(self, X):\n",
        "        for blk in self.net:\n",
        "            Y = blk(X)\n",
        "            # Concatenate input and output of each block along the channels\n",
        "            X = torch.cat((X, Y), dim=1)\n",
        "        return X\n",
        "\n",
        "class DenseNet(d2l.Classifier):\n",
        "    def b1(self):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "    def __init__(self, num_channels=64, growth_rate=32, arch=[[[3,1],[3,1]],[[3,1],[3,1]]],lr=0.1, num_classes=10):\n",
        "        super(DenseNet, self).__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(self.b1())\n",
        "        for i, convs in enumerate(arch):\n",
        "            self.net.add_module(f'dense_blk{i+1}', DenseBlock(convs, growth_rate))\n",
        "            # The number of output channels in the previous dense block\n",
        "            num_channels += len(convs) * growth_rate\n",
        "            # A transition layer that halves the number of channels is added\n",
        "            # between the dense blocks\n",
        "            if i != len(arch) - 1:\n",
        "                num_channels //= 2\n",
        "                self.net.add_module(f'tran_blk{i+1}', transition_block(\n",
        "                    num_channels))\n",
        "        self.net.add_module('last', nn.Sequential(\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "            nn.LazyLinear(num_classes)))\n",
        "        self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M4jTZmhAH8WC",
      "metadata": {
        "id": "M4jTZmhAH8WC"
      },
      "outputs": [],
      "source": [
        "data = d2l.FashionMNIST(batch_size=32, resize=(224, 224))\n",
        "arch121 = ([[[1,0],[3,1]]*6,[[1,0],[3,1]]*12,[[1,0],[3,1]]*24,[[1,0],[3,1]]*16])\n",
        "densenet121 = DenseNet(lr=0.01, arch=arch121)\n",
        "densenet121.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "# print(count_parameters(model))\n",
        "summary(densenet121, (1, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "okfyIWV3Hvcv",
      "metadata": {
        "id": "okfyIWV3Hvcv"
      },
      "outputs": [],
      "source": [
        "arch169 = ([[[1,0],[3,1]]*6,[[1,0],[3,1]]*12,[[1,0],[3,1]]*32,[[1,0],[3,1]]*32])\n",
        "densenet169 = DenseNet(lr=0.01, arch=arch169)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VJT1FJG4H1BB",
      "metadata": {
        "id": "VJT1FJG4H1BB"
      },
      "outputs": [],
      "source": [
        "arch201 = ([[[1,0],[3,1]]*6,[[1,0],[3,1]]*12,[[1,0],[3,1]]*48,[[1,0],[3,1]]*32])\n",
        "densenet201 = DenseNet(lr=0.01, arch=arch201)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_IFHK-AiH4SG",
      "metadata": {
        "id": "_IFHK-AiH4SG"
      },
      "outputs": [],
      "source": [
        "arch264 = ([[[1,0],[3,1]]*6,[[1,0],[3,1]]*12,[[1,0],[3,1]]*64,[[1,0],[3,1]]*48])\n",
        "densenet264 = DenseNet(lr=0.01, arch=arch264)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LHjYVGwsISys",
      "metadata": {
        "id": "LHjYVGwsISys"
      },
      "source": [
        "No. 5\n",
        "\n",
        "Design an MLP-based model by applying the DenseNet idea. Apply it to the housing price prediction task in Section 5.7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Oe00-gSEIWkc",
      "metadata": {
        "id": "Oe00-gSEIWkc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import cProfile\n",
        "import d2l\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jJYQIVXrIdZZ",
      "metadata": {
        "id": "jJYQIVXrIdZZ"
      },
      "outputs": [],
      "source": [
        "class KaggleHouse(d2l.DataModule):\n",
        "    def __init__(self, batch_size, train=None, val=None):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        if self.train is None:\n",
        "            self.raw_train = pd.read_csv(d2l.download(d2l.DATA_URL+ 'kaggle_house_pred_train.csv', self.root,\n",
        "                sha1_hash='585e9cc93e70b39160e7921475f9bcd7d31219ce'))\n",
        "            self.raw_val = pd.read_csv(d2l.download(\n",
        "                d2l.DATA_URL + 'kaggle_house_pred_test.csv', self.root,\n",
        "                sha1_hash='fa19780a7b011d9b009e8bff8e99922a8ee2eb90'))\n",
        "\n",
        "    def preprocess(self, std_flag=True):\n",
        "        label = 'SalePrice'\n",
        "        features = pd.concat((self.raw_train.drop(columns=['Id',label]),\n",
        "                              self.raw_val.drop(columns=['Id'])))\n",
        "        numeric_features = features.dtypes[features.dtypes!='object'].index\n",
        "        if std_flag:\n",
        "            features[numeric_features] = features[numeric_features].apply(lambda x: (x-x.mean())/x.std())\n",
        "        features[numeric_features] = features[numeric_features].fillna(0)\n",
        "        features = pd.get_dummies(features, dummy_na=True)\n",
        "        self.train = features[:self.raw_train.shape[0]].copy()\n",
        "        self.train[label] = self.raw_train[label]\n",
        "        self.val = features[self.raw_train.shape[0]:].copy()\n",
        "\n",
        "    def get_dataloader(self, train):\n",
        "        label = 'SalePrice'\n",
        "        data = self.train if train else self.val\n",
        "        if label not in data:\n",
        "            return\n",
        "        get_tensor = lambda x: torch.tensor(x.values.astype(float), dtype=torch.float32)\n",
        "        # tensors = (get_tensor(data.drop(columns=[label])),\n",
        "        #            torch.log(get_tensor(data[label])).reshape(-1,1))\n",
        "        tensors = (get_tensor(data.drop(columns=[label])),  # X\n",
        "               torch.log(get_tensor(data[label])).reshape((-1, 1)))  # Y\n",
        "        return self.get_tensorloader(tensors, train)\n",
        "\n",
        "def k_fold_data(data,k):\n",
        "    rets = []\n",
        "    fold_size = data.train.shape[0] // k\n",
        "    for j in range(k):\n",
        "        idx = range(j*fold_size,(j+1)*fold_size)\n",
        "        rets.append(KaggleHouse(data.batch_size,data.train.drop(index=idx),data.train.iloc[idx]))\n",
        "    return rets\n",
        "\n",
        "def k_fold(trainer, data, k, ModelClass,hparams,plot_flag=True):\n",
        "    val_loss, models = [], []\n",
        "    for i, data_fold in enumerate(k_fold_data(data,k)):\n",
        "        model = ModelClass(**hparams)\n",
        "        model.board.yscale='log'\n",
        "        if not plot_flag or i != 0:\n",
        "            model.board.display=False\n",
        "        trainer.fit(model,data_fold)\n",
        "        val_loss.append(float(model.board.data['val_loss'][-1].y))\n",
        "        models.append(model)\n",
        "    avg_val_loss = sum(val_loss)/len(val_loss)\n",
        "    print(f'average validation log mse = {avg_val_loss}, params:{hparams}')\n",
        "    return models, avg_val_loss\n",
        "\n",
        "\n",
        "\n",
        "class HouseResMLP(d2l.LinearRegression):\n",
        "    def __init__(self, num_outputs, num_hiddens, lr, dropouts, weight_decay):\n",
        "        super().__init__(lr)\n",
        "        self.save_hyperparameters()\n",
        "        layers = [nn.Flatten()]\n",
        "        for i in range(len(num_hiddens)):\n",
        "            layers.append(nn.Sequential(nn.LazyLinear(num_hiddens[i]),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Dropout(dropouts[i]),\n",
        "                                        nn.LazyBatchNorm1d(),\n",
        "                                        ))\n",
        "        layers.append(nn.LazyLinear(num_outputs))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.net[0](X)\n",
        "        for blk in self.net[1:-1]:\n",
        "            Y = blk(X)\n",
        "            # Concatenate input and output of each block along the channels\n",
        "            X = torch.cat((X, Y), dim=1)\n",
        "        return self.net[-1](X)\n",
        "\n",
        "class HouseDenseBlock(nn.Module):\n",
        "    def __init__(self, num_hiddens):\n",
        "        super().__init__()\n",
        "        layer = []\n",
        "        for i in range(len(num_hiddens)):\n",
        "            layer.append(nn.Sequential(nn.LazyLinear(num_hiddens[i]),\n",
        "                                        nn.LazyBatchNorm1d(), nn.ReLU(),\n",
        "                                        ))\n",
        "        self.net = nn.Sequential(*layer)\n",
        "\n",
        "    def forward(self, X):\n",
        "        for blk in self.net:\n",
        "            Y = blk(X)\n",
        "            # Concatenate input and output of each block along the channels\n",
        "            X = torch.cat((X, Y), dim=1)\n",
        "        return X\n",
        "\n",
        "def transition_block():\n",
        "    return nn.Sequential(\n",
        "        nn.LazyBatchNorm1d(), nn.ReLU(),\n",
        "        nn.AvgPool1d(kernel_size=2, stride=2))\n",
        "\n",
        "class HouseResMLP(d2l.LinearRegression):\n",
        "    def __init__(self, num_outputs, arch, lr, dropouts, weight_decay):\n",
        "        super().__init__(lr)\n",
        "        self.save_hyperparameters()\n",
        "        layers = [nn.Flatten()]\n",
        "        for num_hiddens in arch:\n",
        "            layers.append(HouseDenseBlock(num_hiddens))\n",
        "            # layers.append(nn.LazyLinear(sum(num_hiddens)//4))\n",
        "        layers.append(nn.LazyLinear(num_outputs))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.net(X)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.SGD(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u1EENvzPI4Ce",
      "metadata": {
        "id": "u1EENvzPI4Ce"
      },
      "outputs": [],
      "source": [
        "hparams = {'dropouts': [0]*5,\n",
        " 'lr': 0.01,\n",
        " 'num_hiddens': [64,32,16,8],\n",
        " 'num_outputs': 1,\n",
        " 'weight_decay': 0}\n",
        "model = HouseResMLP(**hparams)\n",
        "summary(model,(1,80))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Spw_j0cTI5la",
      "metadata": {
        "id": "Spw_j0cTI5la"
      },
      "outputs": [],
      "source": [
        "data = KaggleHouse(batch_size=64)\n",
        "print(data.raw_train.shape, data.raw_val.shape)\n",
        "data.preprocess()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EnVj-vh9I7Ya",
      "metadata": {
        "id": "EnVj-vh9I7Ya"
      },
      "outputs": [],
      "source": [
        "hparams = {'dropouts': [0]*5,\n",
        " 'lr': 0.01,\n",
        " 'num_hiddens': [64,32,16,8],\n",
        " 'num_outputs': 1,\n",
        " 'weight_decay': 0}\n",
        "trainer = d2l.Trainer(max_epochs=10)\n",
        "models,avg_val_loss = k_fold(trainer, data, k=5,ModelClass=HouseResMLP,hparams=hparams,plot_flag=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VBJfk9eDJBnU",
      "metadata": {
        "id": "VBJfk9eDJBnU"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XtiiSVuAYKZD",
      "metadata": {
        "id": "XtiiSVuAYKZD"
      },
      "source": [
        "#8.8 Designing Convolution Network Architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ea1dde2",
      "metadata": {
        "id": "7ea1dde2"
      },
      "source": [
        "# Designing Convolution Network Architectures\n",
        ":label:`sec_cnn-design`\n",
        "\n",
        "The previous sections have taken us on a tour of modern network design for computer vision. Common to all the work we covered was that it greatly relied on the intuition of scientists. Many of the architectures are heavily informed by human creativity and to a much lesser extent by systematic exploration of the design space that deep networks offer. Nonetheless, this *network engineering* approach has been tremendously successful.\n",
        "\n",
        "Ever since AlexNet (:numref:`sec_alexnet`)\n",
        "beat conventional computer vision models on ImageNet,\n",
        "it has become popular to construct very deep networks\n",
        "by stacking blocks of convolutions, all designed according to the same pattern.\n",
        "In particular, $3 \\times 3$ convolutions were\n",
        "popularized by VGG networks (:numref:`sec_vgg`).\n",
        "NiN (:numref:`sec_nin`) showed that even $1 \\times 1$ convolutions could\n",
        "be beneficial by adding local nonlinearities.\n",
        "Moreover, NiN solved the problem of aggregating information at the head of a network\n",
        "by aggregating across all locations.\n",
        "GoogLeNet (:numref:`sec_googlenet`) added multiple branches of different convolution width,\n",
        "combining the advantages of VGG and NiN in its Inception block.\n",
        "ResNets (:numref:`sec_resnet`)\n",
        "changed the inductive bias towards the identity mapping (from $f(x) = 0$). This allowed for very deep networks. Almost a decade later, the ResNet design is still popular, a testament to its design. Lastly, ResNeXt (:numref:`subsec_resnext`) added grouped convolutions, offering a better trade-off between parameters and computation. A precursor to Transformers for vision, the Squeeze-and-Excitation Networks (SENets) allow for efficient information transfer between locations\n",
        ":cite:`Hu.Shen.Sun.2018`. This was accomplished by computing a per-channel global attention function.\n",
        "\n",
        "Up to now we have omitted networks obtained via *neural architecture search* (NAS) :cite:`zoph2016neural,liu2018darts`. We chose to do so since their cost is usually enormous, relying on brute-force search, genetic algorithms, reinforcement learning, or some other form of hyperparameter optimization. Given a fixed search space,\n",
        "NAS uses a search strategy to automatically select\n",
        "an architecture based on the returned performance estimation.\n",
        "The outcome of NAS\n",
        "is a single network instance. EfficientNets are a notable outcome of this search :cite:`tan2019efficientnet`.\n",
        "\n",
        "In the following we discuss an idea that is quite different to the quest for the *single best network*. It is computationally relatively inexpensive, it leads to scientific insights on the way, and it is quite effective in terms of the quality of outcomes. Let's review the strategy by :citet:`Radosavovic.Kosaraju.Girshick.ea.2020` to *design network design spaces*. The strategy combines the strength of manual design and NAS. It accomplishes this by operating on *distributions of networks* and optimizing the distributions in a way to obtain good performance for entire families of networks. The outcome of it are *RegNets*, specifically RegNetX and RegNetY, plus a range of guiding principles for the design of performant CNNs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2d025e9",
      "metadata": {
        "id": "d2d025e9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6e554d6",
      "metadata": {
        "id": "a6e554d6"
      },
      "source": [
        "## The AnyNet Design Space\n",
        ":label:`subsec_the-anynet-design-space`\n",
        "\n",
        "The description below closely follows the reasoning in :citet:`Radosavovic.Kosaraju.Girshick.ea.2020` with some abbreviations to make it fit in the scope of the book.\n",
        "To begin, we need a template for the family of networks to explore. One of the commonalities of the designs in this chapter is that the networks consist of a *stem*, a *body* and a *head*. The stem performs initial image processing, often through convolutions with a larger window size. The body consists of multiple blocks, carrying out the bulk of the transformations needed to go from raw images to object representations. Lastly, the head converts this into the desired outputs, such as via a softmax regressor for multiclass classification.\n",
        "The body, in turn, consists of multiple stages, operating on the image at decreasing resolutions. In fact, both the stem and each subsequent stage quarter the spatial resolution. Lastly, each stage consists of one or more blocks. This pattern is common to all networks, from VGG to ResNeXt. Indeed, for the design of generic AnyNet networks, :citet:`Radosavovic.Kosaraju.Girshick.ea.2020` used the ResNeXt block of :numref:`fig_resnext_block`.\n",
        "\n",
        "\n",
        "![The AnyNet design space. The numbers $(\\mathit{c}, \\mathit{r})$ along each arrow indicate the number of channels $c$ and the resolution $\\mathit{r} \\times \\mathit{r}$ of the images at that point. From left to right: generic network structure composed of stem, body, and head; body composed of four stages; detailed structure of a stage; two alternative structures for blocks, one without downsampling and one that halves the resolution in each dimension. Design choices include depth $\\mathit{d_i}$, the number of output channels $\\mathit{c_i}$, the number of groups $\\mathit{g_i}$, and bottleneck ratio $\\mathit{k_i}$ for any stage $\\mathit{i}$.](http://d2l.ai/_images/anynet.svg)\n",
        ":label:`fig_anynet_full`\n",
        "\n",
        "Let's review the structure outlined in :numref:`fig_anynet_full` in detail. As mentioned, an AnyNet consists of a stem, body, and head. The stem takes as its input RGB images (3 channels), using a $3 \\times 3$ convolution with a stride of $2$, followed by a batch norm, to halve the resolution from $r \\times r$ to $r/2 \\times r/2$. Moreover, it generates $c_0$ channels that serve as input to the body.\n",
        "\n",
        "Since the network is designed to work well with ImageNet images of shape $224 \\times 224 \\times 3$, the body serves to reduce this to $7 \\times 7 \\times c_4$ through 4 stages (recall that $224 / 2^{1+4} = 7$), each with an eventual stride of $2$. Lastly, the head employs an entirely standard design via global average pooling, similar to NiN (:numref:`sec_nin`), followed by a fully connected layer to emit an $n$-dimensional vector for $n$-class classification.\n",
        "\n",
        "Most of the relevant design decisions are inherent to the body of the network. It proceeds in stages, where each stage is composed of the same type of ResNeXt blocks as we discussed in :numref:`subsec_resnext`. The design there is again entirely generic: we begin with a block that halves the resolution by using a stride of $2$ (the rightmost in :numref:`fig_anynet_full`). To match this, the residual branch of the ResNeXt block needs to pass through a $1 \\times 1$ convolution. This block is followed by a variable number of additional ResNeXt blocks that leave both resolution and the number of channels unchanged. Note that a common design practice is to add a slight bottleneck in the design of convolutional blocks.\n",
        "As such, with bottleneck ratio $k_i \\geq 1$ we afford some number of channels, $c_i/k_i$,  within each block for stage $i$ (as the experiments show, this is not really effective and should be skipped). Lastly, since we are dealing with ResNeXt blocks, we also need to pick the number of groups $g_i$ for grouped convolutions at stage $i$.\n",
        "\n",
        "This seemingly generic design space provides us nonetheless with many parameters: we can set the block width (number of channels) $c_0, \\ldots c_4$, the depth (number of blocks) per stage $d_1, \\ldots d_4$, the bottleneck ratios $k_1, \\ldots k_4$, and the group widths (numbers of groups) $g_1, \\ldots g_4$.\n",
        "In total this adds up to 17 parameters, resulting in an unreasonably large number of configurations that would warrant exploring. We need some tools to reduce this huge design space effectively. This is where the conceptual beauty of design spaces comes in. Before we do so, let's implement the generic design first.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bcf1d35",
      "metadata": {
        "id": "0bcf1d35"
      },
      "outputs": [],
      "source": [
        "class AnyNet(d2l.Classifier):\n",
        "    def stem(self, num_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(num_channels, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e24d3006",
      "metadata": {
        "id": "e24d3006"
      },
      "source": [
        "Each stage consists of `depth` ResNeXt blocks,\n",
        "where `num_channels` specifies the block width.\n",
        "Note that the first block halves the height and width of input images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6faf93f",
      "metadata": {
        "id": "c6faf93f"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(AnyNet)\n",
        "def stage(self, depth, num_channels, groups, bot_mul):\n",
        "    blk = []\n",
        "    for i in range(depth):\n",
        "        if i == 0:\n",
        "            blk.append(d2l.ResNeXtBlock(num_channels, groups, bot_mul,\n",
        "                use_1x1conv=True, strides=2))\n",
        "        else:\n",
        "            blk.append(d2l.ResNeXtBlock(num_channels, groups, bot_mul))\n",
        "    return nn.Sequential(*blk)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb035054",
      "metadata": {
        "id": "fb035054"
      },
      "source": [
        "Putting the network stem, body, and head together,\n",
        "we complete the implementation of AnyNet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18a44834",
      "metadata": {
        "id": "18a44834"
      },
      "outputs": [],
      "source": [
        "@d2l.add_to_class(AnyNet)\n",
        "def __init__(self, arch, stem_channels, lr=0.1, num_classes=10):\n",
        "    super(AnyNet, self).__init__()\n",
        "    self.save_hyperparameters()\n",
        "    self.net = nn.Sequential(self.stem(stem_channels))\n",
        "    for i, s in enumerate(arch):\n",
        "        self.net.add_module(f'stage{i+1}', self.stage(*s))\n",
        "    self.net.add_module('head', nn.Sequential(\n",
        "        nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "        nn.LazyLinear(num_classes)))\n",
        "    self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "114b65ed",
      "metadata": {
        "id": "114b65ed"
      },
      "source": [
        "## Distributions and Parameters of Design Spaces\n",
        "\n",
        "As just discussed in :numref:`subsec_the-anynet-design-space`, parameters of a design space are hyperparameters of networks in that design space.\n",
        "Consider the problem of identifying good parameters in the AnyNet design space. We could try finding the *single best* parameter choice for a given amount of computation (e.g., FLOPs and compute time). If we allowed for even only *two* possible choices for each parameter, we would have to explore $2^{17} = 131072$ combinations to find the best solution. This is clearly infeasible because of its exorbitant cost. Even worse, we do not really learn anything from this exercise in terms of how one should design a network. Next time we add, say, an X-stage, or a shift operation, or similar, we would need to start from scratch. Even worse, due to the stochasticity in training (rounding, shuffling, bit errors), no two runs are likely to produce exactly the same results. A better strategy would be to try to determine general guidelines of how the choices of parameters should be related. For instance, the bottleneck ratio, the number of channels, blocks, groups, or their change between layers should ideally be governed by a collection of simple rules. The approach in :citet:`radosavovic2019network` relies on the following four assumptions:\n",
        "\n",
        "1. We assume that general design principles actually exist, so that many networks satisfying these requirements should offer good performance. Consequently, identifying a *distribution* over networks can be a sensible strategy. In other words, we assume that there are many good needles in the haystack.\n",
        "1. We need not train networks to convergence before we can assess whether a network is good. Instead, it is sufficient to use the intermediate results as reliable guidance for final accuracy. Using (approximate) proxies to optimize an objective is referred to as multi-fidelity optimization :cite:`forrester2007multi`. Consequently, design optimization is carried out, based on the accuracy achieved after only a few passes through the dataset, reducing the cost significantly.\n",
        "1. Results obtained at a smaller scale (for smaller networks) generalize to larger ones. Consequently, optimization is carried out for networks that are structurally similar, but with a smaller number of blocks, fewer channels, etc. Only in the end will we need to verify that the so-found networks also offer good performance at scale.\n",
        "1. Aspects of the design can be approximately factorized so that it is possible to infer their effect on the quality of the outcome somewhat independently. In other words, the optimization problem is moderately easy.\n",
        "\n",
        "These assumptions allow us to test many networks cheaply. In particular, we can *sample* uniformly from the space of configurations and evaluate their performance. Subsequently, we can evaluate the quality of the choice of parameters by reviewing the *distribution* of error/accuracy that can be achieved with said networks. Denote by $F(e)$ the cumulative distribution function (CDF) for errors committed by networks of a given design space, drawn using probability disribution $p$. That is,\n",
        "\n",
        "$$F(e, p) \\stackrel{\\textrm{def}}{=} P_{\\textrm{net} \\sim p} \\{e(\\textrm{net}) \\leq e\\}.$$\n",
        "\n",
        "Our goal is now to find a distribution $p$ over *networks* such that most networks have a very low error rate and where the support of $p$ is concise. Of course, this is computationally infeasible to perform accurately. We resort to a sample of networks $\\mathcal{Z} \\stackrel{\\textrm{def}}{=} \\{\\textrm{net}_1, \\ldots \\textrm{net}_n\\}$ (with errors $e_1, \\ldots, e_n$, respectively) from $p$ and use the empirical CDF $\\hat{F}(e, \\mathcal{Z})$ instead:\n",
        "\n",
        "$$\\hat{F}(e, \\mathcal{Z}) = \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}(e_i \\leq e).$$\n",
        "\n",
        "Whenever the CDF for one set of choices majorizes (or matches) another CDF it follows that its choice of parameters is superior (or indifferent). Accordingly\n",
        ":citet:`Radosavovic.Kosaraju.Girshick.ea.2020` experimented with a shared network bottleneck ratio $k_i = k$ for all stages $i$ of the network. This gets rid of three of the four parameters governing the bottleneck ratio. To assess whether this (negatively) affects the performance one can draw networks from the constrained and from the unconstrained distribution and compare the corresonding CDFs. It turns out that this constraint does not affect the accuracy of the distribution of networks at all, as can be seen in the first panel of :numref:`fig_regnet-fig`.\n",
        "Likewise, we could choose to pick the same group width $g_i = g$ occurring at the various stages of the network. Again, this does not affect performance, as can be seen in the second panel of :numref:`fig_regnet-fig`.\n",
        "Both steps combined reduce the number of free parameters by six.\n",
        "\n",
        "![Comparing error empirical distribution functions of design spaces. $\\textrm{AnyNet}_\\mathit{A}$ is the original design space; $\\textrm{AnyNet}_\\mathit{B}$ ties the bottleneck ratios, $\\textrm{AnyNet}_\\mathit{C}$ also ties group widths, $\\textrm{AnyNet}_\\mathit{D}$ increases the network depth across stages. From left to right: (i) tying bottleneck ratios has no effect on performance; (ii) tying group widths has no effect on performance; (iii) increasing network widths (channels) across stages improves performance; (iv) increasing network depths across stages improves performance. Figure courtesy of :citet:`Radosavovic.Kosaraju.Girshick.ea.2020`.](https://github.com/mdaffaalghiffari23/KomputasiIntelegensia/blob/img/regnet-fig.png?raw=1)\n",
        ":label:`fig_regnet-fig`\n",
        "\n",
        "Next we look for ways to reduce the multitude of potential choices for width and depth of the stages. It is a reasonable assumption that, as we go deeper, the number of channels should increase, i.e., $c_i \\geq c_{i-1}$ ($w_{i+1} \\geq w_i$ per their notation in :numref:`fig_regnet-fig`), yielding\n",
        "$\\textrm{AnyNetX}_D$. Likewise, it is equally reasonable to assume that as the stages progress, they should become deeper, i.e., $d_i \\geq d_{i-1}$, yielding $\\textrm{AnyNetX}_E$. This can be experimentally verified in the third and fourth panel of :numref:`fig_regnet-fig`, respectively.\n",
        "\n",
        "## RegNet\n",
        "\n",
        "The resulting $\\textrm{AnyNetX}_E$ design space consists of simple networks\n",
        "following easy-to-interpret design principles:\n",
        "\n",
        "* Share the bottleneck ratio $k_i = k$ for all stages $i$;\n",
        "* Share the group width $g_i = g$ for all stages $i$;\n",
        "* Increase network width across stages: $c_{i} \\leq c_{i+1}$;\n",
        "* Increase network depth across stages: $d_{i} \\leq d_{i+1}$.\n",
        "\n",
        "This leaves us with a final set of choices: how to pick the specific values for the above parameters of the eventual $\\textrm{AnyNetX}_E$ design space. By studying the best-performing networks from the distribution in $\\textrm{AnyNetX}_E$ one can observe the following: the width of the network ideally increases linearly with the block index across the network, i.e., $c_j \\approx c_0 + c_a j$, where $j$ is the block index and slope $c_a > 0$. Given that we get to choose a different block width only per stage, we arrive at a piecewise constant function, engineered to match this dependence. Furthermore, experiments also show that a bottleneck ratio of $k = 1$ performs best, i.e., we are advised not to use bottlenecks at all.\n",
        "\n",
        "We recommend the interested reader reviews further details in the design of specific networks for different amounts of computation by perusing :citet:`Radosavovic.Kosaraju.Girshick.ea.2020`. For instance, an effective 32-layer RegNetX variant is given by $k = 1$ (no bottleneck), $g = 16$ (group width is 16), $c_1 = 32$ and $c_2 = 80$ channels for the first and second stage, respectively, chosen to be $d_1=4$ and $d_2=6$ blocks deep. The astonishing insight from the design is that it still applies, even when investigating networks at a larger scale. Even better, it even holds for Squeeze-and-Excitation (SE) network designs (RegNetY) that have a global channel activation :cite:`Hu.Shen.Sun.2018`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dab5f41a",
      "metadata": {
        "id": "dab5f41a"
      },
      "outputs": [],
      "source": [
        "class RegNetX32(AnyNet):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        stem_channels, groups, bot_mul = 32, 16, 1\n",
        "        depths, channels = (4, 6), (32, 80)\n",
        "        super().__init__(\n",
        "            ((depths[0], channels[0], groups, bot_mul),\n",
        "             (depths[1], channels[1], groups, bot_mul)),\n",
        "            stem_channels, lr, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd897988",
      "metadata": {
        "id": "cd897988"
      },
      "source": [
        "We can see that each RegNetX stage progressively reduces resolution and increases output channels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75a56c8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75a56c8e",
        "outputId": "bc7d4708-51d7-4e56-d0fb-10f235d872a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential output shape:\t torch.Size([1, 32, 48, 48])\n",
            "Sequential output shape:\t torch.Size([1, 32, 24, 24])\n",
            "Sequential output shape:\t torch.Size([1, 80, 12, 12])\n",
            "Sequential output shape:\t torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "RegNetX32().layer_summary((1, 1, 96, 96))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d568cc20",
      "metadata": {
        "id": "d568cc20"
      },
      "source": [
        "## Training\n",
        "\n",
        "Training the 32-layer RegNetX on the Fashion-MNIST dataset is just like before.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91cbec9a",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "91cbec9a",
        "outputId": "14908af9-b754-4c26-e07c-0f78ef061935"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-10-04T05:02:29.289100</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 238.965625 183.35625 \nL 238.965625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m345a2039e9\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m345a2039e9\" x=\"30.103125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(26.921875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m345a2039e9\" x=\"69.163125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(65.981875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m345a2039e9\" x=\"108.223125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(105.041875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m345a2039e9\" x=\"147.283125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(144.101875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m345a2039e9\" x=\"186.343125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(183.161875 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m345a2039e9\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m0fcaca557e\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m0fcaca557e\" x=\"30.103125\" y=\"140.255838\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.2 -->\n      <g transform=\"translate(7.2 144.055057) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m0fcaca557e\" x=\"30.103125\" y=\"106.261354\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 110.060573) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m0fcaca557e\" x=\"30.103125\" y=\"72.266871\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 76.066089) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m0fcaca557e\" x=\"30.103125\" y=\"38.272387\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 42.071606) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_11\">\n    <path d=\"M 34.954394 13.5 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 49.633125 82.059308 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_15\"/>\n   <g id=\"line2d_16\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 49.633125 82.059308 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 49.633125 39.274202 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 49.633125 82.059308 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 49.633125 39.274202 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 49.633125 82.059308 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 49.633125 39.274202 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_27\">\n    <path d=\"M 49.633125 39.274202 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_34\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_35\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_40\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \nL 88.693125 27.020455 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_43\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \nL 93.419468 127.286692 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_44\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_45\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \nL 88.693125 27.020455 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_46\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \nL 93.419468 127.286692 \nL 103.163647 128.700484 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_47\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_48\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \nL 88.693125 27.020455 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_49\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \nL 93.419468 127.286692 \nL 103.163647 128.700484 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_50\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \nL 108.223125 108.785857 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \nL 88.693125 27.020455 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \nL 93.419468 127.286692 \nL 103.163647 128.700484 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_53\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \nL 108.223125 108.785857 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_54\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \nL 88.693125 27.020455 \nL 108.223125 28.852634 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_55\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \nL 93.419468 127.286692 \nL 103.163647 128.700484 \nL 112.907826 131.327462 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_56\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \nL 108.223125 108.785857 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_57\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \nL 88.693125 27.020455 \nL 108.223125 28.852634 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_58\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \nL 93.419468 127.286692 \nL 103.163647 128.700484 \nL 112.907826 131.327462 \nL 122.652006 133.062986 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_59\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \nL 108.223125 108.785857 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_60\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \nL 88.693125 27.020455 \nL 108.223125 28.852634 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_61\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \nL 93.419468 127.286692 \nL 103.163647 128.700484 \nL 112.907826 131.327462 \nL 122.652006 133.062986 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_62\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \nL 108.223125 108.785857 \nL 127.753125 117.926567 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_63\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \nL 88.693125 27.020455 \nL 108.223125 28.852634 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_64\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \nL 93.419468 127.286692 \nL 103.163647 128.700484 \nL 112.907826 131.327462 \nL 122.652006 133.062986 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_65\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \nL 108.223125 108.785857 \nL 127.753125 117.926567 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_66\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \nL 88.693125 27.020455 \nL 108.223125 28.852634 \nL 127.753125 24.684007 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_67\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \nL 93.419468 127.286692 \nL 103.163647 128.700484 \nL 112.907826 131.327462 \nL 122.652006 133.062986 \nL 132.396185 136.369905 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_68\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \nL 108.223125 108.785857 \nL 127.753125 117.926567 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_69\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \nL 88.693125 27.020455 \nL 108.223125 28.852634 \nL 127.753125 24.684007 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_70\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \nL 93.419468 127.286692 \nL 103.163647 128.700484 \nL 112.907826 131.327462 \nL 122.652006 133.062986 \nL 132.396185 136.369905 \nL 142.140364 135.297778 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_71\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \nL 108.223125 108.785857 \nL 127.753125 117.926567 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_72\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \nL 88.693125 27.020455 \nL 108.223125 28.852634 \nL 127.753125 24.684007 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_73\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \nL 93.419468 127.286692 \nL 103.163647 128.700484 \nL 112.907826 131.327462 \nL 122.652006 133.062986 \nL 132.396185 136.369905 \nL 142.140364 135.297778 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_74\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \nL 108.223125 108.785857 \nL 127.753125 117.926567 \nL 147.283125 121.807301 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_75\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \nL 88.693125 27.020455 \nL 108.223125 28.852634 \nL 127.753125 24.684007 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_76\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \nL 93.419468 127.286692 \nL 103.163647 128.700484 \nL 112.907826 131.327462 \nL 122.652006 133.062986 \nL 132.396185 136.369905 \nL 142.140364 135.297778 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_77\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \nL 108.223125 108.785857 \nL 127.753125 117.926567 \nL 147.283125 121.807301 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_78\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \nL 88.693125 27.020455 \nL 108.223125 28.852634 \nL 127.753125 24.684007 \nL 147.283125 23.154389 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_79\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \nL 93.419468 127.286692 \nL 103.163647 128.700484 \nL 112.907826 131.327462 \nL 122.652006 133.062986 \nL 132.396185 136.369905 \nL 142.140364 135.297778 \nL 151.884543 139.5 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_80\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \nL 108.223125 108.785857 \nL 127.753125 117.926567 \nL 147.283125 121.807301 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_81\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \nL 88.693125 27.020455 \nL 108.223125 28.852634 \nL 127.753125 24.684007 \nL 147.283125 23.154389 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_82\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \nL 93.419468 127.286692 \nL 103.163647 128.700484 \nL 112.907826 131.327462 \nL 122.652006 133.062986 \nL 132.396185 136.369905 \nL 142.140364 135.297778 \nL 151.884543 139.5 \nL 161.628722 138.500025 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_83\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \nL 108.223125 108.785857 \nL 127.753125 117.926567 \nL 147.283125 121.807301 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_84\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \nL 88.693125 27.020455 \nL 108.223125 28.852634 \nL 127.753125 24.684007 \nL 147.283125 23.154389 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_85\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \nL 93.419468 127.286692 \nL 103.163647 128.700484 \nL 112.907826 131.327462 \nL 122.652006 133.062986 \nL 132.396185 136.369905 \nL 142.140364 135.297778 \nL 151.884543 139.5 \nL 161.628722 138.500025 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_86\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \nL 108.223125 108.785857 \nL 127.753125 117.926567 \nL 147.283125 121.807301 \nL 166.813125 113.616751 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_87\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \nL 88.693125 27.020455 \nL 108.223125 28.852634 \nL 127.753125 24.684007 \nL 147.283125 23.154389 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_88\">\n    <path d=\"M 34.954394 13.5 \nL 44.698573 91.747242 \nL 54.442752 109.658834 \nL 64.186931 114.185342 \nL 73.93111 121.20839 \nL 83.675289 123.886136 \nL 93.419468 127.286692 \nL 103.163647 128.700484 \nL 112.907826 131.327462 \nL 122.652006 133.062986 \nL 132.396185 136.369905 \nL 142.140364 135.297778 \nL 151.884543 139.5 \nL 161.628722 138.500025 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_89\">\n    <path d=\"M 49.633125 82.059308 \nL 69.163125 106.130139 \nL 88.693125 110.938378 \nL 108.223125 108.785857 \nL 127.753125 117.926567 \nL 147.283125 121.807301 \nL 166.813125 113.616751 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_90\">\n    <path d=\"M 49.633125 39.274202 \nL 69.163125 28.550072 \nL 88.693125 27.020455 \nL 108.223125 28.852634 \nL 127.753125 24.684007 \nL 147.283125 23.154389 \nL 166.813125 25.810208 \n\" clip-path=\"url(#pdf1450814e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 145.8 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 145.8 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 145.8 \nL 225.403125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 138.8125 100.434375 \nL 218.403125 100.434375 \nQ 220.403125 100.434375 220.403125 98.434375 \nL 220.403125 54.565625 \nQ 220.403125 52.565625 218.403125 52.565625 \nL 138.8125 52.565625 \nQ 136.8125 52.565625 136.8125 54.565625 \nL 136.8125 98.434375 \nQ 136.8125 100.434375 138.8125 100.434375 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_91\">\n     <path d=\"M 140.8125 60.664063 \nL 150.8125 60.664063 \nL 160.8125 60.664063 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- train_loss -->\n     <g transform=\"translate(168.8125 64.164063) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_92\">\n     <path d=\"M 140.8125 75.620313 \nL 150.8125 75.620313 \nL 160.8125 75.620313 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- val_loss -->\n     <g transform=\"translate(168.8125 79.120313) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n    <g id=\"line2d_93\">\n     <path d=\"M 140.8125 90.576563 \nL 150.8125 90.576563 \nL 160.8125 90.576563 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_14\">\n     <!-- val_acc -->\n     <g transform=\"translate(168.8125 94.076563) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pdf1450814e\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = RegNetX32(lr=0.05)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(96, 96))\n",
        "trainer.fit(model, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f60c0281",
      "metadata": {
        "id": "f60c0281"
      },
      "source": [
        "## Discussion\n",
        "\n",
        "With desirable inductive biases (assumptions or preferences) like locality and translation invariance (:numref:`sec_why-conv`)\n",
        "for vision, CNNs have been the dominant architectures in this area. This remained the case from LeNet up until Transformers (:numref:`sec_transformer`) :cite:`Dosovitskiy.Beyer.Kolesnikov.ea.2021,touvron2021training` started surpassing CNNs in terms of accuracy. While much of the recent progress in terms of vision Transformers *can* be backported into CNNs :cite:`liu2022convnet`, it is only possible at a higher computational cost. Just as importantly, recent hardware optimizations (NVIDIA Ampere and Hopper) have only widened the gap in favor of Transformers.\n",
        "\n",
        "It is worth noting that Transformers have a significantly lower degree of inductive bias towards locality and translation invariance than CNNs. That learned structures prevailed is due, not least, to the availability of large image collections, such as LAION-400m and LAION-5B :cite:`schuhmann2022laion` with up to 5 billion images. Quite surprisingly, some of the more relevant work in this context even includes MLPs :cite:`tolstikhin2021mlp`.\n",
        "\n",
        "In sum, vision Transformers (:numref:`sec_vision-transformer`) by now lead in terms of\n",
        "state-of-the-art performance in large-scale image classification,\n",
        "showing that *scalability trumps inductive biases* :cite:`Dosovitskiy.Beyer.Kolesnikov.ea.2021`.\n",
        "This includes pretraining large-scale Transformers (:numref:`sec_large-pretraining-transformers`) with multi-head self-attention (:numref:`sec_multihead-attention`). We invite the readers to dive into these chapters for a much more detailed discussion.\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Increase the number of stages to four. Can you design a deeper RegNetX that performs better?\n",
        "1. De-ResNeXt-ify RegNets by replacing the ResNeXt block with the ResNet block. How does your new model perform?\n",
        "1. Implement multiple instances of a \"VioNet\" family by *violating* the design principles of RegNetX. How do they perform? Which of ($d_i$, $c_i$, $g_i$, $b_i$) is the most important factor?\n",
        "1. Your goal is to design the \"perfect\" MLP. Can you use the design principles introduced above to find good architectures? Is it possible to extrapolate from small to large networks?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceLcsYAnb9UC",
      "metadata": {
        "id": "ceLcsYAnb9UC"
      },
      "source": [
        "No. 1\n",
        "Increase the number of stages to four. Can you design a deeper RegNetX that performs better?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p7i79a7FJCDH",
      "metadata": {
        "id": "p7i79a7FJCDH"
      },
      "outputs": [],
      "source": [
        "class AnyNet(d2l.Classifier):\n",
        "    def stem(self, num_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(num_channels, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU())\n",
        "    def stage(self, depth, num_channels, groups, bot_mul):\n",
        "        blk = []\n",
        "        for i in range(depth):\n",
        "            if i == 0:\n",
        "                blk.append(d2l.ResNeXtBlock(num_channels, groups, bot_mul,\n",
        "                    use_1x1conv=True, strides=2))\n",
        "            else:\n",
        "                blk.append(d2l.ResNeXtBlock(num_channels, groups, bot_mul))\n",
        "        return nn.Sequential(*blk)\n",
        "\n",
        "    def __init__(self, arch, stem_channels, lr=0.1, num_classes=10):\n",
        "        super(AnyNet, self).__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(self.stem(stem_channels))\n",
        "        for i, s in enumerate(arch):\n",
        "            self.net.add_module(f'stage{i+1}', self.stage(*s))\n",
        "        self.net.add_module('head', nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "            nn.LazyLinear(num_classes)))\n",
        "        self.net.apply(d2l.init_cnn)\n",
        "\n",
        "class RegNetX32(AnyNet):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        stem_channels, groups, bot_mul = 32, 16, 1\n",
        "        depths, channels = (4, 6, 8, 16), (32, 80, 128, 256)\n",
        "        super().__init__(\n",
        "            # ((depths[0], channels[0], groups, bot_mul),\n",
        "            #  (depths[1], channels[1], groups, bot_mul)),\n",
        "            [(depths[i], channels[i], groups, bot_mul) for i in range(len(depths))],\n",
        "            stem_channels, lr, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ptEbePMhcozq",
      "metadata": {
        "id": "ptEbePMhcozq"
      },
      "outputs": [],
      "source": [
        "model = RegNetX32(lr=0.05)\n",
        "# summary(model,(1,224,224))\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(224, 224))\n",
        "trainer.fit(model, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iCtbVncXctI5",
      "metadata": {
        "id": "iCtbVncXctI5"
      },
      "source": [
        "No. 2\n",
        "\n",
        "De-ResNeXt-ify RegNets by replacing the ResNeXt block with the ResNet block. How does your new model perform?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m_qLXeXBcwOv",
      "metadata": {
        "id": "m_qLXeXBcwOv"
      },
      "outputs": [],
      "source": [
        "class DeAnyNet(d2l.Classifier):\n",
        "    def stem(self, num_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.LazyConv2d(num_channels, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LazyBatchNorm2d(), nn.ReLU())\n",
        "    def stage(self, depth, num_channels):\n",
        "        blk = []\n",
        "        for i in range(depth):\n",
        "            if i == 0:\n",
        "                blk.append(d2l.Residual(num_channels, use_1x1conv=True, strides=2))\n",
        "            else:\n",
        "                blk.append(d2l.Residual(num_channels))\n",
        "        return nn.Sequential(*blk)\n",
        "\n",
        "    def __init__(self, arch, stem_channels, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.net = nn.Sequential(self.stem(stem_channels))\n",
        "        for i, s in enumerate(arch):\n",
        "            self.net.add_module(f'stage{i+1}', self.stage(*s))\n",
        "        self.net.add_module('head', nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "            nn.LazyLinear(num_classes)))\n",
        "        self.net.apply(d2l.init_cnn)\n",
        "\n",
        "class DeResNeXt(DeAnyNet):\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        stem_channels, groups, bot_mul = 32, 16, 1\n",
        "        depths, channels = (5, 6), (32, 80)\n",
        "        super().__init__(\n",
        "            ((depths[0], channels[0]),\n",
        "             (depths[1], channels[1])),\n",
        "            stem_channels, lr, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mN8vw2zHc1ZG",
      "metadata": {
        "id": "mN8vw2zHc1ZG"
      },
      "outputs": [],
      "source": [
        "model = DeResNeXt(lr=0.05)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "trainer.fit(model, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8T7jW4whc4pI",
      "metadata": {
        "id": "8T7jW4whc4pI"
      },
      "source": [
        "No. 3\n",
        "\n",
        "Implement multiple instances of a “VioNet” family by violating the design principles of RegNetX. How do they perform? Which of (d_i, c_i, g_i, b_i) is the most important factor?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20Fd5O4ngQKH",
      "metadata": {
        "id": "20Fd5O4ngQKH"
      },
      "outputs": [],
      "source": [
        "class VioNet(AnyNet):\n",
        "    def __init__(self, lr=0.1, num_classes=10, depths=(4, 6), channels=(32, 80),\n",
        "                 stem_channels=32, groups=(16, 16), bot_mul=(1, 1)):\n",
        "        super().__init__(\n",
        "            [(depths[i], channels[i], groups[i], bot_mul[i]) for i in range(len(depths))],\n",
        "            stem_channels, lr, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P7evr_VqgT7O",
      "metadata": {
        "id": "P7evr_VqgT7O"
      },
      "outputs": [],
      "source": [
        "VioNet_d = VioNet(depths=(6, 4))\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "trainer.fit(VioNet_d, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lnOHLB5qgViA",
      "metadata": {
        "id": "lnOHLB5qgViA"
      },
      "outputs": [],
      "source": [
        "VioNet_c = VioNet(channels=(80, 32))\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "trainer.fit(VioNet_c, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Log2bZJggXq4",
      "metadata": {
        "id": "Log2bZJggXq4"
      },
      "outputs": [],
      "source": [
        "VioNet_g = VioNet(groups=(16, 32))\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "trainer.fit(VioNet_g, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gwzfdRtLgYZB",
      "metadata": {
        "id": "gwzfdRtLgYZB"
      },
      "outputs": [],
      "source": [
        "VioNet_b = VioNet(bot_mul=(1, 2))\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "trainer.fit(VioNet_b, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sag3YdU_hRsb",
      "metadata": {
        "id": "sag3YdU_hRsb"
      },
      "source": [
        "Dari empat faktor yang diuji, faktor yang paling penting bergantung pada bagaimana perubahan tersebut memengaruhi kapasitas model dan kemampuannya untuk menyeimbangkan kompleksitas dan kinerja. Misalnya, peningkatan depths (d_i) atau channels (c_i) dapat memperkaya representasi fitur, tetapi mungkin meningkatkan risiko overfitting jika terlalu besar. Demikian pula, pengaturan groups (g_i) dan bottleneck multiplier (b_i) berperan dalam pengurangan parameter dan efisiensi komputasi tanpa mengorbankan akurasi."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z8KT9aSnh-XH",
      "metadata": {
        "id": "z8KT9aSnh-XH"
      },
      "source": [
        "No. 4\n",
        "Your goal is to design the “perfect” MLP. Can you use the design principles introduced above to find good architectures? Is it possible to extrapolate from small to large networks?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rdQ29RXMilvG",
      "metadata": {
        "id": "rdQ29RXMilvG"
      },
      "source": [
        "Merancang MLP (Multilayer Perceptron) yang sempurna membutuhkan pemilihan arsitektur yang tepat untuk mencapai kinerja tinggi dalam tugas tertentu. Beberapa prinsip desain yang disebutkan dalam penelitian, seperti kedalaman dan lebar jaringan, koneksi skip, normalisasi, dan fungsi aktivasi, dapat diterapkan untuk menciptakan MLP yang efektif.\n",
        "\n",
        "Kedalaman dan lebar jaringan harus disesuaikan dengan hati-hati untuk menangkap pola kompleks tanpa menyebabkan overfitting. Penggunaan dropout, batch normalization, dan regularisasi juga membantu menghindari overfitting. Selain itu, optimisasi parameter seperti fungsi aktivasi, inisialisasi bobot, dan strategi pooling dapat meningkatkan kinerja.\n",
        "\n",
        "Proses perancangan MLP ideal memerlukan eksperimen terus-menerus, evaluasi kinerja, dan penyesuaian arsitektur berdasarkan hasil yang diperoleh."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": []
  },
  "nbformat": 4,
  "nbformat_minor": 5
}